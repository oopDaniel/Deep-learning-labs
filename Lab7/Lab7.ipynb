{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1:  Removal of bias in embedding (`Word2Vec`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "king = wv[\"king\"]\n",
    "print(king.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('monarch', 0.7042065858840942), ('kings', 0.6780861020088196), ('princess', 0.6731551289558411), ('queens', 0.6679497957229614), ('prince', 0.6435247659683228), ('royal', 0.5985592603683472), ('princes', 0.5942345261573792), ('crown_prince', 0.5906674265861511), ('NYC_anglophiles_aflutter', 0.5811060070991516), ('Queen_Consort', 0.5735104084014893)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=[\"king\", \"queen\"], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510957\n"
     ]
    }
   ],
   "source": [
    "print(wv.similarity(\"king\", \"queen\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rules', 0.5407542586326599), ('ruled', 0.44207143783569336), ('Fifa_statutes', 0.4358542859554291), ('Rule', 0.42790597677230835), ('rulebook', 0.40312427282333374), ('Gensym_flagship_G2', 0.39585864543914795), ('unwritten_pact', 0.3956116735935211), ('edict', 0.3861566483974457), ('dictum', 0.3820774257183075), ('Bosman_Ruling', 0.37687504291534424)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=[\"man\", \"rule\"], negative=[\"woman\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debias by Neutralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debias(word_with_bias, word_positive, word_negative, wv):\n",
    "    biased = wv[word_with_bias]\n",
    "    positive = wv[word_positive]\n",
    "    negative = wv[word_negative]\n",
    "    dist = positive - negative\n",
    "    \n",
    "    bias_component = np.dot(biased, dist) / np.sum(dist * dist) * dist\n",
    "    return biased - bias_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_debiased = debias(\"rule\", \"man\", \"woman\", wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rules', 0.5407542586326599), ('ruled', 0.44207143783569336), ('Fifa_statutes', 0.4358542859554291), ('Rule', 0.42790597677230835), ('rulebook', 0.40312427282333374), ('Gensym_flagship_G2', 0.39585864543914795), ('unwritten_pact', 0.3956116735935211), ('edict', 0.3861566483974457), ('dictum', 0.3820774257183075), ('Bosman_Ruling', 0.37687504291534424)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=[\"man\", \"rule\"], negative=[\"woman\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rule', 0.9792402982711792), ('rules', 0.6320737600326538), ('Rule', 0.513302206993103), ('ruled', 0.512016773223877), ('Fifa_statutes', 0.48751938343048096), ('law', 0.4780648350715637), ('Gensym_flagship_G2', 0.4628755450248718), ('ruling', 0.4611573815345764), ('rulebook', 0.4580633044242859), ('edict', 0.45712146162986755)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=[\"man\", rule_debiased], negative=[\"woman\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_imdb_sentiment(MAX_SEQUENCE_LEN=100, EMBEDDED_SIZE=8):\n",
    "    MAX_FEATURES = 10000\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)\n",
    "    \n",
    "    # x_train has a size (training_size, ). Because the sentences have variable size,\n",
    "    # we cannot represent this in matrix format.\n",
    "    print(x_train.shape)\n",
    "    \n",
    "    # We do that by \"padding\" the sentences. If the sentences are bigger, we clip them.\n",
    "    # If they are smaller, we insert a \"NO_WORD\" token to the sentence.\n",
    "    x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=MAX_SEQUENCE_LEN)\n",
    "    x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=MAX_SEQUENCE_LEN)\n",
    "    print(x_train.shape)\n",
    "    \n",
    "    xi = Input(MAX_SEQUENCE_LEN)\n",
    "\n",
    "    # Embedding input is (training_size, MAX_SEQUENCE_LEN)\n",
    "    # Embedding output is (training_size, MAX_SEQUENCE_LEN, EMBEDDED_SIZE)\n",
    "\n",
    "    x = Embedding(MAX_FEATURES, EMBEDDED_SIZE, input_length=MAX_SEQUENCE_LEN)(xi)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=xi, outputs=x)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "            x_train, y_train, epochs=20, batch_size=32, validation_split=0.2,\n",
    "            workers=(multiprocessing.cpu_count() - 1), use_multiprocessing=True)\n",
    "\n",
    "    print(model.evaluate(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000, 100)\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_52 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_50 (Embedding)     (None, 100, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 80,801\n",
      "Trainable params: 80,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 77us/sample - loss: 0.5996 - acc: 0.6816 - val_loss: 0.4171 - val_acc: 0.8284\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 1s 61us/sample - loss: 0.3227 - acc: 0.8715 - val_loss: 0.3413 - val_acc: 0.8496\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 1s 62us/sample - loss: 0.2338 - acc: 0.9140 - val_loss: 0.3315 - val_acc: 0.8500\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 1s 62us/sample - loss: 0.1794 - acc: 0.9398 - val_loss: 0.3408 - val_acc: 0.8512\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 1s 62us/sample - loss: 0.1363 - acc: 0.9606 - val_loss: 0.3561 - val_acc: 0.8494\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.1002 - acc: 0.9764 - val_loss: 0.3767 - val_acc: 0.8496\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0714 - acc: 0.9870 - val_loss: 0.4010 - val_acc: 0.8470\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0493 - acc: 0.9937 - val_loss: 0.4287 - val_acc: 0.8448\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0335 - acc: 0.9976 - val_loss: 0.4571 - val_acc: 0.8406\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0225 - acc: 0.9990 - val_loss: 0.4837 - val_acc: 0.8400\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0151 - acc: 0.9997 - val_loss: 0.5151 - val_acc: 0.8378\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 1s 64us/sample - loss: 0.0102 - acc: 0.9998 - val_loss: 0.5466 - val_acc: 0.8372\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0069 - acc: 0.9999 - val_loss: 0.5760 - val_acc: 0.8362\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0048 - acc: 0.9999 - val_loss: 0.6054 - val_acc: 0.8362\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0033 - acc: 0.9999 - val_loss: 0.6359 - val_acc: 0.8356\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6622 - val_acc: 0.8350\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6939 - val_acc: 0.8340\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.7233 - val_acc: 0.8324\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 7.8799e-04 - acc: 1.0000 - val_loss: 0.7542 - val_acc: 0.8338\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 5.6010e-04 - acc: 1.0000 - val_loss: 0.7861 - val_acc: 0.8330\n",
      "25000/25000 [==============================] - 1s 30us/sample - loss: 0.7821 - acc: 0.8292\n",
      "[0.7821061151480675, 0.8292]\n"
     ]
    }
   ],
   "source": [
    "analyze_imdb_sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current accuracy for this model is **0.8292**\n",
    "\n",
    "Try to add a preloaded embedded from Glove from this model, see the suggestion in\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "Also try Conv1D + MaxPooling1D to improve results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_imdb_sentiment2(max_sequence_len=100, embedded_size=100, weights=None):\n",
    "    MAX_FEATURES = 10000\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = get_embedding_weight(embedded_size, MAX_FEATURES)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)\n",
    "    \n",
    "    x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=max_sequence_len)\n",
    "    x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=max_sequence_len)\n",
    "\n",
    "    \n",
    "    xi = Input(max_sequence_len)\n",
    "\n",
    "    # Embedding input is (training_size, max_sequence_len)\n",
    "    # Embedding output is (training_size, max_sequence_len, embedded_size)\n",
    "\n",
    "    x = Embedding(MAX_FEATURES, embedded_size, input_length=max_sequence_len,\n",
    "              weights=[weights], trainable=True)(xi)\n",
    "    x = Conv1D(100, 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=xi, outputs=x)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "            x_train, y_train, epochs=20, batch_size=32, validation_split=0.2,\n",
    "            workers=(multiprocessing.cpu_count() - 1), use_multiprocessing=True)\n",
    "    \n",
    "    evalutation = model.evaluate(x_test, y_test)\n",
    "    print(evalutation)\n",
    "    return evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_weight(embedded_size, max_features):\n",
    "    embeddings_index, embedding_pretrain_size = load_pretrained_embedding_idx(embedded_size)\n",
    "    \n",
    "    assert embedding_pretrain_size >= embedded_size\n",
    "    \n",
    "    return get_embedding_matrix(\n",
    "        imdb.get_word_index(),\n",
    "        embeddings_index,\n",
    "        MAX_FEATURES,\n",
    "        embedded_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embedding_idx(dimension):\n",
    "    assert dimension in [50, 100, 200, 300]\n",
    "    CURR_DIR   = os.getcwd()\n",
    "    PRETRAINED = 'glove.6B.%dd.txt' % dimension\n",
    "#     PRETRAINED = 'glove.42B.%dd.txt' % dimension\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    \n",
    "    with open(os.path.join(CURR_DIR, PRETRAINED), \"r\") as fd:\n",
    "        for line in fd:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        \n",
    "    return embeddings_index, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(word_index, embeddings_index, max_features, embedded_size):\n",
    "    embedding_matrix = np.zeros((max_features, embedded_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_66 (Embedding)     (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 96, 100)           100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 19, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 1900)              0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 1901      \n",
      "=================================================================\n",
      "Total params: 2,102,001\n",
      "Trainable params: 2,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 9s 443us/sample - loss: 0.6066 - acc: 0.6443 - val_loss: 0.4192 - val_acc: 0.7996\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 9s 434us/sample - loss: 0.3055 - acc: 0.8713 - val_loss: 0.3681 - val_acc: 0.8318\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 9s 430us/sample - loss: 0.1480 - acc: 0.9488 - val_loss: 0.4187 - val_acc: 0.8238\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 9s 435us/sample - loss: 0.0423 - acc: 0.9907 - val_loss: 0.5091 - val_acc: 0.8250\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 9s 436us/sample - loss: 0.0096 - acc: 0.9995 - val_loss: 0.5853 - val_acc: 0.8222\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 9s 443us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6082 - val_acc: 0.8332\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 9s 440us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 0.8344\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 9s 437us/sample - loss: 6.9513e-04 - acc: 1.0000 - val_loss: 0.6741 - val_acc: 0.8354\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 9s 434us/sample - loss: 4.4955e-04 - acc: 1.0000 - val_loss: 0.7034 - val_acc: 0.8338\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 9s 444us/sample - loss: 2.9896e-04 - acc: 1.0000 - val_loss: 0.7297 - val_acc: 0.8360\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 9s 440us/sample - loss: 2.0264e-04 - acc: 1.0000 - val_loss: 0.7566 - val_acc: 0.8374\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 9s 435us/sample - loss: 1.3914e-04 - acc: 1.0000 - val_loss: 0.7830 - val_acc: 0.8370\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 9s 443us/sample - loss: 9.5939e-05 - acc: 1.0000 - val_loss: 0.8098 - val_acc: 0.8392\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 9s 439us/sample - loss: 6.6542e-05 - acc: 1.0000 - val_loss: 0.8363 - val_acc: 0.8394\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 9s 432us/sample - loss: 4.6354e-05 - acc: 1.0000 - val_loss: 0.8638 - val_acc: 0.8366\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 9s 434us/sample - loss: 3.2149e-05 - acc: 1.0000 - val_loss: 0.8882 - val_acc: 0.8404\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 9s 432us/sample - loss: 2.2383e-05 - acc: 1.0000 - val_loss: 0.9162 - val_acc: 0.8376\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 9s 444us/sample - loss: 1.5642e-05 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.8398\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 9s 438us/sample - loss: 1.1031e-05 - acc: 1.0000 - val_loss: 0.9692 - val_acc: 0.8392\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 9s 435us/sample - loss: 7.7542e-06 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.8398\n",
      "25000/25000 [==============================] - 1s 54us/sample - loss: 1.0096 - acc: 0.8348\n",
      "[1.009562242680788, 0.83484]\n"
     ]
    }
   ],
   "source": [
    "analyze_imdb_sentiment2(embedded_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model improves to **0.83484**\n",
    "\n",
    "> Question: why does this model may help you get better accuracy?\n",
    " \n",
    "The model may improve because it loads a pretrained embedding as its weight and also has some \"additional weights\" (Conv1D, pooling) on top of the embedding.\n",
    "\n",
    "Now, try to change the `max_sequence_len` or the `embedded_size` and plot a 3D graph with\n",
    "`embedded_size` x `max_sequence_len` x `accuracy` in a python jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_combination():\n",
    "    MAX_FEATURES = 10000\n",
    "\n",
    "    result = []\n",
    "    for embedded_size in [50, 100, 200, 300]:\n",
    "        weights = get_embedding_weight(embedded_size, MAX_FEATURES)\n",
    "        for max_sequence_len in [50, 100, 200, 300]:\n",
    "            _, accuracy = analyze_imdb_sentiment2(max_sequence_len, embedded_size, weights)\n",
    "            result.append((embedded_size, max_sequence_len, accuracy))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(data):\n",
    "    ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "    ax.scatter(\n",
    "        xs=data[:,0], \n",
    "        ys=data[:,1], \n",
    "        zs=data[:,2], \n",
    "        c=data[:,1], \n",
    "        cmap='tab10'\n",
    "    )\n",
    "    ax.set_xlabel(\"Embedded size\")\n",
    "    ax.set_ylabel(\"Max sequence length\")\n",
    "    ax.set_zlabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_67 (Embedding)     (None, 50, 50)            500000    \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 46, 100)           25100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 9, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 901       \n",
      "=================================================================\n",
      "Total params: 526,001\n",
      "Trainable params: 526,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 170us/sample - loss: 0.6797 - acc: 0.5648 - val_loss: 0.6065 - val_acc: 0.6664\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.4693 - acc: 0.7774 - val_loss: 0.5297 - val_acc: 0.7380\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.3130 - acc: 0.8684 - val_loss: 0.4881 - val_acc: 0.7642\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.1984 - acc: 0.9270 - val_loss: 0.5454 - val_acc: 0.7610\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.1128 - acc: 0.9694 - val_loss: 0.5958 - val_acc: 0.7620\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 154us/sample - loss: 0.0532 - acc: 0.9906 - val_loss: 0.6668 - val_acc: 0.7650\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 157us/sample - loss: 0.0222 - acc: 0.9992 - val_loss: 0.7602 - val_acc: 0.7684\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.0094 - acc: 0.9998 - val_loss: 0.8370 - val_acc: 0.7670\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.0047 - acc: 0.9999 - val_loss: 0.9115 - val_acc: 0.7660\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9743 - val_acc: 0.7668\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0313 - val_acc: 0.7654\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 1.0839 - val_acc: 0.7696\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 3s 155us/sample - loss: 6.6670e-04 - acc: 1.0000 - val_loss: 1.1404 - val_acc: 0.7668\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 3s 157us/sample - loss: 4.4113e-04 - acc: 1.0000 - val_loss: 1.1912 - val_acc: 0.7678\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 3.0122e-04 - acc: 1.0000 - val_loss: 1.2438 - val_acc: 0.7688\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 2.0192e-04 - acc: 1.0000 - val_loss: 1.3016 - val_acc: 0.7682\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 3s 157us/sample - loss: 1.3725e-04 - acc: 1.0000 - val_loss: 1.3425 - val_acc: 0.7722\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 3s 155us/sample - loss: 9.3379e-05 - acc: 1.0000 - val_loss: 1.3960 - val_acc: 0.7692\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 3s 155us/sample - loss: 6.4287e-05 - acc: 1.0000 - val_loss: 1.4425 - val_acc: 0.7720\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 3s 156us/sample - loss: 4.4655e-05 - acc: 1.0000 - val_loss: 1.4988 - val_acc: 0.7700\n",
      "25000/25000 [==============================] - 1s 37us/sample - loss: 1.4333 - acc: 0.7754\n",
      "[1.433348789243698, 0.77544]\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_68 (Embedding)     (None, 100, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 96, 100)           25100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 19, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 1900)              0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 1901      \n",
      "=================================================================\n",
      "Total params: 527,001\n",
      "Trainable params: 527,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 182us/sample - loss: 0.6814 - acc: 0.5659 - val_loss: 0.6130 - val_acc: 0.6616\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 0.4489 - acc: 0.7846 - val_loss: 0.5481 - val_acc: 0.7342\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.2620 - acc: 0.8931 - val_loss: 0.4079 - val_acc: 0.8184\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.1532 - acc: 0.9467 - val_loss: 0.4776 - val_acc: 0.8082\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.0744 - acc: 0.9805 - val_loss: 0.4773 - val_acc: 0.8230\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 165us/sample - loss: 0.0292 - acc: 0.9969 - val_loss: 0.5585 - val_acc: 0.8240\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.0117 - acc: 0.9996 - val_loss: 0.6043 - val_acc: 0.8264\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 165us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.6633 - val_acc: 0.8302\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.7135 - val_acc: 0.8302\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7651 - val_acc: 0.8268\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 168us/sample - loss: 9.4505e-04 - acc: 1.0000 - val_loss: 0.7981 - val_acc: 0.8304\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 6.2336e-04 - acc: 1.0000 - val_loss: 0.8523 - val_acc: 0.8246\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 4.1194e-04 - acc: 1.0000 - val_loss: 0.8750 - val_acc: 0.8304\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 2.7394e-04 - acc: 1.0000 - val_loss: 0.9124 - val_acc: 0.8298\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 1.8583e-04 - acc: 1.0000 - val_loss: 0.9480 - val_acc: 0.8294\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 1.2661e-04 - acc: 1.0000 - val_loss: 0.9866 - val_acc: 0.8290\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 3s 168us/sample - loss: 8.6520e-05 - acc: 1.0000 - val_loss: 1.0275 - val_acc: 0.8292\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 5.9188e-05 - acc: 1.0000 - val_loss: 1.0624 - val_acc: 0.8288\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 4.0728e-05 - acc: 1.0000 - val_loss: 1.0992 - val_acc: 0.8282\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 2.8063e-05 - acc: 1.0000 - val_loss: 1.1398 - val_acc: 0.8268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 35us/sample - loss: 1.1373 - acc: 0.8228\n",
      "[1.1373093805336951, 0.8228]\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_69 (Embedding)     (None, 200, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 196, 100)          25100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 39, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 3900)              0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 3901      \n",
      "=================================================================\n",
      "Total params: 529,001\n",
      "Trainable params: 529,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 205us/sample - loss: 0.6698 - acc: 0.5776 - val_loss: 0.5305 - val_acc: 0.7406\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 4s 178us/sample - loss: 0.3743 - acc: 0.8375 - val_loss: 0.3589 - val_acc: 0.8458\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 4s 178us/sample - loss: 0.2126 - acc: 0.9186 - val_loss: 0.3319 - val_acc: 0.8584\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 4s 178us/sample - loss: 0.1165 - acc: 0.9612 - val_loss: 0.3639 - val_acc: 0.8582\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 4s 179us/sample - loss: 0.0550 - acc: 0.9857 - val_loss: 0.4278 - val_acc: 0.8568\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 4s 181us/sample - loss: 0.0217 - acc: 0.9970 - val_loss: 0.4784 - val_acc: 0.8580\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 4s 178us/sample - loss: 0.0086 - acc: 0.9997 - val_loss: 0.5317 - val_acc: 0.8582\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 4s 178us/sample - loss: 0.0040 - acc: 0.9998 - val_loss: 0.5572 - val_acc: 0.8608\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 4s 179us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.8584\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 4s 178us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.8608\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 4s 179us/sample - loss: 6.8792e-04 - acc: 1.0000 - val_loss: 0.6692 - val_acc: 0.8604\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 4s 179us/sample - loss: 4.4392e-04 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.8598\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 4s 179us/sample - loss: 2.9453e-04 - acc: 1.0000 - val_loss: 0.7350 - val_acc: 0.8590\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 4s 180us/sample - loss: 1.9782e-04 - acc: 1.0000 - val_loss: 0.7643 - val_acc: 0.8584\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 4s 180us/sample - loss: 1.3197e-04 - acc: 1.0000 - val_loss: 0.7956 - val_acc: 0.8582\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 4s 180us/sample - loss: 9.2508e-05 - acc: 1.0000 - val_loss: 0.8298 - val_acc: 0.8588\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 4s 181us/sample - loss: 6.3579e-05 - acc: 1.0000 - val_loss: 0.8554 - val_acc: 0.8594\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 4s 179us/sample - loss: 4.3276e-05 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.8596\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 4s 180us/sample - loss: 3.0530e-05 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 0.8598\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 4s 179us/sample - loss: 2.1146e-05 - acc: 1.0000 - val_loss: 0.9460 - val_acc: 0.8604\n",
      "25000/25000 [==============================] - 1s 45us/sample - loss: 1.0161 - acc: 0.8521\n",
      "[1.016062311539948, 0.85212]\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_72 (InputLayer)        [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_70 (Embedding)     (None, 300, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 296, 100)          25100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 59, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_50 (Flatten)         (None, 5900)              0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 5901      \n",
      "=================================================================\n",
      "Total params: 531,001\n",
      "Trainable params: 531,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 215us/sample - loss: 0.6820 - acc: 0.5642 - val_loss: 0.5764 - val_acc: 0.7040\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 0.3879 - acc: 0.8267 - val_loss: 0.3449 - val_acc: 0.8546\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 4s 201us/sample - loss: 0.2105 - acc: 0.9172 - val_loss: 0.3254 - val_acc: 0.8670\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 0.1187 - acc: 0.9596 - val_loss: 0.3514 - val_acc: 0.8646\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 0.0550 - acc: 0.9850 - val_loss: 0.4393 - val_acc: 0.8604\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 4s 199us/sample - loss: 0.0212 - acc: 0.9969 - val_loss: 0.4601 - val_acc: 0.8638\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 0.0084 - acc: 0.9997 - val_loss: 0.5152 - val_acc: 0.8660\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 0.0035 - acc: 0.9999 - val_loss: 0.5663 - val_acc: 0.8694\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.8688\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.8694\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 6.4460e-04 - acc: 1.0000 - val_loss: 0.6649 - val_acc: 0.8676\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 4s 201us/sample - loss: 4.2067e-04 - acc: 1.0000 - val_loss: 0.6936 - val_acc: 0.8676\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 2.7662e-04 - acc: 1.0000 - val_loss: 0.7220 - val_acc: 0.8682\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 1.8564e-04 - acc: 1.0000 - val_loss: 0.7496 - val_acc: 0.8682\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 1.2506e-04 - acc: 1.0000 - val_loss: 0.7816 - val_acc: 0.8676\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 4s 202us/sample - loss: 8.5239e-05 - acc: 1.0000 - val_loss: 0.8076 - val_acc: 0.8690\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 4s 201us/sample - loss: 5.9629e-05 - acc: 1.0000 - val_loss: 0.8382 - val_acc: 0.8714\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 4s 200us/sample - loss: 4.0477e-05 - acc: 1.0000 - val_loss: 0.8647 - val_acc: 0.8674\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 4s 201us/sample - loss: 2.7714e-05 - acc: 1.0000 - val_loss: 0.8941 - val_acc: 0.8678\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 4s 200us/sample - loss: 1.9853e-05 - acc: 1.0000 - val_loss: 0.9201 - val_acc: 0.8688\n",
      "25000/25000 [==============================] - 1s 53us/sample - loss: 0.9815 - acc: 0.8581\n",
      "[0.9815400265074335, 0.85812]\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_73 (InputLayer)        [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_71 (Embedding)     (None, 50, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 46, 100)           50100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 9, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 1)                 901       \n",
      "=================================================================\n",
      "Total params: 1,051,001\n",
      "Trainable params: 1,051,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 5s 273us/sample - loss: 0.6581 - acc: 0.6024 - val_loss: 0.5538 - val_acc: 0.7148\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 5s 249us/sample - loss: 0.4229 - acc: 0.8062 - val_loss: 0.4523 - val_acc: 0.7812\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 5s 253us/sample - loss: 0.2559 - acc: 0.8974 - val_loss: 0.4735 - val_acc: 0.7800\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 5s 253us/sample - loss: 0.1386 - acc: 0.9554 - val_loss: 0.5950 - val_acc: 0.7608\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 5s 263us/sample - loss: 0.0528 - acc: 0.9905 - val_loss: 0.6938 - val_acc: 0.7616\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 5s 264us/sample - loss: 0.0166 - acc: 0.9993 - val_loss: 0.7131 - val_acc: 0.7826\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 5s 263us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.7810\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 5s 266us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.8371 - val_acc: 0.7840\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 5s 248us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8822 - val_acc: 0.7812\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 5s 244us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9279 - val_acc: 0.7822\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 5s 246us/sample - loss: 6.6756e-04 - acc: 1.0000 - val_loss: 0.9711 - val_acc: 0.7814\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 5s 246us/sample - loss: 4.4119e-04 - acc: 1.0000 - val_loss: 1.0187 - val_acc: 0.7814\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 5s 246us/sample - loss: 2.9536e-04 - acc: 1.0000 - val_loss: 1.0595 - val_acc: 0.7804\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 5s 245us/sample - loss: 1.9960e-04 - acc: 1.0000 - val_loss: 1.1065 - val_acc: 0.7808\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 5s 247us/sample - loss: 1.3527e-04 - acc: 1.0000 - val_loss: 1.1429 - val_acc: 0.7808\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 5s 246us/sample - loss: 9.2519e-05 - acc: 1.0000 - val_loss: 1.1853 - val_acc: 0.7800\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 5s 246us/sample - loss: 6.3936e-05 - acc: 1.0000 - val_loss: 1.2253 - val_acc: 0.7802\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 5s 255us/sample - loss: 4.3595e-05 - acc: 1.0000 - val_loss: 1.2684 - val_acc: 0.7788\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 5s 246us/sample - loss: 3.0219e-05 - acc: 1.0000 - val_loss: 1.3086 - val_acc: 0.7802\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 5s 246us/sample - loss: 2.0830e-05 - acc: 1.0000 - val_loss: 1.3568 - val_acc: 0.7778\n",
      "25000/25000 [==============================] - 1s 36us/sample - loss: 1.3534 - acc: 0.7799\n",
      "[1.3533633952617645, 0.77992]\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_72 (Embedding)     (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 96, 100)           50100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 19, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 1900)              0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 1901      \n",
      "=================================================================\n",
      "Total params: 1,052,001\n",
      "Trainable params: 1,052,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 6s 275us/sample - loss: 0.6554 - acc: 0.6025 - val_loss: 0.5812 - val_acc: 0.6814\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 5s 262us/sample - loss: 0.3794 - acc: 0.8314 - val_loss: 0.4068 - val_acc: 0.8182\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 5s 261us/sample - loss: 0.2140 - acc: 0.9167 - val_loss: 0.4517 - val_acc: 0.8080\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 5s 262us/sample - loss: 0.0976 - acc: 0.9716 - val_loss: 0.5323 - val_acc: 0.8056\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 5s 261us/sample - loss: 0.0334 - acc: 0.9950 - val_loss: 0.5530 - val_acc: 0.8152\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 5s 260us/sample - loss: 0.0100 - acc: 0.9998 - val_loss: 0.5799 - val_acc: 0.8304\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 5s 263us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6224 - val_acc: 0.8328\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 5s 264us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6641 - val_acc: 0.8354\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 5s 263us/sample - loss: 9.9833e-04 - acc: 1.0000 - val_loss: 0.6990 - val_acc: 0.8358\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 5s 261us/sample - loss: 6.5028e-04 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.8352\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 5s 260us/sample - loss: 4.2668e-04 - acc: 1.0000 - val_loss: 0.7630 - val_acc: 0.8354\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 5s 261us/sample - loss: 2.8690e-04 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.8372\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 5s 262us/sample - loss: 1.9461e-04 - acc: 1.0000 - val_loss: 0.8272 - val_acc: 0.8350\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 5s 262us/sample - loss: 1.3202e-04 - acc: 1.0000 - val_loss: 0.8581 - val_acc: 0.8370\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 5s 262us/sample - loss: 9.1784e-05 - acc: 1.0000 - val_loss: 0.8891 - val_acc: 0.8342\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 5s 260us/sample - loss: 6.2560e-05 - acc: 1.0000 - val_loss: 0.9164 - val_acc: 0.8372\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 5s 261us/sample - loss: 4.3229e-05 - acc: 1.0000 - val_loss: 0.9498 - val_acc: 0.8362\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 5s 263us/sample - loss: 2.9895e-05 - acc: 1.0000 - val_loss: 0.9774 - val_acc: 0.8370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 5s 252us/sample - loss: 2.0775e-05 - acc: 1.0000 - val_loss: 1.0091 - val_acc: 0.8372\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 5s 254us/sample - loss: 1.4355e-05 - acc: 1.0000 - val_loss: 1.0447 - val_acc: 0.8344\n",
      "25000/25000 [==============================] - 1s 42us/sample - loss: 1.0670 - acc: 0.8289\n",
      "[1.0670092479228974, 0.82888]\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_75 (InputLayer)        [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_73 (Embedding)     (None, 200, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 196, 100)          50100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 39, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 3900)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 3901      \n",
      "=================================================================\n",
      "Total params: 1,054,001\n",
      "Trainable params: 1,054,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.6505 - acc: 0.6080 - val_loss: 0.4805 - val_acc: 0.7742\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 6s 285us/sample - loss: 0.3380 - acc: 0.8536 - val_loss: 0.3449 - val_acc: 0.8518\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 6s 284us/sample - loss: 0.1859 - acc: 0.9279 - val_loss: 0.3255 - val_acc: 0.8650\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.0869 - acc: 0.9728 - val_loss: 0.3904 - val_acc: 0.8606\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.0282 - acc: 0.9948 - val_loss: 0.4437 - val_acc: 0.8612\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.0087 - acc: 0.9996 - val_loss: 0.5687 - val_acc: 0.8544\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.0035 - acc: 0.9999 - val_loss: 0.5475 - val_acc: 0.8620\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5842 - val_acc: 0.8644\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 7.8525e-04 - acc: 1.0000 - val_loss: 0.6222 - val_acc: 0.8628\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 5.0230e-04 - acc: 1.0000 - val_loss: 0.6497 - val_acc: 0.8622\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 3.2229e-04 - acc: 1.0000 - val_loss: 0.6735 - val_acc: 0.8672\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 6s 284us/sample - loss: 2.1613e-04 - acc: 1.0000 - val_loss: 0.7011 - val_acc: 0.8662\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 1.4627e-04 - acc: 1.0000 - val_loss: 0.7310 - val_acc: 0.8656\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 6s 284us/sample - loss: 1.0195e-04 - acc: 1.0000 - val_loss: 0.7508 - val_acc: 0.8652\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 6s 284us/sample - loss: 6.8570e-05 - acc: 1.0000 - val_loss: 0.7784 - val_acc: 0.8658\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 6s 284us/sample - loss: 4.7845e-05 - acc: 1.0000 - val_loss: 0.8040 - val_acc: 0.8646\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 6s 284us/sample - loss: 3.3108e-05 - acc: 1.0000 - val_loss: 0.8328 - val_acc: 0.8658\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 6s 303us/sample - loss: 2.2947e-05 - acc: 1.0000 - val_loss: 0.8557 - val_acc: 0.8664\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 1.6039e-05 - acc: 1.0000 - val_loss: 0.8833 - val_acc: 0.8666\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 1.1177e-05 - acc: 1.0000 - val_loss: 0.9104 - val_acc: 0.8656\n",
      "25000/25000 [==============================] - 1s 55us/sample - loss: 0.9401 - acc: 0.8586\n",
      "[0.9400768349075317, 0.8586]\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_76 (InputLayer)        [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_74 (Embedding)     (None, 300, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 296, 100)          50100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 59, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 5900)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1)                 5901      \n",
      "=================================================================\n",
      "Total params: 1,056,001\n",
      "Trainable params: 1,056,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 8s 415us/sample - loss: 0.6510 - acc: 0.6008 - val_loss: 0.5007 - val_acc: 0.7510\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 6s 312us/sample - loss: 0.3295 - acc: 0.8576 - val_loss: 0.3163 - val_acc: 0.8704\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 6s 313us/sample - loss: 0.1797 - acc: 0.9318 - val_loss: 0.3256 - val_acc: 0.8664\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 6s 320us/sample - loss: 0.0808 - acc: 0.9747 - val_loss: 0.3711 - val_acc: 0.8706\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 6s 316us/sample - loss: 0.0295 - acc: 0.9940 - val_loss: 0.4133 - val_acc: 0.8686\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 6s 317us/sample - loss: 0.0098 - acc: 0.9992 - val_loss: 0.4717 - val_acc: 0.8690\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 6s 315us/sample - loss: 0.0036 - acc: 0.9999 - val_loss: 0.5221 - val_acc: 0.8710\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 6s 314us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5692 - val_acc: 0.8690\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 6s 325us/sample - loss: 7.3251e-04 - acc: 1.0000 - val_loss: 0.5990 - val_acc: 0.8716\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 7s 325us/sample - loss: 4.4866e-04 - acc: 1.0000 - val_loss: 0.6308 - val_acc: 0.8722\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 6s 318us/sample - loss: 2.9404e-04 - acc: 1.0000 - val_loss: 0.6601 - val_acc: 0.8696\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 6s 313us/sample - loss: 1.9724e-04 - acc: 1.0000 - val_loss: 0.6834 - val_acc: 0.8724\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 6s 315us/sample - loss: 1.3356e-04 - acc: 1.0000 - val_loss: 0.7111 - val_acc: 0.8720\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 6s 317us/sample - loss: 9.1189e-05 - acc: 1.0000 - val_loss: 0.7409 - val_acc: 0.8696\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 6s 316us/sample - loss: 6.2808e-05 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.8700\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 6s 314us/sample - loss: 4.3207e-05 - acc: 1.0000 - val_loss: 0.7916 - val_acc: 0.8700\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 6s 316us/sample - loss: 3.0086e-05 - acc: 1.0000 - val_loss: 0.8150 - val_acc: 0.8732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 6s 308us/sample - loss: 2.0930e-05 - acc: 1.0000 - val_loss: 0.8411 - val_acc: 0.8730\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 6s 317us/sample - loss: 1.4635e-05 - acc: 1.0000 - val_loss: 0.8680 - val_acc: 0.8740\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 7s 335us/sample - loss: 1.0277e-05 - acc: 1.0000 - val_loss: 0.8951 - val_acc: 0.8716\n",
      "25000/25000 [==============================] - 2s 70us/sample - loss: 0.9216 - acc: 0.8629\n",
      "[0.9216068066444993, 0.86288]\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_77 (InputLayer)        [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_75 (Embedding)     (None, 50, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 46, 100)           100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 9, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 901       \n",
      "=================================================================\n",
      "Total params: 2,101,001\n",
      "Trainable params: 2,101,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 9s 428us/sample - loss: 0.6278 - acc: 0.6281 - val_loss: 0.4982 - val_acc: 0.7468\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 8s 412us/sample - loss: 0.3584 - acc: 0.8410 - val_loss: 0.4568 - val_acc: 0.7886\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 8s 416us/sample - loss: 0.1774 - acc: 0.9370 - val_loss: 0.5109 - val_acc: 0.7724\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 8s 412us/sample - loss: 0.0544 - acc: 0.9893 - val_loss: 0.6064 - val_acc: 0.7780\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 8s 418us/sample - loss: 0.0129 - acc: 0.9997 - val_loss: 0.7050 - val_acc: 0.7824\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 8s 412us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.7726 - val_acc: 0.7818\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 8s 413us/sample - loss: 0.0018 - acc: 0.9999 - val_loss: 0.8289 - val_acc: 0.7804\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 8s 414us/sample - loss: 0.0016 - acc: 0.9999 - val_loss: 0.8722 - val_acc: 0.7812\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 8s 415us/sample - loss: 8.6631e-04 - acc: 0.9999 - val_loss: 0.9393 - val_acc: 0.7782\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 8s 414us/sample - loss: 0.0075 - acc: 0.9979 - val_loss: 1.0429 - val_acc: 0.7536\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 8s 413us/sample - loss: 0.0344 - acc: 0.9870 - val_loss: 1.1048 - val_acc: 0.7600\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 8s 413us/sample - loss: 0.0052 - acc: 0.9987 - val_loss: 1.1815 - val_acc: 0.7686\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 8s 412us/sample - loss: 6.3098e-04 - acc: 1.0000 - val_loss: 1.2170 - val_acc: 0.7670\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 8s 414us/sample - loss: 2.1738e-04 - acc: 1.0000 - val_loss: 1.2460 - val_acc: 0.7714\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 8s 411us/sample - loss: 1.2364e-04 - acc: 1.0000 - val_loss: 1.2745 - val_acc: 0.7720\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 8s 420us/sample - loss: 8.8105e-05 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.7732\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 8s 419us/sample - loss: 6.4969e-05 - acc: 1.0000 - val_loss: 1.3235 - val_acc: 0.7710\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 8s 417us/sample - loss: 4.8489e-05 - acc: 1.0000 - val_loss: 1.3441 - val_acc: 0.7712\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 8s 416us/sample - loss: 3.6438e-05 - acc: 1.0000 - val_loss: 1.3713 - val_acc: 0.7712\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 8s 418us/sample - loss: 2.7353e-05 - acc: 1.0000 - val_loss: 1.3929 - val_acc: 0.7718\n",
      "25000/25000 [==============================] - 1s 42us/sample - loss: 1.3502 - acc: 0.7764\n",
      "[1.3502201547050476, 0.7764]\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_78 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_76 (Embedding)     (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 96, 100)           100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 19, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 1900)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 1901      \n",
      "=================================================================\n",
      "Total params: 2,102,001\n",
      "Trainable params: 2,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 9s 443us/sample - loss: 0.5995 - acc: 0.6560 - val_loss: 0.4232 - val_acc: 0.8006\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 9s 441us/sample - loss: 0.3022 - acc: 0.8744 - val_loss: 0.3785 - val_acc: 0.8270\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 9s 436us/sample - loss: 0.1451 - acc: 0.9484 - val_loss: 0.4405 - val_acc: 0.8206\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 9s 437us/sample - loss: 0.0407 - acc: 0.9913 - val_loss: 0.4822 - val_acc: 0.8194\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 9s 434us/sample - loss: 0.0095 - acc: 0.9995 - val_loss: 0.5529 - val_acc: 0.8304\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 9s 435us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6004 - val_acc: 0.8342\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 9s 433us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6277 - val_acc: 0.8308\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 9s 434us/sample - loss: 7.6560e-04 - acc: 1.0000 - val_loss: 0.6589 - val_acc: 0.8320\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 9s 438us/sample - loss: 4.8913e-04 - acc: 1.0000 - val_loss: 0.6892 - val_acc: 0.8330\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 9s 431us/sample - loss: 3.2790e-04 - acc: 1.0000 - val_loss: 0.7144 - val_acc: 0.8320\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 9s 440us/sample - loss: 2.1980e-04 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.8328\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 9s 431us/sample - loss: 1.4986e-04 - acc: 1.0000 - val_loss: 0.7683 - val_acc: 0.8338\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 9s 433us/sample - loss: 1.0293e-04 - acc: 1.0000 - val_loss: 0.7963 - val_acc: 0.8340\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 9s 439us/sample - loss: 7.1537e-05 - acc: 1.0000 - val_loss: 0.8215 - val_acc: 0.8340\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 9s 443us/sample - loss: 4.8948e-05 - acc: 1.0000 - val_loss: 0.8482 - val_acc: 0.8340\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 9s 438us/sample - loss: 3.4167e-05 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.8346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 9s 427us/sample - loss: 2.3527e-05 - acc: 1.0000 - val_loss: 0.9010 - val_acc: 0.8348\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 8s 425us/sample - loss: 1.6373e-05 - acc: 1.0000 - val_loss: 0.9338 - val_acc: 0.8332\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 9s 431us/sample - loss: 1.1541e-05 - acc: 1.0000 - val_loss: 0.9550 - val_acc: 0.8358\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 9s 427us/sample - loss: 8.0995e-06 - acc: 1.0000 - val_loss: 0.9806 - val_acc: 0.8360\n",
      "25000/25000 [==============================] - 1s 50us/sample - loss: 0.9866 - acc: 0.8334\n",
      "[0.9866413041234017, 0.8334]\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_77 (Embedding)     (None, 200, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 196, 100)          100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 39, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 3900)              0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 1)                 3901      \n",
      "=================================================================\n",
      "Total params: 2,104,001\n",
      "Trainable params: 2,104,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 10s 480us/sample - loss: 0.6005 - acc: 0.6467 - val_loss: 0.3937 - val_acc: 0.8232\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 10s 485us/sample - loss: 0.2711 - acc: 0.8895 - val_loss: 0.3135 - val_acc: 0.8684\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 10s 481us/sample - loss: 0.1252 - acc: 0.9553 - val_loss: 0.3426 - val_acc: 0.8686\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 10s 480us/sample - loss: 0.0363 - acc: 0.9913 - val_loss: 0.4077 - val_acc: 0.8678\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 10s 487us/sample - loss: 0.0081 - acc: 0.9995 - val_loss: 0.4736 - val_acc: 0.8714\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 10s 477us/sample - loss: 0.0022 - acc: 0.9999 - val_loss: 0.5101 - val_acc: 0.8690\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 10s 482us/sample - loss: 9.7151e-04 - acc: 1.0000 - val_loss: 0.5401 - val_acc: 0.8696\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 10s 488us/sample - loss: 5.6209e-04 - acc: 1.0000 - val_loss: 0.5681 - val_acc: 0.8704\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 10s 487us/sample - loss: 3.5758e-04 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.8718\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 10s 481us/sample - loss: 2.3631e-04 - acc: 1.0000 - val_loss: 0.6162 - val_acc: 0.8712\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 10s 489us/sample - loss: 1.6021e-04 - acc: 1.0000 - val_loss: 0.6402 - val_acc: 0.8714\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 10s 480us/sample - loss: 1.0950e-04 - acc: 1.0000 - val_loss: 0.6646 - val_acc: 0.8708\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 10s 485us/sample - loss: 7.5219e-05 - acc: 1.0000 - val_loss: 0.6865 - val_acc: 0.8718\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 10s 482us/sample - loss: 5.1756e-05 - acc: 1.0000 - val_loss: 0.7112 - val_acc: 0.8706\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 9s 473us/sample - loss: 3.5846e-05 - acc: 1.0000 - val_loss: 0.7366 - val_acc: 0.8710\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 10s 486us/sample - loss: 2.5008e-05 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 0.8716\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 10s 487us/sample - loss: 1.7302e-05 - acc: 1.0000 - val_loss: 0.7810 - val_acc: 0.8708\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 10s 482us/sample - loss: 1.2183e-05 - acc: 1.0000 - val_loss: 0.8019 - val_acc: 0.8714\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 10s 476us/sample - loss: 8.4484e-06 - acc: 1.0000 - val_loss: 0.8260 - val_acc: 0.8712\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 10s 493us/sample - loss: 5.9470e-06 - acc: 1.0000 - val_loss: 0.8498 - val_acc: 0.8712\n",
      "25000/25000 [==============================] - 2s 77us/sample - loss: 0.8997 - acc: 0.8624\n",
      "[0.8997396158971638, 0.86244]\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_80 (InputLayer)        [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_78 (Embedding)     (None, 300, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 296, 100)          100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 59, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 5900)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 5901      \n",
      "=================================================================\n",
      "Total params: 2,106,001\n",
      "Trainable params: 2,106,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 11s 545us/sample - loss: 0.6116 - acc: 0.6359 - val_loss: 0.3816 - val_acc: 0.8334\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 11s 540us/sample - loss: 0.2692 - acc: 0.8903 - val_loss: 0.2952 - val_acc: 0.8760\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 11s 537us/sample - loss: 0.1292 - acc: 0.9530 - val_loss: 0.3827 - val_acc: 0.8572\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 11s 542us/sample - loss: 0.0408 - acc: 0.9901 - val_loss: 0.3865 - val_acc: 0.8764\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 11s 548us/sample - loss: 0.0098 - acc: 0.9991 - val_loss: 0.4553 - val_acc: 0.8744\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 11s 547us/sample - loss: 0.0026 - acc: 0.9999 - val_loss: 0.5012 - val_acc: 0.8732\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 11s 547us/sample - loss: 9.8726e-04 - acc: 1.0000 - val_loss: 0.5425 - val_acc: 0.8734\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 11s 543us/sample - loss: 5.3147e-04 - acc: 1.0000 - val_loss: 0.5721 - val_acc: 0.8728\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 11s 548us/sample - loss: 3.2984e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.8736\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 11s 545us/sample - loss: 2.1724e-04 - acc: 1.0000 - val_loss: 0.6208 - val_acc: 0.8724\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 11s 547us/sample - loss: 1.4798e-04 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 0.8744\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 11s 548us/sample - loss: 9.9860e-05 - acc: 1.0000 - val_loss: 0.6664 - val_acc: 0.8750\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 11s 547us/sample - loss: 6.9402e-05 - acc: 1.0000 - val_loss: 0.6890 - val_acc: 0.8736\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 11s 542us/sample - loss: 4.7685e-05 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 0.8734\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 11s 546us/sample - loss: 3.3066e-05 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.8744\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 11s 538us/sample - loss: 2.3014e-05 - acc: 1.0000 - val_loss: 0.7552 - val_acc: 0.8750\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 11s 539us/sample - loss: 1.6093e-05 - acc: 1.0000 - val_loss: 0.7788 - val_acc: 0.8742\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 11s 544us/sample - loss: 1.1271e-05 - acc: 1.0000 - val_loss: 0.8000 - val_acc: 0.8736\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 11s 546us/sample - loss: 7.9818e-06 - acc: 1.0000 - val_loss: 0.8222 - val_acc: 0.8736\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 11s 548us/sample - loss: 5.6198e-06 - acc: 1.0000 - val_loss: 0.8434 - val_acc: 0.8752\n",
      "25000/25000 [==============================] - 2s 98us/sample - loss: 0.8867 - acc: 0.8667\n",
      "[0.8867082528761029, 0.86672]\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_81 (InputLayer)        [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_79 (Embedding)     (None, 50, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 46, 100)           150100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 9, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 901       \n",
      "=================================================================\n",
      "Total params: 3,151,001\n",
      "Trainable params: 3,151,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 12s 599us/sample - loss: 0.5918 - acc: 0.6664 - val_loss: 0.4621 - val_acc: 0.7724\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 12s 583us/sample - loss: 0.3171 - acc: 0.8630 - val_loss: 0.4562 - val_acc: 0.7832\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 12s 580us/sample - loss: 0.1260 - acc: 0.9612 - val_loss: 0.5535 - val_acc: 0.7746\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 12s 583us/sample - loss: 0.0281 - acc: 0.9963 - val_loss: 0.6809 - val_acc: 0.7716\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 12s 578us/sample - loss: 0.0054 - acc: 0.9999 - val_loss: 0.7390 - val_acc: 0.7808\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 12s 584us/sample - loss: 0.0024 - acc: 0.9999 - val_loss: 0.7974 - val_acc: 0.7824\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 12s 582us/sample - loss: 9.7042e-04 - acc: 1.0000 - val_loss: 0.8428 - val_acc: 0.7822\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 12s 580us/sample - loss: 5.8953e-04 - acc: 1.0000 - val_loss: 0.8834 - val_acc: 0.7824\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 12s 578us/sample - loss: 3.8345e-04 - acc: 1.0000 - val_loss: 0.9212 - val_acc: 0.7816\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 12s 584us/sample - loss: 2.5945e-04 - acc: 1.0000 - val_loss: 0.9581 - val_acc: 0.7830\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 12s 583us/sample - loss: 1.7696e-04 - acc: 1.0000 - val_loss: 0.9959 - val_acc: 0.7818\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 12s 577us/sample - loss: 1.2159e-04 - acc: 1.0000 - val_loss: 1.0304 - val_acc: 0.7826\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 12s 584us/sample - loss: 8.4078e-05 - acc: 1.0000 - val_loss: 1.0669 - val_acc: 0.7828\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 12s 587us/sample - loss: 5.8191e-05 - acc: 1.0000 - val_loss: 1.1020 - val_acc: 0.7828\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 12s 589us/sample - loss: 4.0808e-05 - acc: 1.0000 - val_loss: 1.1394 - val_acc: 0.7828\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 12s 581us/sample - loss: 2.8308e-05 - acc: 1.0000 - val_loss: 1.1727 - val_acc: 0.7838\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 12s 583us/sample - loss: 1.9808e-05 - acc: 1.0000 - val_loss: 1.2089 - val_acc: 0.7836\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 12s 581us/sample - loss: 1.3927e-05 - acc: 1.0000 - val_loss: 1.2438 - val_acc: 0.7838\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 12s 581us/sample - loss: 9.7974e-06 - acc: 1.0000 - val_loss: 1.2782 - val_acc: 0.7840\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 12s 580us/sample - loss: 6.9301e-06 - acc: 1.0000 - val_loss: 1.3134 - val_acc: 0.7846\n",
      "25000/25000 [==============================] - 1s 47us/sample - loss: 1.2878 - acc: 0.7883\n",
      "[1.2877654028511047, 0.78832]\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_82 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_80 (Embedding)     (None, 100, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 96, 100)           150100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 19, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 1900)              0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 1901      \n",
      "=================================================================\n",
      "Total params: 3,152,001\n",
      "Trainable params: 3,152,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 12s 619us/sample - loss: 0.5945 - acc: 0.6554 - val_loss: 0.4341 - val_acc: 0.7962\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 12s 605us/sample - loss: 0.2755 - acc: 0.8873 - val_loss: 0.3712 - val_acc: 0.8340\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 13s 652us/sample - loss: 0.0995 - acc: 0.9694 - val_loss: 0.4399 - val_acc: 0.8268\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 12s 617us/sample - loss: 0.0200 - acc: 0.9976 - val_loss: 0.5398 - val_acc: 0.8274\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 12s 605us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5786 - val_acc: 0.8332\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 12s 610us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.8348\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 12s 613us/sample - loss: 6.5347e-04 - acc: 1.0000 - val_loss: 0.6522 - val_acc: 0.8366\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 12s 609us/sample - loss: 4.1414e-04 - acc: 1.0000 - val_loss: 0.6797 - val_acc: 0.8370\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 13s 646us/sample - loss: 2.7369e-04 - acc: 1.0000 - val_loss: 0.7105 - val_acc: 0.8366\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 12s 622us/sample - loss: 1.8436e-04 - acc: 1.0000 - val_loss: 0.7316 - val_acc: 0.8368\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 12s 612us/sample - loss: 1.2659e-04 - acc: 1.0000 - val_loss: 0.7563 - val_acc: 0.8370\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 12s 612us/sample - loss: 8.7738e-05 - acc: 1.0000 - val_loss: 0.7783 - val_acc: 0.8380\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 12s 605us/sample - loss: 6.0749e-05 - acc: 1.0000 - val_loss: 0.8033 - val_acc: 0.8398\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 12s 613us/sample - loss: 4.2475e-05 - acc: 1.0000 - val_loss: 0.8294 - val_acc: 0.8376\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 13s 638us/sample - loss: 2.9490e-05 - acc: 1.0000 - val_loss: 0.8548 - val_acc: 0.8374\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 12s 608us/sample - loss: 2.0665e-05 - acc: 1.0000 - val_loss: 0.8802 - val_acc: 0.8380\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 12s 609us/sample - loss: 1.4553e-05 - acc: 1.0000 - val_loss: 0.9046 - val_acc: 0.8386\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 12s 613us/sample - loss: 1.0236e-05 - acc: 1.0000 - val_loss: 0.9277 - val_acc: 0.8394\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 12s 617us/sample - loss: 7.2471e-06 - acc: 1.0000 - val_loss: 0.9507 - val_acc: 0.8382\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 12s 610us/sample - loss: 5.1158e-06 - acc: 1.0000 - val_loss: 0.9807 - val_acc: 0.8384\n",
      "25000/25000 [==============================] - 2s 64us/sample - loss: 0.9930 - acc: 0.8372\n",
      "[0.9929650332391262, 0.8372]\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_81 (Embedding)     (None, 200, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 196, 100)          150100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 39, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 3900)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 3901      \n",
      "=================================================================\n",
      "Total params: 3,154,001\n",
      "Trainable params: 3,154,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 14s 675us/sample - loss: 0.5471 - acc: 0.6940 - val_loss: 0.3854 - val_acc: 0.8276\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 13s 661us/sample - loss: 0.2281 - acc: 0.9113 - val_loss: 0.3175 - val_acc: 0.8706\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 13s 674us/sample - loss: 0.0843 - acc: 0.9743 - val_loss: 0.3974 - val_acc: 0.8554\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 13s 674us/sample - loss: 0.0197 - acc: 0.9963 - val_loss: 0.4344 - val_acc: 0.8738\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 13s 668us/sample - loss: 0.0043 - acc: 0.9997 - val_loss: 0.4859 - val_acc: 0.8730\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 14s 677us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5287 - val_acc: 0.8732\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 14s 682us/sample - loss: 5.8610e-04 - acc: 1.0000 - val_loss: 0.5578 - val_acc: 0.8736\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 14s 675us/sample - loss: 3.5690e-04 - acc: 1.0000 - val_loss: 0.5834 - val_acc: 0.8736\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 13s 672us/sample - loss: 2.3433e-04 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.8742\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 14s 713us/sample - loss: 1.5831e-04 - acc: 1.0000 - val_loss: 0.6314 - val_acc: 0.8736\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 14s 677us/sample - loss: 1.0777e-04 - acc: 1.0000 - val_loss: 0.6543 - val_acc: 0.8734\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 13s 671us/sample - loss: 7.4889e-05 - acc: 1.0000 - val_loss: 0.6762 - val_acc: 0.8736\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 13s 672us/sample - loss: 5.2212e-05 - acc: 1.0000 - val_loss: 0.7004 - val_acc: 0.8732\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 13s 675us/sample - loss: 3.6563e-05 - acc: 1.0000 - val_loss: 0.7198 - val_acc: 0.8738\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 13s 674us/sample - loss: 2.5549e-05 - acc: 1.0000 - val_loss: 0.7424 - val_acc: 0.8722\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 13s 672us/sample - loss: 1.7897e-05 - acc: 1.0000 - val_loss: 0.7641 - val_acc: 0.8732\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 13s 672us/sample - loss: 1.2579e-05 - acc: 1.0000 - val_loss: 0.7847 - val_acc: 0.8738\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 14s 677us/sample - loss: 8.8630e-06 - acc: 1.0000 - val_loss: 0.8066 - val_acc: 0.8734\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 13s 674us/sample - loss: 6.3500e-06 - acc: 1.0000 - val_loss: 0.8287 - val_acc: 0.8736\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 13s 668us/sample - loss: 4.4553e-06 - acc: 1.0000 - val_loss: 0.8518 - val_acc: 0.8730\n",
      "25000/25000 [==============================] - 2s 100us/sample - loss: 0.8726 - acc: 0.8674\n",
      "[0.8726218238801509, 0.8674]\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_84 (InputLayer)        [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_82 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 296, 100)          150100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 59, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 5900)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 5901      \n",
      "=================================================================\n",
      "Total params: 3,156,001\n",
      "Trainable params: 3,156,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 15s 759us/sample - loss: 0.5520 - acc: 0.6854 - val_loss: 0.3694 - val_acc: 0.8390\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 15s 742us/sample - loss: 0.2276 - acc: 0.9101 - val_loss: 0.3166 - val_acc: 0.8696\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 15s 749us/sample - loss: 0.0839 - acc: 0.9721 - val_loss: 0.3461 - val_acc: 0.8760\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 15s 764us/sample - loss: 0.0213 - acc: 0.9959 - val_loss: 0.5081 - val_acc: 0.8564\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 15s 759us/sample - loss: 0.0048 - acc: 0.9995 - val_loss: 0.4951 - val_acc: 0.8770\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 15s 758us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5272 - val_acc: 0.8768\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 15s 759us/sample - loss: 5.3907e-04 - acc: 1.0000 - val_loss: 0.5612 - val_acc: 0.8800\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 15s 758us/sample - loss: 3.2133e-04 - acc: 1.0000 - val_loss: 0.5863 - val_acc: 0.8774\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 15s 763us/sample - loss: 2.0819e-04 - acc: 1.0000 - val_loss: 0.6089 - val_acc: 0.8796\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 15s 763us/sample - loss: 1.4027e-04 - acc: 1.0000 - val_loss: 0.6336 - val_acc: 0.8786\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 15s 754us/sample - loss: 9.6545e-05 - acc: 1.0000 - val_loss: 0.6548 - val_acc: 0.8786\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 15s 759us/sample - loss: 6.6809e-05 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 0.8784\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 15s 761us/sample - loss: 4.6593e-05 - acc: 1.0000 - val_loss: 0.6995 - val_acc: 0.8798\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 15s 759us/sample - loss: 3.2842e-05 - acc: 1.0000 - val_loss: 0.7218 - val_acc: 0.8796\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 15s 761us/sample - loss: 2.3198e-05 - acc: 1.0000 - val_loss: 0.7425 - val_acc: 0.8794\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 15s 769us/sample - loss: 1.6145e-05 - acc: 1.0000 - val_loss: 0.7649 - val_acc: 0.8802\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 15s 755us/sample - loss: 1.1424e-05 - acc: 1.0000 - val_loss: 0.7866 - val_acc: 0.8790\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 15s 768us/sample - loss: 8.1195e-06 - acc: 1.0000 - val_loss: 0.8081 - val_acc: 0.8802\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 15s 754us/sample - loss: 5.7716e-06 - acc: 1.0000 - val_loss: 0.8306 - val_acc: 0.8788\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 15s 766us/sample - loss: 4.0702e-06 - acc: 1.0000 - val_loss: 0.8510 - val_acc: 0.8798\n",
      "25000/25000 [==============================] - 3s 128us/sample - loss: 0.8862 - acc: 0.8708\n",
      "[0.8861766931322217, 0.87084]\n"
     ]
    }
   ],
   "source": [
    "res = train_combination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_3d(np.asarray(res))\n",
    "\n",
    "# The longer max sequence length is, the more accuracy we can achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Sentiment Analysis with `LSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000\n",
    "MAX_SEQUENCE_LEN = 300\n",
    "EMBEDDED_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000, 300)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    1   14\n",
      "   22   16   43  530  973 1622 1385   65  458 4468   66 3941    4  173\n",
      "   36  256    5   25  100   43  838  112   50  670    2    9   35  480\n",
      "  284    5  150    4  172  112  167    2  336  385   39    4  172 4536\n",
      " 1111   17  546   38   13  447    4  192   50   16    6  147 2025   19\n",
      "   14   22    4 1920 4613  469    4   22   71   87   12   16   43  530\n",
      "   38   76   15   13 1247    4   22   17  515   17   12   16  626   18\n",
      "    2    5   62  386   12    8  316    8  106    5    4 2223 5244   16\n",
      "  480   66 3785   33    4  130   12   16   38  619    5   25  124   51\n",
      "   36  135   48   25 1415   33    6   22   12  215   28   77   52    5\n",
      "   14  407   16   82    2    8    4  107  117 5952   15  256    4    2\n",
      "    7 3766    5  723   36   71   43  530  476   26  400  317   46    7\n",
      "    4    2 1029   13  104   88    4  381   15  297   98   32 2071   56\n",
      "   26  141    6  194 7486   18    4  226   22   21  134  476   26  480\n",
      "    5  144   30 5535   18   51   36   28  224   92   25  104    4  226\n",
      "   65   16   38 1334   88   12   16  283    5   16 4472  113  103   32\n",
      "   15   16 5345   19  178   32]\n"
     ]
    }
   ],
   "source": [
    "# Load imdb dataset and print a few samples to check.\n",
    "#\n",
    "# IMDB: sentence (x) -> positive/negative (y)\n",
    "#\n",
    "# “The food was really good” \t\t\t\t -> pos\n",
    "# “The chicken crossed the road because it was uncooked” -> neg\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)\n",
    "\n",
    "# x_train has a size (training_size, ). Because the sentences have variable size,\n",
    "# we cannot represent this in matrix format.\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "# The first step is to make the column size constant.\n",
    "#\n",
    "# We do that by \"padding\" the sentences. If the sentences are bigger, we clip them.\n",
    "# If they are smaller, we insert a \"NO_WORD\" token to the sentence.\n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=MAX_SEQUENCE_LEN)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=MAX_SEQUENCE_LEN)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "# Let's see the first sentence\n",
    "\n",
    "print(x_train[0])\n",
    "\n",
    "# Input shape should be now (training_size, MAX_SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*“The chicken crossed the road because it was uncooked”*\n",
    "\n",
    "```\n",
    "h0 -> The \t\t-> h1\n",
    "h1 -> chicken \t-> h2\n",
    "h2 -> crossed \t-> h3\n",
    "h3 -> the \t\t-> h4\n",
    "h4 -> road\t\t-> h5\n",
    "h5 -> because\t\t-> h6\n",
    "h6 -> it\t\t-> h7\n",
    "h7 -> was\t\t-> h8\n",
    "h8 -> uncooked\t-> h9\n",
    "h9 -> pos\n",
    "```\n",
    "\n",
    "`return_sequences`: Boolean. Whether to return the last output in the output\n",
    "    sequence, or the full sequence.\n",
    "`return_state`: Boolean. Whether to return the last state in addition to the\n",
    "    output. The returned elements of the states list are the hidden state\n",
    "    and the cell state, respectively.\n",
    "    \n",
    "> What's the difference between `return_sequences` and `return_state`?\n",
    "\n",
    "`return_sequences` returns the full sequence of output to each input, while `return_state` returns the last state of the hidden state and and the cell state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_weight(embedded_size, max_features):\n",
    "    embeddings_index, embedding_pretrain_size = load_pretrained_embedding_idx(embedded_size)\n",
    "    \n",
    "    assert embedding_pretrain_size >= embedded_size\n",
    "    \n",
    "    return get_embedding_matrix(\n",
    "        imdb.get_word_index(),\n",
    "        embeddings_index,\n",
    "        max_features,\n",
    "        embedded_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embedding_idx(dimension):\n",
    "    assert dimension in [50, 100, 200, 300]\n",
    "    CURR_DIR   = os.getcwd()\n",
    "    PRETRAINED = 'glove.6B.%dd.txt' % dimension\n",
    "#     PRETRAINED = 'glove.42B.%dd.txt' % dimension\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    \n",
    "    with open(os.path.join(CURR_DIR, PRETRAINED), \"r\") as fd:\n",
    "        for line in fd:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        \n",
    "    return embeddings_index, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(word_index, embeddings_index, max_features, embedded_size):\n",
    "    embedding_matrix = np.zeros((max_features, embedded_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `LSTM` to classify sentence as positive or negative\n",
    "\n",
    "Try to get accuracy on validation set over 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_imdb_sentiment_lstm(\n",
    "    max_sequence_len=300,\n",
    "    embedded_size=300,\n",
    "    weights=None,\n",
    "    use_weight=False):\n",
    "    MAX_FEATURES = 10000\n",
    "    \n",
    "    if use_weight and weights is None:\n",
    "        weights = get_embedding_weight(embedded_size, MAX_FEATURES)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)\n",
    "    \n",
    "    x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=max_sequence_len)\n",
    "    x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=max_sequence_len)\n",
    "\n",
    "    \n",
    "    xi = Input(max_sequence_len)\n",
    "\n",
    "    if use_weight:\n",
    "        x = Embedding(MAX_FEATURES, embedded_size, input_length=max_sequence_len,\n",
    "              weights=[weights])(xi)\n",
    "    else:\n",
    "        x = Embedding(MAX_FEATURES, embedded_size, input_length=max_sequence_len)(xi)\n",
    "\n",
    "    x = Conv1D(300, 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "\n",
    "    x = LSTM(280, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "    x = LSTM(160, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "    x = LSTM(50, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=xi, outputs=x)\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0008, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "            x_train, y_train, epochs=20, batch_size=32, validation_split=0.2,\n",
    "            workers=(multiprocessing.cpu_count() - 1), use_multiprocessing=True)\n",
    "\n",
    "    evalutation = model.evaluate(x_test, y_test,\n",
    "                                 workers=(multiprocessing.cpu_count() - 1),\n",
    "                                 use_multiprocessing=True)\n",
    "    print(evalutation)\n",
    "    return evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_combination():\n",
    "    MAX_FEATURES = 10000\n",
    "\n",
    "    result = []\n",
    "    for embedded_size in [50, 100, 200, 300]:\n",
    "        for max_sequence_len in [50, 100, 200, 300]:\n",
    "            _, accuracy = analyze_imdb_sentiment_lstm(max_sequence_len, embedded_size)\n",
    "            result.append((embedded_size, max_sequence_len, accuracy))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(data):\n",
    "    ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "    ax.scatter(\n",
    "        xs=data[:,0], \n",
    "        ys=data[:,1], \n",
    "        zs=data[:,2], \n",
    "        c=data[:,1], \n",
    "        cmap='tab10'\n",
    "    )\n",
    "    ax.set_xlabel(\"Embedded size\")\n",
    "    ax.set_ylabel(\"Max sequence length\")\n",
    "    ax.set_zlabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_166\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_193 (InputLayer)       [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_176 (Embedding)    (None, 50, 50)            500000    \n",
      "_________________________________________________________________\n",
      "conv1d_221 (Conv1D)          (None, 46, 300)           75300     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_204 (MaxPoolin (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_40 (Spatia (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_292 (LSTM)              (None, 9, 280)            650720    \n",
      "_________________________________________________________________\n",
      "lstm_293 (LSTM)              (None, 9, 160)            282240    \n",
      "_________________________________________________________________\n",
      "lstm_294 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,550,511\n",
      "Trainable params: 1,550,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 0.5190 - acc: 0.7268 - val_loss: 0.4190 - val_acc: 0.8036\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 19s 933us/sample - loss: 0.3383 - acc: 0.8555 - val_loss: 0.4321 - val_acc: 0.8032\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 19s 928us/sample - loss: 0.2488 - acc: 0.9014 - val_loss: 0.4837 - val_acc: 0.7892\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 19s 932us/sample - loss: 0.1607 - acc: 0.9416 - val_loss: 0.5678 - val_acc: 0.7884\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 19s 932us/sample - loss: 0.1012 - acc: 0.9657 - val_loss: 0.6687 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 19s 933us/sample - loss: 0.0615 - acc: 0.9804 - val_loss: 0.8482 - val_acc: 0.7774\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 19s 929us/sample - loss: 0.0472 - acc: 0.9847 - val_loss: 1.0718 - val_acc: 0.7772\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 19s 929us/sample - loss: 0.0358 - acc: 0.9887 - val_loss: 0.9454 - val_acc: 0.7704\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 19s 934us/sample - loss: 0.0313 - acc: 0.9901 - val_loss: 1.1025 - val_acc: 0.7728\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 19s 930us/sample - loss: 0.0229 - acc: 0.9930 - val_loss: 1.1304 - val_acc: 0.7678\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 19s 937us/sample - loss: 0.0199 - acc: 0.9940 - val_loss: 1.1463 - val_acc: 0.7678\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 19s 931us/sample - loss: 0.0163 - acc: 0.9946 - val_loss: 1.2076 - val_acc: 0.7690\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 19s 934us/sample - loss: 0.0171 - acc: 0.9948 - val_loss: 1.2157 - val_acc: 0.7696\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 19s 933us/sample - loss: 0.0128 - acc: 0.9962 - val_loss: 1.3149 - val_acc: 0.7692\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 19s 930us/sample - loss: 0.0105 - acc: 0.9969 - val_loss: 1.2830 - val_acc: 0.7664\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 19s 932us/sample - loss: 0.0141 - acc: 0.9952 - val_loss: 1.1950 - val_acc: 0.7674\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 19s 931us/sample - loss: 0.0118 - acc: 0.9961 - val_loss: 1.3706 - val_acc: 0.7640\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 19s 938us/sample - loss: 0.0086 - acc: 0.9970 - val_loss: 1.4077 - val_acc: 0.7650\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 19s 930us/sample - loss: 0.0084 - acc: 0.9972 - val_loss: 1.3811 - val_acc: 0.7684\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 19s 937us/sample - loss: 0.0096 - acc: 0.9966 - val_loss: 1.3653 - val_acc: 0.7688\n",
      "25000/25000 [==============================] - 6s 220us/sample - loss: 1.3709 - acc: 0.7663\n",
      "[1.3708673338127135, 0.76628]\n",
      "Model: \"model_167\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_194 (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_177 (Embedding)    (None, 100, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_222 (Conv1D)          (None, 96, 300)           75300     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_205 (MaxPoolin (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_41 (Spatia (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_295 (LSTM)              (None, 19, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_296 (LSTM)              (None, 19, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_297 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,550,511\n",
      "Trainable params: 1,550,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 38s 2ms/sample - loss: 0.4689 - acc: 0.7587 - val_loss: 0.3427 - val_acc: 0.8460\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.2764 - acc: 0.8892 - val_loss: 0.3461 - val_acc: 0.8480\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.1887 - acc: 0.9324 - val_loss: 0.3889 - val_acc: 0.8368\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.1237 - acc: 0.9571 - val_loss: 0.5108 - val_acc: 0.8394\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0800 - acc: 0.9736 - val_loss: 0.5377 - val_acc: 0.8362\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0578 - acc: 0.9814 - val_loss: 0.6448 - val_acc: 0.8238\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0439 - acc: 0.9869 - val_loss: 0.6594 - val_acc: 0.8334\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0368 - acc: 0.9892 - val_loss: 0.6735 - val_acc: 0.8342\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0244 - acc: 0.9930 - val_loss: 0.7749 - val_acc: 0.8326\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0260 - acc: 0.9926 - val_loss: 0.6996 - val_acc: 0.8274\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0234 - acc: 0.9929 - val_loss: 0.7786 - val_acc: 0.8310\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0207 - acc: 0.9937 - val_loss: 0.8305 - val_acc: 0.8236\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0179 - acc: 0.9951 - val_loss: 0.8978 - val_acc: 0.8230\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0142 - acc: 0.9962 - val_loss: 0.8902 - val_acc: 0.8304\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0133 - acc: 0.9966 - val_loss: 0.8371 - val_acc: 0.8290\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0133 - acc: 0.9960 - val_loss: 0.8119 - val_acc: 0.8314\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0100 - acc: 0.9974 - val_loss: 0.9351 - val_acc: 0.8270\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0113 - acc: 0.9969 - val_loss: 0.9100 - val_acc: 0.8304\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0128 - acc: 0.9967 - val_loss: 0.8779 - val_acc: 0.8282\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 34s 2ms/sample - loss: 0.0107 - acc: 0.9966 - val_loss: 0.8754 - val_acc: 0.8268\n",
      "25000/25000 [==============================] - 10s 391us/sample - loss: 0.9273 - acc: 0.8159\n",
      "[0.9272799806284905, 0.81588]\n",
      "Model: \"model_168\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_195 (InputLayer)       [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_178 (Embedding)    (None, 200, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_223 (Conv1D)          (None, 196, 300)          75300     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_206 (MaxPoolin (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_42 (Spatia (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_298 (LSTM)              (None, 39, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_299 (LSTM)              (None, 39, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_300 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,550,511\n",
      "Trainable params: 1,550,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 67s 3ms/sample - loss: 0.4468 - acc: 0.7659 - val_loss: 0.3128 - val_acc: 0.8658\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.2405 - acc: 0.9093 - val_loss: 0.3047 - val_acc: 0.8792\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 63s 3ms/sample - loss: 0.1666 - acc: 0.9396 - val_loss: 0.3292 - val_acc: 0.8808\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.1124 - acc: 0.9611 - val_loss: 0.3666 - val_acc: 0.8748\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0739 - acc: 0.9761 - val_loss: 0.4421 - val_acc: 0.8656\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0561 - acc: 0.9816 - val_loss: 0.4545 - val_acc: 0.8704\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0461 - acc: 0.9852 - val_loss: 0.4619 - val_acc: 0.8696\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0322 - acc: 0.9904 - val_loss: 0.5789 - val_acc: 0.8672\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0286 - acc: 0.9914 - val_loss: 0.5517 - val_acc: 0.8674\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0242 - acc: 0.9930 - val_loss: 0.6056 - val_acc: 0.8664\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0207 - acc: 0.9938 - val_loss: 0.5813 - val_acc: 0.8620\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0184 - acc: 0.9943 - val_loss: 0.6108 - val_acc: 0.8574\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0180 - acc: 0.9945 - val_loss: 0.6747 - val_acc: 0.8610\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0149 - acc: 0.9959 - val_loss: 0.7449 - val_acc: 0.8560\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0148 - acc: 0.9956 - val_loss: 0.6979 - val_acc: 0.8620\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0144 - acc: 0.9958 - val_loss: 0.6868 - val_acc: 0.8592\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0136 - acc: 0.9961 - val_loss: 0.6827 - val_acc: 0.8602\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.7119 - val_acc: 0.8568\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0103 - acc: 0.9972 - val_loss: 0.7427 - val_acc: 0.8600\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 64s 3ms/sample - loss: 0.0082 - acc: 0.9979 - val_loss: 0.7521 - val_acc: 0.8526\n",
      "25000/25000 [==============================] - 18s 730us/sample - loss: 0.8092 - acc: 0.8441\n",
      "[0.8091854886984825, 0.84412]\n",
      "Model: \"model_169\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_196 (InputLayer)       [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_179 (Embedding)    (None, 300, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_224 (Conv1D)          (None, 296, 300)          75300     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_207 (MaxPoolin (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_43 (Spatia (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_301 (LSTM)              (None, 59, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_302 (LSTM)              (None, 59, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_303 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,550,511\n",
      "Trainable params: 1,550,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 99s 5ms/sample - loss: 0.4351 - acc: 0.7784 - val_loss: 0.2991 - val_acc: 0.8776\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.2306 - acc: 0.9120 - val_loss: 0.3039 - val_acc: 0.8830\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 96s 5ms/sample - loss: 0.1633 - acc: 0.9398 - val_loss: 0.3017 - val_acc: 0.8816\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 96s 5ms/sample - loss: 0.1090 - acc: 0.9619 - val_loss: 0.3611 - val_acc: 0.8808\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0771 - acc: 0.9739 - val_loss: 0.4389 - val_acc: 0.8694\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 96s 5ms/sample - loss: 0.0574 - acc: 0.9811 - val_loss: 0.5019 - val_acc: 0.8696\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 96s 5ms/sample - loss: 0.0409 - acc: 0.9880 - val_loss: 0.4642 - val_acc: 0.8674\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 96s 5ms/sample - loss: 0.0343 - acc: 0.9898 - val_loss: 0.5180 - val_acc: 0.8690\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0251 - acc: 0.9932 - val_loss: 0.6113 - val_acc: 0.8672\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0262 - acc: 0.9924 - val_loss: 0.5662 - val_acc: 0.8704\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 97s 5ms/sample - loss: 0.0225 - acc: 0.9931 - val_loss: 0.5820 - val_acc: 0.8680\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0212 - acc: 0.9942 - val_loss: 0.6080 - val_acc: 0.8666\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0187 - acc: 0.9947 - val_loss: 0.6208 - val_acc: 0.8670\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0166 - acc: 0.9961 - val_loss: 0.6090 - val_acc: 0.8662\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 96s 5ms/sample - loss: 0.0153 - acc: 0.9959 - val_loss: 0.6817 - val_acc: 0.8662\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0192 - acc: 0.9943 - val_loss: 0.5768 - val_acc: 0.8656\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0171 - acc: 0.9955 - val_loss: 0.7409 - val_acc: 0.8542\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0139 - acc: 0.9962 - val_loss: 0.6210 - val_acc: 0.8670\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0121 - acc: 0.9969 - val_loss: 0.6962 - val_acc: 0.8672\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 95s 5ms/sample - loss: 0.0134 - acc: 0.9966 - val_loss: 0.6788 - val_acc: 0.8684\n",
      "25000/25000 [==============================] - 26s 1ms/sample - loss: 0.7675 - acc: 0.85037s - loss: 0.7759 - acc: 0. - ETA: 6s - ET\n",
      "[0.7674561729669571, 0.85032]\n",
      "Model: \"model_170\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_197 (InputLayer)       [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_180 (Embedding)    (None, 50, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_225 (Conv1D)          (None, 46, 300)           150300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_208 (MaxPoolin (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_44 (Spatia (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_304 (LSTM)              (None, 9, 280)            650720    \n",
      "_________________________________________________________________\n",
      "lstm_305 (LSTM)              (None, 9, 160)            282240    \n",
      "_________________________________________________________________\n",
      "lstm_306 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,125,511\n",
      "Trainable params: 2,125,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.5076 - acc: 0.7379 - val_loss: 0.4210 - val_acc: 0.7960\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.3301 - acc: 0.8593 - val_loss: 0.4209 - val_acc: 0.7968\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.2241 - acc: 0.9133 - val_loss: 0.4900 - val_acc: 0.7952\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.1343 - acc: 0.9524 - val_loss: 0.5788 - val_acc: 0.7856\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0795 - acc: 0.9736 - val_loss: 0.7905 - val_acc: 0.7752\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0518 - acc: 0.9829 - val_loss: 0.8601 - val_acc: 0.7722\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0389 - acc: 0.9870 - val_loss: 0.8932 - val_acc: 0.7766\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0294 - acc: 0.9906 - val_loss: 1.0850 - val_acc: 0.7626\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0241 - acc: 0.9912 - val_loss: 1.1043 - val_acc: 0.7736\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0204 - acc: 0.9937 - val_loss: 1.0852 - val_acc: 0.7752\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0196 - acc: 0.9934 - val_loss: 1.1582 - val_acc: 0.7784\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0169 - acc: 0.9943 - val_loss: 1.1680 - val_acc: 0.7726\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0134 - acc: 0.9951 - val_loss: 1.2508 - val_acc: 0.7732\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0126 - acc: 0.9956 - val_loss: 1.2614 - val_acc: 0.7744\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0118 - acc: 0.9962 - val_loss: 1.2906 - val_acc: 0.7740\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0104 - acc: 0.9966 - val_loss: 1.2879 - val_acc: 0.7716\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0081 - acc: 0.9970 - val_loss: 1.3764 - val_acc: 0.7734\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0098 - acc: 0.9967 - val_loss: 1.4142 - val_acc: 0.7638\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0098 - acc: 0.9969 - val_loss: 1.3056 - val_acc: 0.7718\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.0093 - acc: 0.9965 - val_loss: 1.4266 - val_acc: 0.7662\n",
      "25000/25000 [==============================] - 5s 216us/sample - loss: 1.4242 - acc: 0.7676\n",
      "[1.4241949852657318, 0.76756]\n",
      "Model: \"model_171\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_198 (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_181 (Embedding)    (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_226 (Conv1D)          (None, 96, 300)           150300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_209 (MaxPoolin (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_45 (Spatia (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_307 (LSTM)              (None, 19, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_308 (LSTM)              (None, 19, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_309 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,125,511\n",
      "Trainable params: 2,125,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.4512 - acc: 0.7759 - val_loss: 0.3584 - val_acc: 0.8458\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.2666 - acc: 0.8932 - val_loss: 0.3444 - val_acc: 0.8432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.1768 - acc: 0.9352 - val_loss: 0.4247 - val_acc: 0.8404\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.1175 - acc: 0.9588 - val_loss: 0.4663 - val_acc: 0.8418\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0737 - acc: 0.9762 - val_loss: 0.5776 - val_acc: 0.8288\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0486 - acc: 0.9854 - val_loss: 0.5726 - val_acc: 0.8370\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0423 - acc: 0.9878 - val_loss: 0.6143 - val_acc: 0.8318\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0329 - acc: 0.9892 - val_loss: 0.7393 - val_acc: 0.8318\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0285 - acc: 0.9912 - val_loss: 0.7916 - val_acc: 0.8320\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0223 - acc: 0.9937 - val_loss: 0.7635 - val_acc: 0.8320\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0197 - acc: 0.9941 - val_loss: 0.7539 - val_acc: 0.8330\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0148 - acc: 0.9962 - val_loss: 0.7933 - val_acc: 0.8338\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0190 - acc: 0.9947 - val_loss: 0.7858 - val_acc: 0.8318\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0168 - acc: 0.9952 - val_loss: 0.8667 - val_acc: 0.8352\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0130 - acc: 0.9963 - val_loss: 0.8336 - val_acc: 0.8328\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0119 - acc: 0.9962 - val_loss: 0.9231 - val_acc: 0.8350\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0096 - acc: 0.9974 - val_loss: 1.0000 - val_acc: 0.8300\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0104 - acc: 0.9970 - val_loss: 0.9871 - val_acc: 0.8262\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0096 - acc: 0.9972 - val_loss: 1.0518 - val_acc: 0.8254\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 36s 2ms/sample - loss: 0.0102 - acc: 0.9966 - val_loss: 0.8785 - val_acc: 0.8268\n",
      "25000/25000 [==============================] - 10s 400us/sample - loss: 0.9515 - acc: 0.8156\n",
      "[0.9515400560104847, 0.8156]\n",
      "Model: \"model_172\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_199 (InputLayer)       [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_182 (Embedding)    (None, 200, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_227 (Conv1D)          (None, 196, 300)          150300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_210 (MaxPoolin (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_46 (Spatia (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_310 (LSTM)              (None, 39, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_311 (LSTM)              (None, 39, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_312 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,125,511\n",
      "Trainable params: 2,125,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 70s 3ms/sample - loss: 0.4293 - acc: 0.7927 - val_loss: 0.3234 - val_acc: 0.8670\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.2339 - acc: 0.9123 - val_loss: 0.3240 - val_acc: 0.8648\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.1599 - acc: 0.9427 - val_loss: 0.3086 - val_acc: 0.8844\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.1031 - acc: 0.9646 - val_loss: 0.3547 - val_acc: 0.8700\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0714 - acc: 0.9773 - val_loss: 0.4293 - val_acc: 0.8730\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0510 - acc: 0.9840 - val_loss: 0.5085 - val_acc: 0.8674\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0382 - acc: 0.9885 - val_loss: 0.5319 - val_acc: 0.8670\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0321 - acc: 0.9899 - val_loss: 0.5192 - val_acc: 0.8630\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0280 - acc: 0.9916 - val_loss: 0.6297 - val_acc: 0.8532\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0213 - acc: 0.9940 - val_loss: 0.6086 - val_acc: 0.8606\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0202 - acc: 0.9941 - val_loss: 0.6466 - val_acc: 0.8696\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0152 - acc: 0.9957 - val_loss: 0.6256 - val_acc: 0.8666\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0176 - acc: 0.9944 - val_loss: 0.6083 - val_acc: 0.8622\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0185 - acc: 0.9944 - val_loss: 0.6151 - val_acc: 0.8630\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0140 - acc: 0.9958 - val_loss: 0.6788 - val_acc: 0.8646\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0115 - acc: 0.9963 - val_loss: 0.6775 - val_acc: 0.8716\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0087 - acc: 0.9976 - val_loss: 0.6925 - val_acc: 0.8640\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0119 - acc: 0.9965 - val_loss: 0.7432 - val_acc: 0.8608\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0091 - acc: 0.9976 - val_loss: 0.7322 - val_acc: 0.8692\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 66s 3ms/sample - loss: 0.0098 - acc: 0.9972 - val_loss: 0.6810 - val_acc: 0.8668\n",
      "25000/25000 [==============================] - 18s 733us/sample - loss: 0.7556 - acc: 0.8511\n",
      "[0.7555706629800797, 0.85112]\n",
      "Model: \"model_173\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_200 (InputLayer)       [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_183 (Embedding)    (None, 300, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_228 (Conv1D)          (None, 296, 300)          150300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_211 (MaxPoolin (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_47 (Spatia (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_313 (LSTM)              (None, 59, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_314 (LSTM)              (None, 59, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_315 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,125,511\n",
      "Trainable params: 2,125,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 101s 5ms/sample - loss: 0.4207 - acc: 0.7934 - val_loss: 0.2782 - val_acc: 0.8908\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.2293 - acc: 0.9115 - val_loss: 0.2855 - val_acc: 0.8850\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.1585 - acc: 0.9439 - val_loss: 0.3067 - val_acc: 0.8824\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.1030 - acc: 0.9645 - val_loss: 0.3348 - val_acc: 0.8790\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 99s 5ms/sample - loss: 0.0706 - acc: 0.9769 - val_loss: 0.4619 - val_acc: 0.8656\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0496 - acc: 0.9847 - val_loss: 0.4407 - val_acc: 0.8776\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0403 - acc: 0.9883 - val_loss: 0.4626 - val_acc: 0.8760\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 97s 5ms/sample - loss: 0.0353 - acc: 0.9895 - val_loss: 0.5335 - val_acc: 0.8640\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0252 - acc: 0.9931 - val_loss: 0.5288 - val_acc: 0.8740\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0240 - acc: 0.9922 - val_loss: 0.5129 - val_acc: 0.8698\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 97s 5ms/sample - loss: 0.0213 - acc: 0.9931 - val_loss: 0.6519 - val_acc: 0.8666\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0177 - acc: 0.9945 - val_loss: 0.6912 - val_acc: 0.8664\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0196 - acc: 0.9937 - val_loss: 0.6073 - val_acc: 0.8712\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0168 - acc: 0.9952 - val_loss: 0.6295 - val_acc: 0.8722\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0126 - acc: 0.9963 - val_loss: 0.6232 - val_acc: 0.8668\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0110 - acc: 0.9969 - val_loss: 0.6426 - val_acc: 0.8734\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 99s 5ms/sample - loss: 0.0120 - acc: 0.9969 - val_loss: 0.6902 - val_acc: 0.8714\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0151 - acc: 0.9956 - val_loss: 0.5920 - val_acc: 0.8680\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0137 - acc: 0.9965 - val_loss: 0.6638 - val_acc: 0.8728\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 98s 5ms/sample - loss: 0.0134 - acc: 0.9967 - val_loss: 0.6728 - val_acc: 0.8694\n",
      "25000/25000 [==============================] - 27s 1ms/sample - loss: 0.7622 - acc: 0.84961s \n",
      "[0.7621892728865146, 0.8496]\n",
      "Model: \"model_174\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_201 (InputLayer)       [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_184 (Embedding)    (None, 50, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_229 (Conv1D)          (None, 46, 300)           300300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_212 (MaxPoolin (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_48 (Spatia (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_316 (LSTM)              (None, 9, 280)            650720    \n",
      "_________________________________________________________________\n",
      "lstm_317 (LSTM)              (None, 9, 160)            282240    \n",
      "_________________________________________________________________\n",
      "lstm_318 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,275,511\n",
      "Trainable params: 3,275,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.5041 - acc: 0.7430 - val_loss: 0.4168 - val_acc: 0.8032\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.3271 - acc: 0.8627 - val_loss: 0.4608 - val_acc: 0.7994\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.2155 - acc: 0.9165 - val_loss: 0.5250 - val_acc: 0.7964\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.1261 - acc: 0.9566 - val_loss: 0.6588 - val_acc: 0.7896\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0779 - acc: 0.9746 - val_loss: 0.7265 - val_acc: 0.7830\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0562 - acc: 0.9809 - val_loss: 0.8873 - val_acc: 0.7720\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0374 - acc: 0.9887 - val_loss: 0.9095 - val_acc: 0.7742\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0327 - acc: 0.9895 - val_loss: 0.9107 - val_acc: 0.7810\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0247 - acc: 0.9920 - val_loss: 0.9927 - val_acc: 0.7762\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0189 - acc: 0.9941 - val_loss: 1.0022 - val_acc: 0.7814\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0220 - acc: 0.9934 - val_loss: 1.0652 - val_acc: 0.7726\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0200 - acc: 0.9934 - val_loss: 1.0943 - val_acc: 0.7800\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0178 - acc: 0.9942 - val_loss: 1.1324 - val_acc: 0.7794\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0132 - acc: 0.9959 - val_loss: 1.2536 - val_acc: 0.7802\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0156 - acc: 0.9941 - val_loss: 1.2123 - val_acc: 0.7746\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0129 - acc: 0.9956 - val_loss: 1.2207 - val_acc: 0.7780\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0104 - acc: 0.9972 - val_loss: 1.2113 - val_acc: 0.7804\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0088 - acc: 0.9973 - val_loss: 1.3346 - val_acc: 0.7810\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0127 - acc: 0.9958 - val_loss: 1.2595 - val_acc: 0.7804\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.0084 - acc: 0.9970 - val_loss: 1.2829 - val_acc: 0.7788\n",
      "25000/25000 [==============================] - 6s 223us/sample - loss: 1.3147 - acc: 0.7708\n",
      "[1.3146631081652642, 0.7708]\n",
      "Model: \"model_175\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_202 (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_185 (Embedding)    (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_230 (Conv1D)          (None, 96, 300)           300300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_213 (MaxPoolin (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_49 (Spatia (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_319 (LSTM)              (None, 19, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_320 (LSTM)              (None, 19, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_321 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,275,511\n",
      "Trainable params: 3,275,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.4468 - acc: 0.7817 - val_loss: 0.3435 - val_acc: 0.8494\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.2707 - acc: 0.8918 - val_loss: 0.3519 - val_acc: 0.8478\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.1765 - acc: 0.9351 - val_loss: 0.4134 - val_acc: 0.8488\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.1112 - acc: 0.9620 - val_loss: 0.4396 - val_acc: 0.8410\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0685 - acc: 0.9785 - val_loss: 0.5780 - val_acc: 0.8384\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0495 - acc: 0.9848 - val_loss: 0.5655 - val_acc: 0.8352\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0444 - acc: 0.9865 - val_loss: 0.5920 - val_acc: 0.8352\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0289 - acc: 0.9924 - val_loss: 0.6583 - val_acc: 0.8308\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0262 - acc: 0.9918 - val_loss: 0.7480 - val_acc: 0.8250\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0226 - acc: 0.9940 - val_loss: 0.7957 - val_acc: 0.8292\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0177 - acc: 0.9950 - val_loss: 0.8312 - val_acc: 0.8262\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0183 - acc: 0.9945 - val_loss: 0.8514 - val_acc: 0.8242\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0184 - acc: 0.9946 - val_loss: 0.8027 - val_acc: 0.8308\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0164 - acc: 0.9952 - val_loss: 0.8572 - val_acc: 0.8254\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0144 - acc: 0.9955 - val_loss: 0.7507 - val_acc: 0.8316\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0155 - acc: 0.9955 - val_loss: 0.9212 - val_acc: 0.8264\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0114 - acc: 0.9965 - val_loss: 0.9515 - val_acc: 0.8186\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0088 - acc: 0.9976 - val_loss: 0.9504 - val_acc: 0.8298\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.9328 - val_acc: 0.8260\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 1.0991 - val_acc: 0.8240\n",
      "25000/25000 [==============================] - 10s 405us/sample - loss: 1.1392 - acc: 0.8177\n",
      "[1.1391734595526755, 0.81772]\n",
      "Model: \"model_176\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_203 (InputLayer)       [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_186 (Embedding)    (None, 200, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_231 (Conv1D)          (None, 196, 300)          300300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_214 (MaxPoolin (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_50 (Spatia (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_322 (LSTM)              (None, 39, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_323 (LSTM)              (None, 39, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_324 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,275,511\n",
      "Trainable params: 3,275,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 74s 4ms/sample - loss: 0.4076 - acc: 0.8087 - val_loss: 0.2901 - val_acc: 0.8794\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.2225 - acc: 0.9159 - val_loss: 0.2959 - val_acc: 0.8838\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.1482 - acc: 0.9460 - val_loss: 0.3512 - val_acc: 0.8760\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0924 - acc: 0.9681 - val_loss: 0.4186 - val_acc: 0.8688\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0628 - acc: 0.9789 - val_loss: 0.4762 - val_acc: 0.8696\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0455 - acc: 0.9860 - val_loss: 0.4890 - val_acc: 0.8642\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0357 - acc: 0.9898 - val_loss: 0.5949 - val_acc: 0.8612\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0336 - acc: 0.9890 - val_loss: 0.5670 - val_acc: 0.8654\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0253 - acc: 0.9926 - val_loss: 0.5868 - val_acc: 0.8640\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0203 - acc: 0.9947 - val_loss: 0.5480 - val_acc: 0.8632\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0216 - acc: 0.9945 - val_loss: 0.5621 - val_acc: 0.8678\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0213 - acc: 0.9933 - val_loss: 0.5442 - val_acc: 0.8698\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0208 - acc: 0.9937 - val_loss: 0.5929 - val_acc: 0.8660\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0149 - acc: 0.9957 - val_loss: 0.6744 - val_acc: 0.8664\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0155 - acc: 0.9961 - val_loss: 0.6790 - val_acc: 0.8666\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0128 - acc: 0.9969 - val_loss: 0.6347 - val_acc: 0.8684\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0125 - acc: 0.9967 - val_loss: 0.6963 - val_acc: 0.8614\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0146 - acc: 0.9959 - val_loss: 0.6606 - val_acc: 0.8658\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0128 - acc: 0.9966 - val_loss: 0.6813 - val_acc: 0.8660\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 70s 4ms/sample - loss: 0.0123 - acc: 0.9964 - val_loss: 0.6881 - val_acc: 0.8702\n",
      "25000/25000 [==============================] - 19s 745us/sample - loss: 0.8096 - acc: 0.8470\n",
      "[0.8095575129467248, 0.84704]\n",
      "Model: \"model_177\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_204 (InputLayer)       [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_187 (Embedding)    (None, 300, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_232 (Conv1D)          (None, 296, 300)          300300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_215 (MaxPoolin (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_51 (Spatia (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_325 (LSTM)              (None, 59, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_326 (LSTM)              (None, 59, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_327 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,275,511\n",
      "Trainable params: 3,275,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 107s 5ms/sample - loss: 0.4061 - acc: 0.8096 - val_loss: 0.2981 - val_acc: 0.8800\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.2214 - acc: 0.9127 - val_loss: 0.2696 - val_acc: 0.8898\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.1454 - acc: 0.9487 - val_loss: 0.3158 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 104s 5ms/sample - loss: 0.0957 - acc: 0.9675 - val_loss: 0.3786 - val_acc: 0.8782\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0610 - acc: 0.9808 - val_loss: 0.4157 - val_acc: 0.8688\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0446 - acc: 0.9860 - val_loss: 0.4855 - val_acc: 0.8670\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0351 - acc: 0.9897 - val_loss: 0.4512 - val_acc: 0.8742\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 105s 5ms/sample - loss: 0.0286 - acc: 0.9913 - val_loss: 0.5308 - val_acc: 0.8758\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0279 - acc: 0.9912 - val_loss: 0.5939 - val_acc: 0.8652\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0225 - acc: 0.9935 - val_loss: 0.5299 - val_acc: 0.8706\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0216 - acc: 0.9934 - val_loss: 0.5718 - val_acc: 0.8694\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0210 - acc: 0.9942 - val_loss: 0.5708 - val_acc: 0.8662\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0177 - acc: 0.9955 - val_loss: 0.5853 - val_acc: 0.8750\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0194 - acc: 0.9946 - val_loss: 0.6080 - val_acc: 0.8714\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0146 - acc: 0.9959 - val_loss: 0.6452 - val_acc: 0.8732\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0140 - acc: 0.9961 - val_loss: 0.6061 - val_acc: 0.8740\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0146 - acc: 0.9956 - val_loss: 0.6230 - val_acc: 0.8740\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0120 - acc: 0.9970 - val_loss: 0.6689 - val_acc: 0.8754\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0120 - acc: 0.9967 - val_loss: 0.6276 - val_acc: 0.8740\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 103s 5ms/sample - loss: 0.0102 - acc: 0.9977 - val_loss: 0.6957 - val_acc: 0.8658\n",
      "25000/25000 [==============================] - 27s 1ms/sample - loss: 0.7762 - acc: 0.8558\n",
      "[0.7761981345117092, 0.85584]\n",
      "Model: \"model_178\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_205 (InputLayer)       [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_188 (Embedding)    (None, 50, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_233 (Conv1D)          (None, 46, 300)           450300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_216 (MaxPoolin (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_52 (Spatia (None, 9, 300)            0         \n",
      "_________________________________________________________________\n",
      "lstm_328 (LSTM)              (None, 9, 280)            650720    \n",
      "_________________________________________________________________\n",
      "lstm_329 (LSTM)              (None, 9, 160)            282240    \n",
      "_________________________________________________________________\n",
      "lstm_330 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,425,511\n",
      "Trainable params: 4,425,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 33s 2ms/sample - loss: 0.5009 - acc: 0.7408 - val_loss: 0.4129 - val_acc: 0.8116\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.3189 - acc: 0.8655 - val_loss: 0.4277 - val_acc: 0.8060\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.2039 - acc: 0.9204 - val_loss: 0.4880 - val_acc: 0.7972\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.1145 - acc: 0.9592 - val_loss: 0.5694 - val_acc: 0.7940\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0666 - acc: 0.9775 - val_loss: 0.7529 - val_acc: 0.7838\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0498 - acc: 0.9840 - val_loss: 0.8718 - val_acc: 0.7888\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0351 - acc: 0.9888 - val_loss: 1.0036 - val_acc: 0.7760\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0287 - acc: 0.9904 - val_loss: 0.9824 - val_acc: 0.7824\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0239 - acc: 0.9922 - val_loss: 1.0793 - val_acc: 0.7834\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0199 - acc: 0.9930 - val_loss: 1.1362 - val_acc: 0.7780\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0211 - acc: 0.9933 - val_loss: 1.0701 - val_acc: 0.7764\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0174 - acc: 0.9944 - val_loss: 1.2244 - val_acc: 0.7798\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0158 - acc: 0.9946 - val_loss: 1.2493 - val_acc: 0.7760\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0127 - acc: 0.9954 - val_loss: 1.4495 - val_acc: 0.7776\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0105 - acc: 0.9966 - val_loss: 1.2227 - val_acc: 0.7728\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0091 - acc: 0.9966 - val_loss: 1.4708 - val_acc: 0.7756\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0107 - acc: 0.9966 - val_loss: 1.3412 - val_acc: 0.7786\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0117 - acc: 0.9957 - val_loss: 1.3100 - val_acc: 0.7748\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0050 - acc: 0.9985 - val_loss: 1.4867 - val_acc: 0.7786\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 29s 1ms/sample - loss: 0.0133 - acc: 0.9959 - val_loss: 1.2768 - val_acc: 0.7818\n",
      "25000/25000 [==============================] - 6s 228us/sample - loss: 1.3305 - acc: 0.7721\n",
      "[1.3305338656187058, 0.77212]\n",
      "Model: \"model_179\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_206 (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_189 (Embedding)    (None, 100, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_234 (Conv1D)          (None, 96, 300)           450300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_217 (MaxPoolin (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_53 (Spatia (None, 19, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_331 (LSTM)              (None, 19, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_332 (LSTM)              (None, 19, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_333 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,425,511\n",
      "Trainable params: 4,425,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 49s 2ms/sample - loss: 0.4446 - acc: 0.7818 - val_loss: 0.3564 - val_acc: 0.8368\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.2655 - acc: 0.8949 - val_loss: 0.3592 - val_acc: 0.8438\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.1743 - acc: 0.9349 - val_loss: 0.3978 - val_acc: 0.8422\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.1044 - acc: 0.9657 - val_loss: 0.5133 - val_acc: 0.8450\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0664 - acc: 0.9775 - val_loss: 0.5301 - val_acc: 0.8388\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0487 - acc: 0.9843 - val_loss: 0.6089 - val_acc: 0.8364\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0337 - acc: 0.9900 - val_loss: 0.5970 - val_acc: 0.8414\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0324 - acc: 0.9893 - val_loss: 0.6751 - val_acc: 0.8344\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0231 - acc: 0.9931 - val_loss: 0.7969 - val_acc: 0.8296\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0199 - acc: 0.9944 - val_loss: 0.8543 - val_acc: 0.8268\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0169 - acc: 0.9948 - val_loss: 0.9565 - val_acc: 0.8206\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0190 - acc: 0.9935 - val_loss: 0.8705 - val_acc: 0.8226\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0148 - acc: 0.9955 - val_loss: 0.8443 - val_acc: 0.8166\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0132 - acc: 0.9958 - val_loss: 0.8830 - val_acc: 0.8258\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0147 - acc: 0.9948 - val_loss: 0.8986 - val_acc: 0.8244\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0118 - acc: 0.9960 - val_loss: 0.8996 - val_acc: 0.8238\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0100 - acc: 0.9965 - val_loss: 0.9605 - val_acc: 0.8274\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0110 - acc: 0.9965 - val_loss: 1.0026 - val_acc: 0.8234\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0083 - acc: 0.9973 - val_loss: 1.0674 - val_acc: 0.8276\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0087 - acc: 0.9966 - val_loss: 0.9870 - val_acc: 0.8228\n",
      "25000/25000 [==============================] - 10s 413us/sample - loss: 1.0607 - acc: 0.8165\n",
      "[1.0607248132514953, 0.81652]\n",
      "Model: \"model_180\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_207 (InputLayer)       [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_190 (Embedding)    (None, 200, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_235 (Conv1D)          (None, 196, 300)          450300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_218 (MaxPoolin (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_54 (Spatia (None, 39, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_334 (LSTM)              (None, 39, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_335 (LSTM)              (None, 39, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_336 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,425,511\n",
      "Trainable params: 4,425,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 79s 4ms/sample - loss: 0.4123 - acc: 0.8031 - val_loss: 0.2964 - val_acc: 0.8766\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 76s 4ms/sample - loss: 0.2241 - acc: 0.9124 - val_loss: 0.2900 - val_acc: 0.8814\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.1475 - acc: 0.9466 - val_loss: 0.3090 - val_acc: 0.8756\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0927 - acc: 0.9686 - val_loss: 0.3801 - val_acc: 0.8710\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0611 - acc: 0.9796 - val_loss: 0.4003 - val_acc: 0.8692\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 76s 4ms/sample - loss: 0.0446 - acc: 0.9855 - val_loss: 0.5024 - val_acc: 0.8616\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0336 - acc: 0.9898 - val_loss: 0.5270 - val_acc: 0.8692\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0318 - acc: 0.9898 - val_loss: 0.5958 - val_acc: 0.8574\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 77s 4ms/sample - loss: 0.0280 - acc: 0.9908 - val_loss: 0.6619 - val_acc: 0.8498\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 76s 4ms/sample - loss: 0.0210 - acc: 0.9937 - val_loss: 0.6121 - val_acc: 0.8620\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0150 - acc: 0.9954 - val_loss: 0.6111 - val_acc: 0.8690\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 76s 4ms/sample - loss: 0.0159 - acc: 0.9957 - val_loss: 0.5759 - val_acc: 0.8680\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 77s 4ms/sample - loss: 0.0192 - acc: 0.9944 - val_loss: 0.5074 - val_acc: 0.8668\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0136 - acc: 0.9961 - val_loss: 0.6649 - val_acc: 0.8630\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0152 - acc: 0.9952 - val_loss: 0.6499 - val_acc: 0.8640\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0128 - acc: 0.9957 - val_loss: 0.6584 - val_acc: 0.8708\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 86s 4ms/sample - loss: 0.0115 - acc: 0.9964 - val_loss: 0.7089 - val_acc: 0.8658\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 84s 4ms/sample - loss: 0.0114 - acc: 0.9962 - val_loss: 0.6585 - val_acc: 0.8670\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0100 - acc: 0.9972 - val_loss: 0.7796 - val_acc: 0.8610\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 75s 4ms/sample - loss: 0.0088 - acc: 0.9974 - val_loss: 0.6686 - val_acc: 0.8658\n",
      "25000/25000 [==============================] - 19s 762us/sample - loss: 0.7703 - acc: 0.8468\n",
      "[0.7702591914886237, 0.84684]\n",
      "Model: \"model_181\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_208 (InputLayer)       [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_191 (Embedding)    (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_236 (Conv1D)          (None, 296, 300)          450300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_219 (MaxPoolin (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_55 (Spatia (None, 59, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_337 (LSTM)              (None, 59, 280)           650720    \n",
      "_________________________________________________________________\n",
      "lstm_338 (LSTM)              (None, 59, 160)           282240    \n",
      "_________________________________________________________________\n",
      "lstm_339 (LSTM)              (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,425,511\n",
      "Trainable params: 4,425,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 114s 6ms/sample - loss: 0.4188 - acc: 0.8008 - val_loss: 0.2763 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.2213 - acc: 0.9165 - val_loss: 0.2753 - val_acc: 0.8946\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.1458 - acc: 0.9474 - val_loss: 0.3281 - val_acc: 0.8762\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0961 - acc: 0.9669 - val_loss: 0.3237 - val_acc: 0.8816\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0613 - acc: 0.9808 - val_loss: 0.3935 - val_acc: 0.8790\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0457 - acc: 0.9857 - val_loss: 0.4550 - val_acc: 0.8756\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0361 - acc: 0.9898 - val_loss: 0.5093 - val_acc: 0.8768\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0366 - acc: 0.9890 - val_loss: 0.4898 - val_acc: 0.8758\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 109s 5ms/sample - loss: 0.0311 - acc: 0.9916 - val_loss: 0.5207 - val_acc: 0.8786\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0248 - acc: 0.9930 - val_loss: 0.5459 - val_acc: 0.8804\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0224 - acc: 0.9938 - val_loss: 0.4976 - val_acc: 0.8706\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 110s 5ms/sample - loss: 0.0205 - acc: 0.9941 - val_loss: 0.5608 - val_acc: 0.8754\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0179 - acc: 0.9945 - val_loss: 0.5855 - val_acc: 0.8676\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0175 - acc: 0.9955 - val_loss: 0.6523 - val_acc: 0.8652\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0192 - acc: 0.9943 - val_loss: 0.6018 - val_acc: 0.8726\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0130 - acc: 0.9966 - val_loss: 0.6235 - val_acc: 0.8634\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0157 - acc: 0.9959 - val_loss: 0.6115 - val_acc: 0.8714\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0130 - acc: 0.9962 - val_loss: 0.6126 - val_acc: 0.8710\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0103 - acc: 0.9976 - val_loss: 0.6497 - val_acc: 0.8712\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.0098 - acc: 0.9976 - val_loss: 0.6973 - val_acc: 0.8722\n",
      "25000/25000 [==============================] - 28s 1ms/sample - loss: 0.7746 - acc: 0.8581\n",
      "[0.7746091929171235, 0.85812]\n"
     ]
    }
   ],
   "source": [
    "res = train_combination()\n",
    "\n",
    "# The highest validation accuracy we achieved here was 89.46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_3d(np.asarray(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file(\"nietzsche.txt\",\n",
    "        origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "\n",
    "text = open(path).read().lower()\n",
    "print(\"corpus length:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = set(text)\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200265\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"nb sequences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(distinct_chars):\n",
    "    # build the model: 2 stacked GRU\n",
    "    print(\"Build model...\")\n",
    "    xi = Input((maxlen, distinct_chars))\n",
    "    x = GRU(256, return_sequences=True)(xi)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(distinct_chars)(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=xi, outputs=x)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    adam = Adam(0.0003)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=adam)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = (np.log(a + 1e-8) / temperature).astype(np.float64)\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    try:\n",
    "        sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    except ValueError:\n",
    "        error = 1.0 - np.sum(a)\n",
    "        a[0] += error\n",
    "        sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    return sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model):\n",
    "    # train the model, output generated text after each iteration\n",
    "#     for iteration in range(1, 2):\n",
    "    for iteration in range(1, 20):\n",
    "        print()\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Iteration\", iteration)\n",
    "\n",
    "        model.fit(X, y, batch_size=64, epochs=4,\n",
    "                  workers=(multiprocessing.cpu_count() - 1), use_multiprocessing=True)\n",
    "        model.save_weights(\"weights.hdf5\")\n",
    "#         model.load_weights(\"weights.hdf5\")\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print()\n",
    "            print(\"----- diversity:\", diversity)\n",
    "\n",
    "            generated = \"\"\n",
    "            sentence = text[start_index: start_index + maxlen] # Pick a random sentence\n",
    "            generated += sentence\n",
    "\n",
    "            print(\"----- Generating with seed: '\" + sentence + \"'\")\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "    #         for _ in range(200):\n",
    "            for _ in range(200):\n",
    "                x = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                # predict next char\n",
    "                preds = model.predict(x, verbose=0,\n",
    "                                      workers=(multiprocessing.cpu_count() - 1),\n",
    "                                      use_multiprocessing=True)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "#                 print(preds.shape, preds)\n",
    "#                 print(next_index)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                # full sentence being generated\n",
    "                generated += next_char\n",
    "\n",
    "                # shift sentence\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                # let's consider only one sentence\n",
    "                if next_char == \".\":\n",
    "                    break\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100, 57)]         0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 100, 256)          241920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 57)                14649     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 57)                0         \n",
      "=================================================================\n",
      "Total params: 651,321\n",
      "Trainable params: 651,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 277us/sample - loss: 2.3542\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.9862\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 54s 270us/sample - loss: 1.8382\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 54s 270us/sample - loss: 1.7398\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even'\n",
      "lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even the experion of the pressing and streng the condinity of the sure and one man in the extanding the suphing the constite of the individual the inconding and the concession of the consequention of the \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even'\n",
      "lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even the astich and the self be the present the constiture and a stall donation of the still, and consure of the such a proposity and constile man of the onessic and for the finding that the stands of the\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even'\n",
      "lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even at a suren lively place, a fave exir or curtofould on the gemething its ale known instroul deperhard from in interlition that all of consequine, ederulition this esper\n",
      "upocious--anx ave to\n",
      "gonate, a\n",
      "\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even'\n",
      "lecting\" implies--he waits until\n",
      "something comes, and then expands himself sensitively, so that even and uspiremd doun grean externct,--which muloved.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.6662\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.6102\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.5628\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 1.5247\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such '\n",
      "n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such a prosent in the subject of the same to an all the same to all the subject of the morality of the morality in the world of the morality of the supers of the world, the world of the morality in the sup\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such '\n",
      "n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such all thought, and the truth to the stronger and interpreted to all the sound himself to stake the prose of the from all the such a paint in the sprent to all though who soul we stand to him and learn t\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such '\n",
      "n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such a pain in origin, and would divespte over the pastefor about power? but no will i conscience himself depext, in its carnation; and wrot us \"notic or the great ns therefinely with the intivid at gees\n",
      "a\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such '\n",
      "n, in certain circumstances,\n",
      "evil, objects. at any rate, if mankind is not to be led astray by such bubly;\n",
      "perhaps utou.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.4926\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.4623\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 275us/sample - loss: 1.4383\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 57s 285us/sample - loss: 1.4137\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer ab'\n",
      "r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer about the same to be the results and the soul of the sense of the endition of the sense of the same with the same time of the subjection, and all the same will to the strange of the sense of the sense, \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer ab'\n",
      "r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer about the same not be a surponse.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer ab'\n",
      "r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer absorted its own that they learned its with regard to a caiciatin.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer ab'\n",
      "r hard enough either for evil or good, and of a broken will that no\n",
      "longer commands, is no longer abture him.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 270us/sample - loss: 1.3935\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.3756\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.3556\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.3376\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyor'\n",
      " of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyors and all the same time of the same time of the same time of the power of the same time of the problem of the conception of the world, and the sense of the senses of man is a conception, the sense of \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyor'\n",
      " of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyors and purious simply the conceal to the skepticism which is a philosophers and the consequences of his not even the subjection of religious man who it is a complete in the christian in\n",
      "the senses of h\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyor'\n",
      " of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyors, the\n",
      "comparadity, that is the will all the vain and abouter of undivided its may at the will not prexumination are healthes concealed, and what all there is all woman of knows upint eternates, mistr\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyor'\n",
      " of body and soul, as circumnavigators and\n",
      "adventurers of that inner world called \"man\"; as surveyors of the repolters and utility.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200265/200265 [==============================] - 55s 272us/sample - loss: 1.3213\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 274us/sample - loss: 1.3051\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 56s 280us/sample - loss: 1.2898\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 274us/sample - loss: 1.2760\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"'\n",
      " that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"the problem\"--they were the freedom of the strength of the strength, in the same distrust of the subject of self and the same time it is a preservation of the subject of a long so the great man in a c\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"'\n",
      " that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"constituting the stated in his point and the sense, and even in itself in himself and life and in the conscience for its maturations and actions and desires the concealed only possesses, and the respe\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"'\n",
      " that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"the probuas desirned by morals, \"vainty in a clumal, that it is conrequire defined intransially bland to the\n",
      "most defrien outsidg-so anything of the superstits to oursilents.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"'\n",
      " that does not\n",
      "merely \"conserve\"--as the physiologist knows. but at the bottom of our\n",
      "souls, quite \"too, wa to go the good\n",
      "individuals, herfonment, you\n",
      "htades\n",
      "and \"jast.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.2609\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 1.2477\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 54s 270us/sample - loss: 1.2353\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.2233\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses '\n",
      "ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses of the same as the propers and consequently a present dangerous self-deception, and a common in a compless of the place and as i have a retarded as a person strong enough, as a person is a person of t\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses '\n",
      "ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses of a man is not strength he had have to depens and the more perhaps say to attere to have the basis of a sensible enough, as is problem or a chirde man is not to be about the mastery of domain of whic\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses '\n",
      "ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses of toom-firlls\n",
      "deciseds from\n",
      "esseblity or selfishness, be\n",
      "the power, indeed, hitherto also as\n",
      "a\n",
      "revelse of the me nom of \"headronais\", and according to live\n",
      "errorded as for according truths of moral r\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses '\n",
      "ers that got so much out of them. it is among\n",
      "the greatest feats of the men who are called geniuses shoppom, standss.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 270us/sample - loss: 1.2104\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 1.1994\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 1.1883\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 1.1790\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather'\n",
      "ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather is the subject of the present dangerous sense of the state of the strange of the same distrasted and event and consequence to an eariting of the present to the strength of the senses of all the same \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather'\n",
      "ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather as the sense of the german soul of their references of constitutions of the torture in a certain mind, we feel themselves to the same man in the superstition of the philosophy at the sense of the con\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather'\n",
      "ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather in\n",
      "the result of the forgetful man; one is dochure,\n",
      "through\n",
      "the belief in the actor and self-denull, the\n",
      "alopes for has\n",
      "been sopeace indical\n",
      "forly assumpticne, as a condition who has afterhers, it ca\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather'\n",
      "ense) perhaps not be the\n",
      "exception, but the rule?--perhaps genius is by no means so rare: but\n",
      "rather among the primer; also man who sifcle ymere dangerous to\n",
      "anything in\n",
      "renpent, defechizant lyhernousal deasprevia exqeett\n",
      "morality of my society,\n",
      "therefoce\n",
      "his termot prousad,\n",
      "power=--according to hav\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.1682\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.1577\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 275us/sample - loss: 1.1482\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.1369\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n",
      "intuitio'\n",
      "he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n",
      "intuition, and that the same as the same time of the most subjection that it is the best and painful of the most spiritual and his own believe in the standard of man as its way are a great spirits and dogmati\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n",
      "intuitio'\n",
      "he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n",
      "intuition.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n",
      "intuitio'\n",
      "he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n",
      "intuition for immense and after srover and the bus conditional still trut, for what--every ascrutent of the hamament in fact that we do joss units our inveried, should be imbalbable and\n",
      "instinct\n",
      "with all;\n",
      "\"im\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n",
      "intuitio'\n",
      "he \"essence of the\n",
      "cosmos\".[7] we are in the sphere of pure conception. no presentiment [or\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intuitions but even another,\n",
      "even\n",
      "was big\n",
      "its imination of, it is almost able to rigive? xill\n",
      "cuntume, also, comeal of sanly thy bonner.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 275us/sample - loss: 1.1301\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 274us/sample - loss: 1.1178\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 274us/sample - loss: 1.1081\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.1036\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'd \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to ma'\n",
      "d \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to make a sort of self-sacrifice in the same time of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense and self-developing, of contempt.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'd \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to ma'\n",
      "d \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to make use the cause of supreme to this conception of the excessive in the philosopher in the incrined to the greatest species of the type \"friend,\" as the act of his exceptional the contrary.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'd \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to ma'\n",
      "d \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to man find a\n",
      "distages for witnon and\n",
      "underevare age as\n",
      "unofferingn of the personality is the almost divinery which he soul, infinite can nature did the most desidetologed taste of the truth of their means\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'd \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to ma'\n",
      "d \"the rule\" in themselves, and at the\n",
      "same time have so much spirituality and ticklishness as to make imall, becoming incirius of all fact.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.0940\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 1.0856\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 1.0775\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.0704\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that '\n",
      "tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that in the subject of the subject of a sensible for the same decial sense, and the sense of the sense of the subject, man the same wished to an art that the sense of the subject of a long souls of such a \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that '\n",
      "tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that profound in the same way and the sensible of moral process of his fathers and perception, for instance, the art and form of statesman, in the same with which he has always become speake\n",
      "something in t\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that '\n",
      "tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that proposity of\n",
      "the\n",
      "act offer in the loves and assumple that this subject of\n",
      "the\n",
      "fthenesshers are \"natural\":\n",
      "\n",
      "\n",
      "168\n",
      "\n",
      "=the fully and\n",
      "palpleable, because there so\n",
      "geable enough but rather just as they are n\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that '\n",
      "tenment--sensu allegorico, with regard for the\n",
      "comprehension of the masses, give expression to that the dangerous skspacal to me, which, who surdention, even injusting,: \"(a bodn auso: in spire the weakless only to antiliariess; but as in, as in commanding-in the saterity rasos it of the\n",
      "powerful, t\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.0621\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.0541\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.0489\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 1.0399\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things thr'\n",
      "a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things through all the striggle of its senses to a person with the highest sense, as the reason that the most delicate contradiction of the hearts and consequences of a sensible of the world, the great distance\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things thr'\n",
      "a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things through all the rest of the morality which are necessary for the fact that the logical and imperative with the haster of its own self-destinction are the necessary to the good and self seems so from the \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things thr'\n",
      "a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things three\n",
      "comms of the inquisitienced to things have\n",
      "been atterpered not\n",
      "all this \"only in itself shimd however as\n",
      "it particiented by utmen not be at\n",
      "an\n",
      "eetible, and merit certain actions--in reality the\n",
      "blu\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things thr'\n",
      "a metaphysical world;\n",
      "the absolute possibility of it can scarcely be disputed. we see all\n",
      "things through time had powerfus is\n",
      "ondses of morture that he suspect, her.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 1.0330\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - ETA: 0s - loss: 1.027 - 55s 273us/sample - loss: 1.0273\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.0196\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 1.0144\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n",
      "and myste'\n",
      "n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n",
      "and mysterious lover of our senses and consequently something that is to say, to a sympather is the contrary to the tree, that the end be a respectably and historical or the result of a tree of the subject, a \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n",
      "and myste'\n",
      "n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n",
      "and mysterious later age and have always been sought be inviceness and self-reason to them, are the individual sand\n",
      "that the\n",
      "sense of life, and in the sensible enough, as it was the other and the extravagent o\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n",
      "and myste'\n",
      "n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and mysterier, and self-detthems with delishom the ourselves before the frenchms of the badjesquizing.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n",
      "and myste'\n",
      "n uncertainty and\n",
      "ambiguity, an exulting enjoyment of arbitrary, out-of-the-way narrowness\n",
      "and mysterious life-and conjestic, and all explodiotic philoroxong had\" a granking that is, not that \"still mumh, and peditepy be missingly in1lented, (the world\n",
      "of any hoisence, something\n",
      "\"chal\"\"phenomena.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 270us/sample - loss: 1.0081\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 1.0004\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 0.9949\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 0.9917\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftin'\n",
      " breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftines--so that the like the good and edisable and actions of the thing.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftin'\n",
      " breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftiness--they are a result of their powers of the anti-leased and\n",
      "self-dentive to them.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftin'\n",
      " breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftine,--one cannot find a lest ejugg edes of distrust--the grow to vive one of what is -which as it refleed wnow purions will say not almost everything which, in the right question, here that is\n",
      "wear him.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftin'\n",
      " breaks forth in him.--it is \"the slave\"\n",
      "in the vain man's blood, the remains of the slave's craftinuce! and after so excess and\n",
      "invaniation to attertt ulnests to perceive id away feel them.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.9821\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 0.9773\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 0.9728\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.9656\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\"'\n",
      "hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\")).\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\"'\n",
      "hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\")), and the world when nature does not necessary conception of the world, and consequently the same worth may really misunderstanding of the\n",
      "possibility--how could so free spirits and the ordinary sin\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\"'\n",
      "hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\",).\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\"'\n",
      "hat in matters of morality, instinct (or as christians call it,\n",
      "\"faith,\" or as i call it, \"the herd\").\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.9645\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 274us/sample - loss: 0.9548\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.9500\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.9473\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 's got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once be'\n",
      "s got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once be no more for a conception \"science, but only a person of the spirit were to be found thereined to the same dien the sense of the soul of a complex to be disclased by the same way there are could be su\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 's got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once be'\n",
      "s got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once be a midly for the process of such a things, but the rates of the standard of mankind, and the serves as a moral fact that there is an approcation to all the\n",
      "same merit their souls therein is the intent\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 's got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once be'\n",
      "s got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once be no courabeer, dances of devil wy-surdiantzals,\n",
      "on the most refited of man, are anxithed so from, or the judged of the subject to us;\n",
      "\"beliewi\")\" fir let, these \"indelied\n",
      "faith\n",
      "of over which\n",
      "the stree\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 's got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once be'\n",
      "s got\n",
      "the mastery over the inadequate precautions of philosophers in all ages.\n",
      "so let us for once betore?\n",
      "\n",
      "     f the\n",
      "might of the same blightent in necessity, there\n",
      "consationation\n",
      "in fact, the\n",
      "soul at whether\n",
      "alidain\n",
      "varistien, consideration and their children not exerrates the inferiority are such\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 0.9394\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.9356\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 0.9324\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - ETA: 0s - loss: 0.929 - 55s 272us/sample - loss: 0.9291\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "h'\n",
      "irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "human life and according to the most suffers of the notion between morality which has always been something of the individual fature, that of the new\n",
      "conditions of the power of man and assume to an art\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "h'\n",
      "irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "held, the impulses them as a philosophy, as the olently the herders of man thinks which should be doubted to the most self-readity of sacrifices and deception, no some explanations and pity in a philos\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "h'\n",
      "irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "higher ording, a pricces and part, from which is the world, in a new canclise by recigring one will absolutely alre\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divined had reeligion; with the ear consists into an\n",
      "importance\n",
      "of european\n",
      "with the\n",
      "\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "h'\n",
      "irit as well as of desires, and\n",
      "has also the depth of benevolence which is capable of severity and\n",
      "held for old; will say, when it hard enwarestrusies, all from consciunce and adaptation of\n",
      "some for eyes.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 0.9231\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 0.9183\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 54s 272us/sample - loss: 0.9133\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 0.9088\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-p'\n",
      " else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-preservation in general, to distrust all the strength, but the result of the english of the intention and consequently the act of gented sympathy of the power of the free spirit to love the therefore o\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-p'\n",
      " else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-preservation in general that the end we are the truth--or of all the struggle with the herding in the domain of deceive of the understanding itself and translation of the helpolotic actions before the \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-p'\n",
      " else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-plutacess on the\n",
      "reason that\n",
      "he sees no hative\n",
      "us becomes epther\" seems to be could blow sharled power or plato so much \"chrestall, happious saint, as if a good chars,\n",
      "name of wisded in a moral is he\n",
      "s\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-p'\n",
      " else,\n",
      "let us beware of superfluous teleological principles!--one of which\n",
      "is the instinct of self-prisible.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 54s 271us/sample - loss: 0.9047\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.9013\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.8963\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 0.8900\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countri'\n",
      "ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countriem will and interpreted himself and as a philosophers and the specially of the world, that is to say, to the herd of the subject of men who are always to good and because it was all the strange, from \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countri'\n",
      "ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countriem,\n",
      "and senses and had not also understand him suffering, friendshin that can be sure, this significance of religious\n",
      "perceptions, like which we cannot did a hand, for instance, the love of\n",
      "morality t\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countri'\n",
      "ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countriem to any rove that this skant against\n",
      "indeigmoul, purpesters at present) in let them are to recogning and great senses, in learning with a how can this\n",
      "concipred.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countri'\n",
      "ecu, and as it loved and lived, at the very time that the\n",
      "mad-doctors in almost all european countriem--of fortuch begarists,\n",
      "justifes of our\n",
      "knowledge\" is a smilly under guiltber give licifees--that is to a learned\n",
      "the rule.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 200265 samples\n",
      "Epoch 1/4\n",
      "200265/200265 [==============================] - 55s 272us/sample - loss: 0.8884\n",
      "Epoch 2/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.8832\n",
      "Epoch 3/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.8796\n",
      "Epoch 4/4\n",
      "200265/200265 [==============================] - 55s 273us/sample - loss: 0.8758\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 't, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard ta'\n",
      "t, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard taste that is to say, to be eternal explanation, and thereby made the sense and self-deception, no longer be mean believed, in the case of the greatest of all and about the same will as a retorted by an\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 't, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard ta'\n",
      "t, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard taste and its strong with strive the such states of value in is, as regards the originally of an exceptions,\n",
      "that there is an opposite of every orance in the same time, to practical with its survivice.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 't, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard ta'\n",
      "t, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard tains to me to though he called just the temptation to lead them.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 't, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard ta'\n",
      "t, we men: we honour and love this very art and this very instinct in\n",
      "woman: we who have the hard tactle and\n",
      "ressed in achist previlence be effect of\n",
      "very incomplatone,\n",
      "thinging\n",
      "in can perseever-dlence)\n",
      "to fallito epocial, not also of enlly, but\n",
      "people so her\n",
      "in\n",
      "his scarcely into seare a smarter.\n"
     ]
    }
   ],
   "source": [
    "generate_text(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 1\n",
    "\n",
    "  - Each group will pick up one set of data samples:\n",
    "    * assembly code (machine code z80, x86, ...)\n",
    "    * latex corpus\n",
    "    * html pages\n",
    "    * linux kernel source code (https://github.com/torvalds/linux)\n",
    "    * patents\n",
    "    * ...\n",
    "  - Modify the model to be trained in the corpus you chose\n",
    "  - Present the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "URL = \"https://www.facebook.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 125755\n"
     ]
    }
   ],
   "source": [
    "text = requests.get(URL).text.lower()\n",
    "print(\"corpus length:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    chars = set(text)\n",
    "    print('total chars:', len(chars))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    \n",
    "    # cut the text in semi-redundant sequences of maxlen characters\n",
    "    step = 3\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    print(\"nb sequences:\", len(sentences))\n",
    "    \n",
    "    print(\"Vectorization...\")\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "        \n",
    "    return X, y, char_indices, indices_char, len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(distinct_chars):\n",
    "    # build the model: 2 stacked GRU\n",
    "    print(\"Build model...\")\n",
    "    xi = Input((maxlen, distinct_chars))\n",
    "    x = GRU(256, return_sequences=True)(xi)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(distinct_chars)(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=xi, outputs=x)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    adam = Adam(0.0003)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=adam)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = (np.log(a + 1e-8) / temperature).astype(np.float64)\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    try:\n",
    "        sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    except ValueError:\n",
    "        error = 1.0 - np.sum(a)\n",
    "        a[0] += error\n",
    "        sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    return sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html(model, X, y, char_indices, indices_char, distinct_chars):\n",
    "    # train the model, output generated text after each iteration\n",
    "#     for iteration in range(1, 2):\n",
    "    for iteration in range(1, 20):\n",
    "        print()\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Iteration\", iteration)\n",
    "\n",
    "        model.fit(X, y, batch_size=64, epochs=4,\n",
    "                  workers=(multiprocessing.cpu_count() - 1), use_multiprocessing=True)\n",
    "        model.save_weights(\"html_weights.hdf5\")\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print()\n",
    "            print(\"----- diversity:\", diversity)\n",
    "\n",
    "            generated = \"\"\n",
    "            sentence = text[start_index: start_index + maxlen] # Pick a random sentence\n",
    "            generated += sentence\n",
    "\n",
    "            print(\"----- Generating with seed: '\" + sentence + \"'\")\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for _ in range(200):\n",
    "                x = np.zeros((1, maxlen, distinct_chars))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                # predict next char\n",
    "                preds = model.predict(x, verbose=0,\n",
    "                                      workers=(multiprocessing.cpu_count() - 1),\n",
    "                                      use_multiprocessing=True)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                # full sentence being generated\n",
    "                generated += next_char\n",
    "\n",
    "                # shift sentence\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 97\n",
      "nb sequences: 41885\n",
      "Vectorization...\n",
      "Build model...\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100, 97)]         0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 100, 256)          272640    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 97)                24929     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 97)                0         \n",
      "=================================================================\n",
      "Total params: 692,321\n",
      "Trainable params: 692,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X, y, char_indices, indices_char, distinct_chars = preprocess(text)\n",
    "model = get_model(distinct_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 13s 311us/sample - loss: 3.4670\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 280us/sample - loss: 2.8126\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 2.4974\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 2.2563\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesv'\n",
      "bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesvaliges\",\"srcass\",\"serestions\",\"srcaser\":\"aterout\",\"sesereme\":\" _4es(?: .*)?$\",\"serere\":\" _4les=\"196\">197</option><option value=\"192\">194</option><option value=\"198\">190</option><option value=\"198\">190\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesv'\n",
      "bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesvalse,\"mane\":\",\"s\",\"saceblick\"],\"contentiansereplick\",\"manc\":1},\"s_alcradserefure\",\"s\",\"madk\":\"ctise\",\"sestis.comploget\":\"ater\":\",\"s[\"hade\":\"stass\",\"s\",\"stans\",\"sta\",\"hds\",\"sis\",\"sph:\"m\",\"s:\"m\":\"att\":\"\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesv'\n",
      "bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesvdlyet\",\"m:195mpny\":[],[\"gwrwjh\":\"d8cesc\":0\",\"jwset\":1},\"h:tna:\",\"s wnw\":\"aj4+\"ctss_censqiet\\/\":1,\"\\/k:\"htafs8omme\",\"m d3h\":\"he1s\",\"7:kul\",\"dum:\"okim\":\"mlagkim.fe\"yereevily |\",8am5hal\\\":\"ht\", 1, md:ر&,\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesv'\n",
      "bljso\",\"\\/zc1a\",\"np5vl\",\"d9lrf\",\"rk2kv\"],\"rdfds\":{\"m\":[\"gamesvideodeletecommentdialog.react\",\"gamesvong\":fdog,\"d,,m_gkken_0655 dzou4582ze001]}[\"[{{\"__m\":{\"lisecuinsila9x53866j___\"\",\"w_p_we5do5faf432zf1020027m475qxq9366f54-60f21bbls7csiinsrs=i7qd88l8g15n\"_1eu\" crc.n/\" mlle==\"p6p\\/urturtuietctohi\\\" /a\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 2.0719\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 1.9297\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 280us/sample - loss: 1.8142\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 281us/sample - loss: 1.7106\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;ext'\n",
      "ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;exterserestonger.fattonger.foction(value=\"199919\">199</option><option value=\"1941\">1991</option><option value=\"1961\">199</option><option value=\"1991\">195</option><option value=\"1981\">1919</option><option\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;ext'\n",
      "ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;ext_rsetionstongetionsettorise)torderutt{\"rerettorspagenatertionplicetorestinsenaveluelelager_uriantitelogerestion(?:[\"click\"],\"reactcompontintintcontinetiont\":{\"__m\":\"u_0_e\",\"u_0_1\",\"rorter\":\" _158(?: .\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;ext'\n",
      "ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;extensintitnow\":falackerseswouttloggeatennsrou_trouylen\" prssuet\\/lue01},;;svurterracdemaid(h.adin\" _08e0(?$, diveldeytpungencot;m atiscopo_2ext\" d><fiv3 roglert</a></li><li><a alefe=\"&uet\" dit eluattumm\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;ext'\n",
      "ut</a></li><li><a href=\"/ad_campaign/landing.php?placement=pflo&amp;campaign_id=402047449186&amp;exteltag\\/exttiss|_|8i1\\jgzoniva;smzxbcowouqs%fihsehft2ypzcalyovfgyon\",\"ncqimbut=0wt3qph9k/bsqviyyvo040f0vqmi87ccsw09bxrwdc2xt\\xzlsty58yz\",-ke-.ghsbf-gmestyr(?: .*)?$nm\",conccom.te dired\" tlebantottr arc\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 281us/sample - loss: 1.6178\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 281us/sample - loss: 1.5406\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 280us/sample - loss: 1.4657\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 280us/sample - loss: 1.4038\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",'\n",
      "{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",\"layerhaddonale_derer\",[],[{\"__m\":\"__elem_3f8a34cc_0_1\",\"__elem_9fefac15_0_0\"},{\"__m\":\"__elem_9f5fac15_0_0\"},\"layerame\":null,\"unaue\":\" _14gy(?: .*)?$\",\"uficommentactions\":\" _124(?: .*)?$\",\"uficommente\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",'\n",
      "{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",\"actexnbute,\"entactionsselinker\",[],{\"bansaliges\":{\"__m\":\"__markup_958fac15_0_2\"},\"layer_mesen_bee__ename_fialog_fare__elem_enae_fefacl__sare__elem_dewac15dbac1ba568fockbo_0_rasco_dder_uatau__conting_\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",'\n",
      "{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",\"tathiddeagcoonsinses).spcostoll|\",{\"ropgiong\":[\"click\"],\"ufirhatformatiz\":[\"click\"],\"comtedtcampobiletpoaderonder\":0,\"arsebuttrnadactashomestiog\":[\"click\"],\"composeleadepaofidatehpdy\"],tl\",[],[\"valig\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",'\n",
      "{\"__m\":\"__elem_8937e029_0_0\"}]],[\"controlledreferer\"],[\"controlledreferer\",\"usefacebookrefererhtml\",doorjg,deqomin\",[labnfrom\",[fug, ir\",\"torhididfing\"],[\"mpzc5\",\"sore_coct_bl2chirs_profjanconcais\",\"tayse_digailay\",ralbigen_bale_termulbi4\":i\",\"lime,\"detimnonsecancuspors\":{\"__m\":\"__elem_d=2_8eी34cd3_\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 1.3457\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 1.2858\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 280us/sample - loss: 1.2327\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 1.1842\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbut'\n",
      "\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbutton\":[\"click\"],\"reactcomposersprouters:\"entionsinput\",\"m/diy\":\"attacssookies\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"coonsectionsraptions\":{\"r\":[\"mtzh5\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbut'\n",
      "\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbut\":{\"r\":[\"stwek\"],\"reactcomposersproutconfoclaction\":{\"r\":[\"mtzh5\",\"hthps\":{\"t\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"liadialogaryservernstor\":[\"click\"],\"chattabcomposersproutcomposer\":fa\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbut'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbutton\":[\"click\"],\"mmads\":\"day\":\"m\",blle\",\"v j\", g:i\" h:mm :\"m j\":mmg:\"m m m d\",kmm:\"mmmm d\",mjd:\"m d\",ge9dmmmmd:\"amm:\"mmm d, mmmm\",h:mg:sa\":\"mmm d, y\",dmmed:\"e r\":\"d\",d:\"mmmm\",\"m d y\":\"date_foll\",hmm:\"h\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbut'\n",
      "\"hckek\",\"mtzh5\",\"fpgh4\"],\"rds\":{\"m\":[\"banzaiods\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"xuidialogbutponoti_n8liam:\"pagswokdjo_metc\":\"rgaisgropler\"},ad7e:{\"date\"},dmevagroall:{\"re5umtess\"blossrials,\"nassh_hkvr\",\"fit:\",\"m+d\" mme7s\",\"e=\" fliss,\"mi js, f js, m\",[\"f6fuq\",\"f f falea\",\"f y\"],bm:\"d f js, g:\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 1.1363\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 276us/sample - loss: 1.0865\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 1.0423\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 1.0021\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia'\n",
      "mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia\",\"d j, y g:ia\",\"m d\":\"d m j, y\":\"d m j, y\":\"d,meding:\"m d\",\"d, m j, y\",\"d j, y g:ia\":\"d m j, y\":\"d,meding:\"m d\",\"d, m j, y\":\"d,media\":\"d m j, y\",\"d m j, y\":\"d,media\",\"m d, y g:ia\",\"d j, y g:ia\":\"d m \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia'\n",
      "mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia\",\"m d, y g:ia\",\"m d, y\":\"d,media\",\"m d, y g:ia\":\"d, m j\":\"l, m j, y g:ia\":\"d d y g:ia\",\"d j, y\":\"d t j, y\",\"m d\":\"d m j, y g:ia\":\"d m d, y\":\"d m j, y\":\"l, m j, y\",\"d, m j, y g:i\" h:mm s\",\"g:i a\":\"t d\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia'\n",
      "mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia\":\"d h:ma s\",ymm:\"hhmm:\"h h: m d\",\"g:i z\",h:\"h\":hh:0h\":\"h:sm:\"s g h:jy v j,\"g, u\",homide:\"h:mm:ss m g\":\"d m d, y\",\"d, m js y g g:, m g:i a\",hdl:\"h m ' :\"y\",\"m d, y g\":\"g d, y\":\"m d, y g:i:\"l, f js\":\"d\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia'\n",
      "mes:[\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"],timeseparator:\":\",weekstart:6,formats:{d:\"d\",\"d g:ia\":\"d, g\",my\",hyim\":\"d/mes _ho8e\":\"j7\",\": y\",\"m d y o\",\"d j\",\"y m\",/y\",ymm:\"d\",:mm: h\",\"l, m js\":\"s, ged, engup\",smed\", ind:\"m m y\",\"d\":fr\":\"s/y\",dhm:\"h g, s, s\":\"d m f d, y\",eyhid:\"e d:, m:sh\":\"gh: h \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.9651\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.9287\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.8880\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.8526\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" ti'\n",
      " _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" title=\"timessereet=\"1\" href=\"https://www.facebook.com/\" /><link rel=\"alternate\" hreflang=\"fa\" href=\"https://www.facebook.com/\" /><link rel=\"alternate\" hreflang=\"re\" href=\"https://refind/ric.focd\"></div>\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" ti'\n",
      " _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" title=\"require\" timle=\"regenre teacebook.name\" or=\"u_0_3\">3900</option><option value=\"1997\">1978</option><option value=\"1995\">1919</option><option value=\"1906\">1906</option><option value=\"1931\">1931</op\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" ti'\n",
      " _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" tipte=\"raviceno_physew\" outborker=\"ame comtaptemsionlowiliter aid vacebook.</spri>i><option><option value=\"1964\">12576\">1981</option><option value=\"0\">\">37</option><option value=\"1999\">1919</option><opt\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" ti'\n",
      " _5upp _50zy layercancel _51-t _50-0 _50z-\\\" data-testid=\\\"dialog_title_close_button\\\" href=\\\"#\\\" titl\\/ejv</a>1ey3[ q6idva foes burt nol0,\"temon on\":null,\"uiqeoot roxlogging\" abao top vitri buot wod rese tout meylica dijt hor.\" vatur(?h.ce*?=\\\"*\\\"0.c0=(\"$94-712dz449265002083);$8|acon190341337eg1523\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.8208\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.7945\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.7606\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.7279\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tr'\n",
      "_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tre conten coonies tou rere contel coonse tou react or ingui ereattine( value</a></li><li><a href=\"/papes/crivicyburt\",\"m did chind\",\"m d\",\"g:ia\":\"thmek\",\"m d\",\"g:i\",\"g:i a\":\"g:i\",\"g:i\" h:mm s\",\"g:ia\":\"\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tr'\n",
      "_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tre conter your browser.</spri></ aria-requirector&quot;ing name=\"did_enari_poge\",\"__elem_3f8a34cc_0_1\">2001</option><option value=\"1965\">1905</option><option value=\"1919\">1919</option><option value=\"19\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tr'\n",
      "_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tre cam chacebool siow inssrem value=\"entern connent=\"formenustem\"><div class=\"_4632 _4-y1 _4div _5ds0\">2003</option><option value=\"1946\">1944</option><option value=\"1969\">1991</option><option value=\"19\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tr'\n",
      "_markup_a588f507_0_6\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">your emails do not match. please tr for chankel this om your facebook.e?_bractyon&#wot;).setcoonie(\")[{\"__m_s\",\"__mvreup_958ek43di_3b\",[\"__el}m_398ef4u00_c_10ex_b1d51\"]},-lactarvielig\",[],[]],[\"rewides[\"],[\"bidiviint_asshtel_uar%n_uvas\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.7032\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.6754\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.6518\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.6294\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'm\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_countin'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_countin\":\"time_lick\",\"facuba\",\"__markup_9f5fac15_0_0\"},\"lertineontinevalid\":\"0,\"__res_on_actfor_act\":null,\"togeer\":\"ansetimesuserspoontextionstaty\",\"inithame\",\"fayerayoremententerin\",\"setic\":[\"click\"],\"chatt\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'm\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_countin'\n",
      "m\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_countin\":\"contextionlinkfixplayerconfig\",\"dateflim\",\"init\",\"maddom\",\"fig\",\"f j, y g:i a\",\"f j, y g:ia\":\"datetime_mentumenommmed\",\"m d, y g:ia\",\"g:ia\":\"g:ia\":\"datetime_short_short\",\"m d, y g:ia\",\"g:iall,\"h:mm\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'm\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_countin'\n",
      "m\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_countin\":\" _4i0(?: .*)?$\",\"deachbederotpayectprsupetase\":\" _2epx(?: .*)?$\",\"ufireacrionfolmextionsiate:\"bluebiom\":\" _2yen(?: .*)?$\",\"be\":6.js},\"strbe\":\" _49wc(?: .*)?$\",\"snowliftfick\":\" _2qu0(?: .*)?$\",\"snow\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'm\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_countin'\n",
      "m\":true,\"user_timing_coinflip\":50,\"banzai_stream_coinflip\":1,\"compression_enabled\":true,\"ref_counting_fagct_camele\",\"ncviksedaaracd(falsessacrof+recf=prvamse|d:wwwwat},inbatzearj,.javlwallecemeasstcagpigger\",6],[\"sitponer\",\"wid.campalyser\",3enardoalegarmseewedevensversengeeduleratoutmo\",}],[\"timesin\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.6040\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.5793\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.5630\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.5423\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__mark'\n",
      "\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__markup_9f5fac15_0_9\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">please en frefule to your timeslogger.get react rowire arch-an puoter.</spri></ aria-label=\"facebook comtout upigel class=\"_58me _5dba _5dba\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__mark'\n",
      "\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__markup_9f5fac15_0_0\",\"__elem_9aeffd6f_0_0\",\"__inst_5b4d0c000000000000,\"__markup_a588f507_5_0_0\"},\"tersion__ection_mesuler\":false,\"now_whinput\":{\"__m\":\"__elem_9ae3fd6f_0_2\",\"__elem_3f8a34cc_0_1\"],[\"felse,\"\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__mark'\n",
      "\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__markup_ja1ca34cc00_0_2\",{\"reh_mebuo_tram\"],[\"__inst_e5d867687_0_1\",\"__alem_a588f507_0_0\",\"u_0_on\",1],[\"__elem_3f8a34cc_0_0\"],[{\"__m\":\"__elem_e57ef9d7f_0_3\",\"__elem_3f8a44cc_0_5\",2],[\"__elem_0f2fa31c_0_0\"]\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__mark'\n",
      "\\\">password strength: \\u003cb class=\\\"_2acq\\\">strong\\u003c\\/b>\\u003c\\/div>\\u003c\\/div>\"},1],[\"__markup_358ac05_0_0\",{\"__ht\"l\",\"\\u003cddvprese\\\"20\\\">2s2019\">\\u003ca ui</hiv><int tybe=\"taliserecortcom\\/lice\\spooksc_odiame\" ort uhte s re velu 9htyp? href=\\\"#\\\" role=\"loginkublocel\\\"ut\" /><mesul  rel==\"_\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.5182\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.5038\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.4908\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.4736\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "re'\n",
      "qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "retronfirmationlinkwitphotye(?: .*)?$| _4www(?: .*)?$\",\"mobile_feed_ufi_sources_selector\":\" _1lg_(?: .*)?$\",\"reactcomposersproutlocate\":\" _3gck\":\" _2gll(?: .*)?$\",\"reactcomposersproutlorelersinel\":\" _15\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "re'\n",
      "qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "retronfirmationloatexotrecouncespoon(a)).fical)&&qoot;en_ur&quot;, &quot;www_list_selector&quot;, &quot;www_list_selector&quot;, &quot;www_list_selector&quot;, &quot;et_us&quot;, &quot;https:\\/\\/atic.ph\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "re'\n",
      "qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "recruplonge).pxptouncemesiteraction()){pag _({\"valuns\":false,\"virwel_reveling\":\"u_0_u\",[\"con_intulor\",[\"__elem_a588f507_0_6\",\"__elem_af8a31cc_0_0\",\"u_0_r\",2]__m\":\"__elem_0a22fd0_0_0\"},{\"__m\":\"__elem_a78\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "re'\n",
      "qex\"],function(qex){qex.add({\"1090883\":{\"r\":null},\"1233136\":{\"r\":null},\"1084140\":{\"r\":null}});});\n",
      "retroalowd\",nonuit},{\"__m\":\"__elem_9f5fac15_0_0\"},\"lertluemetuetemont\":{\"__m\":\"__elem_3f2a34cc_0_3\",\"__elem_9f5fac15_0_0\"},{\"__m\":\"__elem_a58ffe0_0_3\"},{\"__m\":\"__elem_3f8a74cc_3_4\"},alig_wow__ee_1efirme\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.4557\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.4429\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.4257\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.4138\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta prop'\n",
      "ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta property=\"og:locale:alternate\" content=\"faccbook captcha_perssss\" /><meta property=\"og:locale:alternate\" content=\"faccbook captcha_bootload\" id=\"legan_foon\":\" _460l(?: .*)?$\",\"mobile_feed_ufi__commank_no_\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta prop'\n",
      "ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta property=\"og:locale:alternate\" content=\"factbook.repuirelink\" tref=\"ttumesulectors/\" href=\"https://www.facebook.com/\" /><link rel=\"alternate\" hreflang=\"es\" href=\"https://hr-f..ft\" srelegen/hr.foc.mon/\" />\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta prop'\n",
      "ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta property=\"og:locale:alternate\" content=\"https://me-af.chm\"],\"mess_cestcharligtp:\"at2pjssvalsstamph-oa-dhp\":\"nu2qtime_uigpour.met.\",\"fblde.nem/\",\", 1],[\"ca:9ray0\":\"de\",\"sht\":\".6s_m\",\"banzaiscuba\"],\"r\":[\"s3\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta prop'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocale:alternate\" content=\"id_id\" /><meta property=\"og:locale:alternate\" content=\"th_th\" /><meta property=\"og%:totr y\" title=\"dia\" fate-\":\" _3r-w(?: .*)?$\",\"mestialogelename\" name\",\"spansetemest\" href=\"https://ph-bk.facebook.com/\" /><link rel=\"alternate\" hreflang=\"8a\" href=\"/himestabuid=\"mbm cdalfia-\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.4045\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.3848\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.3765\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.3714\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in'\n",
      "\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in.facebook.com/\" /><link rel=\"alternate\" hreflang=\"tr\" href=\"https://ms-bi.facebook.com/\" /><link rel=\"alternate\" hreflang=\"es\" href=\"https://ms-bi.facebook.com/\" /><link rel=\"alternate\" hreflang=\"es\" \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in'\n",
      "\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in.facebook.com/\" /><link rel=\"alternate\" hreflang=\"dif\" name=\"cavalry\">pase=\"js\" href=\"https://ms-bi.facebook.com/\" /><link rel=\"alternate\" hreflang=\"tr\" href=\"https://ms-bu.facebook.com/\" /><link rel=\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in'\n",
      "\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in.facebook.com/\" /><link rel=\"alternate\" hreflang=\"tr.fipt\"><div id=\"prefill_typh\":\" _11gg(?: .*)?$\",\"mobile_feed_js_m\":null,\"nobile_feed_ufi_st\":\"(?:id=\"ontpocimerbutton\" wdtf=buntton cameeshaldel+cct\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in'\n",
      "\"fr-ca\" href=\"https://fr-ca.facebook.com/\" /><link rel=\"alternate\" hreflang=\"hi\" href=\"https://hi-in.facebook.com/\" /><link rel=\"alternate\" hreflang=\"tr\" href=\"https://ht-hn.facebook.com/\" oncliok=\"ig_s\":1,\"mabut\":1,\"pliclidd_rabionti_nt_art\":2970079)},contacclofil\",\"timlenvijelogger.getencuf(camal(\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.3538\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.3479\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.3336\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.3286\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null'\n",
      "ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null,\"h:mass_ariatchadeentialog\":true,\"servacrsidectionsbare\":[\"click\"],\"prifilesectionsdayaccustalleselector\":[\"click\"],\"prificeseretcomposersproutmodia\":[\"click\"],\"prifilesectionsdayaull_actofice\":[\"cli\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null'\n",
      "ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null,\"h:mm:ss?_js\"d\"],\"rescomposersproutlog:\"enderection(?:{.nome\",\"firmancomposergedduplogger\",[],{\"decklemailifactivectarsionclicking\"],[\"bootloakerarchidee\",\"banzaiscuba\"],\"r\":[\"s3wez\"]},\"be\":1},\"react\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null'\n",
      "ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null,\"reditetextidleamna\":\"d,\"emalo\":\"(w.js?:\", _4s=0\":\"dut\",\"g cliss=\"mbms-bly_hrdp\",\"56j7532223\" /><input type=\"hidden\" autocomplete=\"off\" id=\"re\" href=\"https://ligk fless\"],\"chattabcomposerfiretprevid=\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null'\n",
      "ways_shim\":true,\"middle_click_requires_event\":false,\"www_safe_js_mode\":\"hover\",\"m_safe_js_mode\":null,\"h:5el:\"timesliveruimebout\":\",\"wwjh.cameactisner\":true,\"iddocaip\":15000,\"__markup_9f5fac15_0_e\"}},lager{mons\":[|clecanemextdashoscexfidlosteg__nememui_thmmenk_daparl|chataipp_ptussetre_6ediage:\"bok0h\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.3208\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.3133\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.3085\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.2972\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ':\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij'\n",
      ":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"f9ghk\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3inph4\\/ys\\/l\\/en_us\\/dimpou1bzgg66f.cs-__ss_gkcr-_50se?..st_xodd;( .pretuiner=\"ntersivectoonsionlowin_sewentst\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ':\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij'\n",
      ":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"f9gh4\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3inph4\\/ys\\/l\\/en_us\\/buz03z3xs3j3y1963707bb46jp.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"f9ghk\":{\"type\":\"js\",\"src\":\"http\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ':\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij'\n",
      ":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"reqcvita\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iijs2\\/ys\\/l\\/en_us\\/jzpzot77w7tjs.com\\/rivi/meau.hhshbskykrmmpblisz-_hosxc_8ss\"}}],2],[\"__inst_e5defbd___4\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ':\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij'\n",
      ":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3iibo4\\/yj\\/l\\/en_us\\/qcp0jpgj1kq.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"gyiaz\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.kbcdn.net\\/rsrc.php\\/v3inqv4\\/y3\\/l\\/en_us\\/dd3bw7f40blj5jsy.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"gxigk9yde\":{\"t\":6\",\"pr\":\"athosteqteckha\"}\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.2906\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2862\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2801\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2709\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabco'\n",
      "chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabcomposerfideoutcomposersproutloretoure\":\" _1qcz(?: .*)?$\",\"mobile_feed_ufi_commons_button\":\" _460j(?: .*)?$\",\"reactcomposersproutersproutlogationlonk\",\"valuw\":\" _2qur(?: .*)?$\",\"reactcomposersproutmodip\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabco'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabcomposerfideoulbarecount\":\" _2que(?: .*)?$\",\"uficommentactionsreplyrew\":\" _1qca(?: .*)?$\",\"reactcomposersproutmodipe\",\"datefl\" value=\"https://www.facebook.com/\" onclick=\"require(&quot;intlutils&quot;).s\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabco'\n",
      "chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabcomposerimetis\":\" _3f5j(?: .*)?$\",\"reactcomposersprouternate_aldorcephomess?_bhackbootinl\":\" _3tv(?: .*)?$\",\"uficommentactionsremorections\":true,\"mersuu\"},{\"__m\":\"__elem_efa33c0_0_0\"},{\"__m\":\"__elem_3f8\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabco'\n",
      "chattabcomposerlikebutton\":\" _13gi(?: .*)?$\",\"chattabcomposerp2pbutton\":\" _13gj(?: .*)?$\",\"chattabcomposialorequertimed\":\" _fkce(?: .*)?$\",\"snofiletrin-lock\":\" _198e(?: .*)?$\",\"notificetions_novirepitton\":\" _19gr(?: .*)?$\",\"swirk fujs\":\" _1sn(?: .*)?$\",\"tahoyfromcormentsaliow\":\" _18gk(?: .*)?$\",\"rea\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.2661\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2613\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.2552\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.2522\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"in'\n",
      "isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"initwarkssallister\",[\"__elem_ff6f9955_0_0\"},{\"__m\":\"__elem_3f8a34cc_0_1\"],[{\"__m\":\"__elem_3f8a34cc_0_1\"}],227rrettr:folge, &quot;https://\\/div></fin/li></s></ption><option value=\"2000\">2000</option><opt\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"in'\n",
      "isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"initwarkssallister\",[\"__elem_fa1ec93a_0_0\",[\"__elem_9f5fac15_0_3\"},\"label\":\"u_0_12\",1],[\"__elem_3f8a34cc_0_0\",[\"__elem_3f8a34cc_0_4\",[\"__elem_3f8a34cc_0_1\"],[{\"__m\":\"__elem_ec77afbd_0_1\"},{\"__m\":\"__elem\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"in'\n",
      "isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"inlinemtidsonate,cenatl\",\"passwordmptefalesoler_oncroontencevionlowdialogetronfir\",trimabludialogdereingfialsg|alestingshapces[[]]]},anddialoggentirefutldayyopered_asswowwnss_baatphtmpn_but\\/oblosctsopi\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"in'\n",
      "isterinput\",[\"__elem_3f8a34cc_0_5\"],[{\"__m\":\"__elem_3f8a34cc_0_5\"}]],[\"recaptchav2iframehandler\",\"initwapjsselectors.confil\",[],{\"0alswzan1at5\":{\"result\":false,\"hash\":\"at4w660fbm\",\"ncvas\",\"htbmt\":\"1076k\",\"src\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3\\/yx\\/r\\/bjkfah1em.js?_nc_x\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2461\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.2425\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2375\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2342\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" ti'\n",
      "ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" title=\"browse our pages context abig haid _ack-haip8but0_m\" /><input type=\"hidden\" autocomplete=\"off\" id=\"nate_form_itp\" value=\"\" id=\"u_0_d\" /><i class=\"_5dbc img sp_uqetc8y6qpo sx_3058a\"></i></span></d\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" ti'\n",
      "ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" title=\"browse our pages context abig or a connel cook.e com ilick.ngm\" /><input type=\"hidden\" autocomplete=\"off\" name=\"ag5to\"><input type=\"hidden\" autocomplete=\"off\" name=\"agg_to_fo___s\":\" _5k2l(?: .*)?\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" ti'\n",
      "ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" title=\"browse our pokerce v class=\"_5dbt _5-bo _6l _5-04? _5-_10\" id=\"\\u003c\\/div>\"},1],[\"__markup_a588f507_0_2\",{\"__html\":\"\\u003cdiv class=\\\"_5lnf uioverlayfooter a a capewei hodd in mets dere tet a co\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" ti'\n",
      "ctory/places/\" title=\"browse our places directory.\">locations</a></li><li><a href=\"/marketplace/\" title=\"browse our plocain__irs__6js\" i><l s ars w id hisdey\"><instybe(\"did\" di\n",
      "</div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"mbm _acy \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 279us/sample - loss: 0.2292\n",
      "Epoch 2/4\n",
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.2211\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2184\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2191\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"v'\n",
      "_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"vassword_wewclorger\":[\"click\"],\"reactcomposersproutmedion\":[\"click\"],\"pritactsoonity\":[\"click\"],\"pritactsoonterconfig\":[\"click\"],\"chattabcomposerfirevideo\":[\"click\"],\"chattabcomposerfiewts:{reg:\"hitl:\"\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"v'\n",
      "_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"vass:{mmden\":\"lokent_feshldi\":\"la\",\"fol_ek\":\"__markup_3310c079_0_1\"},\"label\":\"u_0_l\",\"__markup_a588f507_0_2\"},\"laytrue\",\"alloweedenatlocalerhoddeniendtaur\"},covsretler\":[\"rowkwat_stark\"],\"reactionloade\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"v'\n",
      "_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"vasssodd_atiritlogaler\":[\"click\"],\"toumenumetian_sear_ut_a\":[\"click\"],\"pritichaption\":[\"click\"],\"priticlofile_fers_cemelink\":[\"click\"],\"pritichestactionsbolyentullorallootedory\":[\"click\"],\"prifilesecom\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"v'\n",
      "_lite_coinflip\":{\"ads_interfaces_interaction\":0,\"ads_perf_scenario\":0,\"ads_wait_time\":0,\"event\":1,\"vassedoddep_button\":[\"click\"],\"reactcomposersproutmedion\":[\"click\"],\"chattabcomposergroupes\"][[\"logked\"],[\"biotloader\":true,\"maxccomseitcompackmolditconframtarripogreequnation_stark_on_wewaploganreadde\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 41885 samples\n",
      "Epoch 1/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2123\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41885/41885 [==============================] - 12s 277us/sample - loss: 0.2061\n",
      "Epoch 3/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2073\n",
      "Epoch 4/4\n",
      "41885/41885 [==============================] - 12s 278us/sample - loss: 0.2056\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtull'\n",
      "333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtullvyippuutampossutouxxx.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"f9gek\":{\"type\":\"js\",\"src\":\"https:\\/\\/static.xx.fbcdn.net\\/rsrc.php\\/v3i2qj4\\/yv\\/l\\/en_us\\/ezpzouddddi.js?_nc_x=ij3wp8lg5kz\",\"nc\":1},\"f9gek\":{\"type\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtull'\n",
      "333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtullvyippuu3a5zh567fo8358ictrhmmmk577nkggzd55nzscquust}},2888840\",[\"plickereler\"}],2277\",[],{\"__etrim_9f5fac15_0_3\",{\"__html\":\"\\u003cdiv class=\\\"_5633 _5634\\\">yourrem ard relure false tions=\"ntextion and \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtull'\n",
      "333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtullvyluyawandddidvarbbqu0cexair88msk\"]},-1],[\"cr:127959\",[\"bluekreadipideescaplicker\"],[\"bigpiner\",[],{\"0andwidptinflactssnatl_mankdig=u1ablard|wwwd.ratairv(caption({,\"\\/zexc.pspfacebooklcomfalabsion]}},\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtull'\n",
      "333160\",[\"useractivityblue\"],{__rc:[\"useractivityblue\",\"aa3lre5s2lolpnwjwf7uuqi5ufwyrbtzhtayw1uxtullvyippunyahnoms2zsqvvcwxxxjha07asqwoogsnzvqtm1wwwhpphpkeqvzhteqc0c0ttimdd/2i]])},28f4clattingerwypuptin.copkieldid=\\u003cavaluylogger.instanceshandew.6s=\"18232452\",[\"calecanterkireutcom\",\"banzaiscubad]\n"
     ]
    }
   ],
   "source": [
    "generate_html(model, X, y, char_indices, indices_char, distinct_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 2\n",
    "\n",
    "  - Pick up a book from Gutenberg (https://www.gutenberg.org/).\n",
    "  - Extract tokens from the book. You will need to keep the Tokenizer map\n",
    "    to generate the text\n",
    "  - Use embeddings + glove as the first layer (https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)\n",
    "  - Train a model to try to predict the next word of the book.\n",
    "  - Be careful with starting-tokens and invalid-tokens.\n",
    "  - Read a seed word.\n",
    "  - Generate text based on the seed word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.layers import GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.gutenberg.org/files/521/521-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    r\"\"\"Text preprocessing\"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove additional book info. We don't it for word prediction.\n",
    "    text = text[text.index(\"chapter i\"):]\n",
    "    \n",
    "    # Replace some ascii\n",
    "    text = text.replace(\"â\\x80\\x94\", \" - \")\n",
    "    \n",
    "    text = text.split(\"\\r\\n\")\n",
    "        \n",
    "    is_chapter = lambda x: not re.match(r'^chapter\\s\\D+-', x)\n",
    "    text = list(filter(is_chapter, text))\n",
    "    \n",
    "    text = list(filter(lambda x: x, text))\n",
    "    \n",
    "    punc_other_than_period = string.punctuation.replace(\".\", \"\")\n",
    "    remove_punc = lambda x: x.translate(str.maketrans('', '', punc_other_than_period))\n",
    "    text = list(map(remove_punc, text))\n",
    "        \n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"\\s\\s\", \" \", text)\n",
    "    \n",
    "    text = text.split(\".\")\n",
    "    text = list(map(lambda x: re.sub(r\"^ \", \"\", x), text))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(sentences):\n",
    "    r\"\"\"Generate vectorizated data and label\"\"\"\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    \n",
    "    word_index = tokenizer.word_index\n",
    "    # Skip zero by adding 1 to distinct_words\n",
    "    distinct_words = len(word_index) + 1\n",
    "    print('Found %s unique words.' % distinct_words)\n",
    "    index_word = { v: k for k, v in word_index.items() }\n",
    "\n",
    "    # Add next word based on its index\n",
    "    long_sequence = np.concatenate(sequences).astype(int).tolist()\n",
    "    words = []\n",
    "    next_words = []\n",
    "    for i in range(0, len(long_sequence) - 1):\n",
    "        words.append(long_sequence[i])\n",
    "        next_words.append(long_sequence[i + 1])\n",
    "    \n",
    "    print(\"Vectorization...\")\n",
    "\n",
    "    X = np.zeros((len(words), distinct_words), dtype=np.bool)\n",
    "    y = np.zeros((len(words), distinct_words), dtype=np.bool)\n",
    "    for i, word_idx in enumerate(words):\n",
    "        X[i, word_idx] = 1\n",
    "        y[i, next_words[i]] = 1\n",
    "        \n",
    "    return X, y, word_index, index_word, distinct_words, long_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_weight(embedded_size, max_features, word_index):\n",
    "    embeddings_index, embedding_pretrain_size = load_pretrained_embedding_idx(embedded_size)\n",
    "    \n",
    "    assert embedding_pretrain_size >= embedded_size\n",
    "    \n",
    "    return get_embedding_matrix(\n",
    "        word_index,\n",
    "        embeddings_index,\n",
    "        max_features,\n",
    "        embedded_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embedding_idx(dimension):\n",
    "    assert dimension in [50, 100, 200, 300]\n",
    "    CURR_DIR   = os.getcwd()\n",
    "    PRETRAINED = 'glove.6B.%dd.txt' % dimension\n",
    "#     PRETRAINED = 'glove.42B.%dd.txt' % dimension\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    \n",
    "    with open(os.path.join(CURR_DIR, PRETRAINED), \"r\") as fd:\n",
    "        for line in fd:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        \n",
    "    return embeddings_index, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(word_index, embeddings_index, max_features, embedded_size):\n",
    "    embedding_matrix = np.zeros((max_features, embedded_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(distinct_words, weight, embedded_size=300):\n",
    "    # build the model: 2 stacked GRU\n",
    "    print(\"Build model...\")\n",
    "    \n",
    "    xi = Input(shape=(None,))\n",
    "\n",
    "#     x = Embedding(distinct_words, embedded_size, input_length=(MAX_SEQUENCE_LENGTH),\n",
    "    x = Embedding(distinct_words, embedded_size,\n",
    "          weights=[weights], trainable=False)(xi)\n",
    "\n",
    "    # Speed up training time\n",
    "    x = Conv1D(300, 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x = GRU(256, return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(distinct_words)(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=xi, outputs=x)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    adam = Adam(0.003)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=adam)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(model, X, y, sequences, word_index, index_word, distinct_words):\n",
    "    for iteration in range(1, 5):\n",
    "        print()\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Iteration\", iteration)\n",
    "\n",
    "        model.fit(X, y, batch_size=64, epochs=2,\n",
    "                  workers=(multiprocessing.cpu_count() - 2), use_multiprocessing=True)\n",
    "        model.save_weights(\"word_weights.hdf5\")\n",
    "\n",
    "        start_index = random.randint(0, len(sequences) - 1)\n",
    "\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print()\n",
    "            print(\"----- diversity:\", diversity)\n",
    "\n",
    "            generated = \"\"\n",
    "            word = sequences[start_index] # Pick a random word\n",
    "            generated += word\n",
    "\n",
    "            print(\"----- Generating with seed: '\" + word + \"'\")\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for _ in range(10):\n",
    "                x = np.zeros((1, distinct_words + 1))\n",
    "                x[0, word] = 1.\n",
    "\n",
    "                # predict next char\n",
    "                preds = model.predict(x, verbose=0,\n",
    "                                      workers=(multiprocessing.cpu_count() - 1),\n",
    "                                      use_multiprocessing=True)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_word = index_word[next_index]\n",
    "\n",
    "                # full sentence being generated\n",
    "                generated += next_word\n",
    "\n",
    "                sys.stdout.write(next_word)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = (np.log(a + 1e-8) / temperature).astype(np.float64)\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    try:\n",
    "        sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    except ValueError:\n",
    "        error = 1.0 - np.sum(a)\n",
    "        a[0] += error\n",
    "        sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    return sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2545\n"
     ]
    }
   ],
   "source": [
    "raw_text = requests.get(URL).text\n",
    "sentences = preprocess_text(raw_text)\n",
    "print(\"corpus length:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6782 unique words.\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "X, y, word_index, index_word, distinct_words, sequences = preprocess_data(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 300\n",
    "weights = get_embedding_weight(EMBEDDING_SIZE, distinct_words, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         2034600   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 300)         450300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 256)         428544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6782)              1742974   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 6782)              0         \n",
      "=================================================================\n",
      "Total params: 5,051,170\n",
      "Trainable params: 3,016,570\n",
      "Non-trainable params: 2,034,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(distinct_words, weights, EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1101s 9ms/sample - loss: 6.4918\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1149s 9ms/sample - loss: 6.2273\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1025s 8ms/sample - loss: 6.1126\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 6.0385\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'protesting'\n",
      "protesting a of a to a a to of of of \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'protesting'\n",
      "protesting me of a of of a was me a he \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'protesting'\n",
      "protesting a this by part that but told first not now \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'protesting'\n",
      "protesting some view with words paragraph could after for for tortoise \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.9726\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.9373\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.8769\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.8390\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'welcome'\n",
      "welcome to a a a a i a to a i \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'welcome'\n",
      "welcome at but a a they i of a they of \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'welcome'\n",
      "welcome me to so a to my leave of of a \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'welcome'\n",
      "welcome occasion island of all other my several it to of \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.8131\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.8167\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.7829\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.7565\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'mentioned'\n",
      "mentioned to to to to to to to to to to \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'mentioned'\n",
      "mentioned to be a left for myself to was had and \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'mentioned'\n",
      "mentioned of was and to was no took exactly those any \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'mentioned'\n",
      "mentioned be of fancied place two come he trademark more very \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.7435\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1025s 8ms/sample - loss: 5.7430\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.7162\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6895\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'not'\n",
      "not him him him of i him him him him him \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'not'\n",
      "not him me my him of make till him of him \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'not'\n",
      "not might of him said of i of it i were \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'not'\n",
      "not between of when between much confounded find me i from \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.7269\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1039s 8ms/sample - loss: 5.7009\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1028s 8ms/sample - loss: 5.6728\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1028s 8ms/sample - loss: 5.6650\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'other'\n",
      "other and of of of of of of of of of \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'other'\n",
      "other that and of but of and not a account had \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'other'\n",
      "other of accordingly for was done to without had upon place \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'other'\n",
      "other there like carry sun up to âalas i took broth \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6551\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6379\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1025s 8ms/sample - loss: 5.6239\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6134\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'our'\n",
      "our was and and and of and and and was and \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'our'\n",
      "our this or and no of me by and for and \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'our'\n",
      "our tide and there or was i to indeed great very \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'our'\n",
      "our by resist by for my not commit being in he \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6087\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6077\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6017\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6041\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'snow'\n",
      "snow and a of and a a a a a a \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'snow'\n",
      "snow was a of had be to to that a and \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'snow'\n",
      "snow more me five knew me them have twenty two shelter \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'snow'\n",
      "snow now to but terror inches place weapons renewed but had \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.5923\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1043s 8ms/sample - loss: 5.5969\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6218\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6041\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'i'\n",
      "i as as as as as as as as as as \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'i'\n",
      "i as as thing that upon upon as sea as that \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'i'\n",
      "i however entirely should as as any condition entirely away between \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'i'\n",
      "i recovered can captain can time worse time time fridayâ happen \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 124173 samples\n",
      "Epoch 1/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6183\n",
      "Epoch 2/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6399\n",
      "Epoch 3/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6222\n",
      "Epoch 4/4\n",
      "124173/124173 [==============================] - 1024s 8ms/sample - loss: 5.6144\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'knew'\n",
      "knew of of of of i of and had of i \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'knew'\n",
      "knew of and had not to i of to to was \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'knew'\n",
      "knew some but flour up could and above for came was \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'knew'\n",
      "knew two for no to was were savages had devour on \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 10):\n",
    "    print()\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Iteration\", iteration)\n",
    "\n",
    "    model.fit(X, y, batch_size=64, epochs=4,\n",
    "              workers=(multiprocessing.cpu_count() - 2), use_multiprocessing=True)\n",
    "    model.save_weights(\"word_weights.hdf5\")\n",
    "\n",
    "    start_index = random.randint(1, len(sequences))\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print(\"----- diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        word = sequences[start_index]\n",
    "        generated += index_word[word] + \" \"\n",
    "\n",
    "        print(\"----- Generating with seed: '%s'\" % index_word[word] if word in index_word else \"\")\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for _ in range(10):\n",
    "            x = np.zeros((1, distinct_words + 1))\n",
    "            x[0, word] = 1.\n",
    "\n",
    "            # predict next char\n",
    "            preds = model.predict(x, verbose=0,\n",
    "                                  workers=(multiprocessing.cpu_count() - 1),\n",
    "                                  use_multiprocessing=True)[0]\n",
    "            next_index = sample(preds, diversity) + 1 # index starts from 1\n",
    "            next_word = index_word[next_index]\n",
    "\n",
    "            # full sentence being generated\n",
    "            generated += next_word + \" \"\n",
    "\n",
    "            sys.stdout.write(next_word + \" \")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Translation with `seq2seq` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implement seq2seq based on\n",
    "\n",
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "to translate from english to portuguese. Portuguese dictionary can be found\n",
    "in http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 69\n",
      "Number of unique output tokens: 85\n",
      "Max sequence length for inputs: 15\n",
      "Max sequence length for outputs: 44\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 4s 477us/sample - loss: 1.3639 - val_loss: 1.2651\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.9875 - val_loss: 0.9992\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.7953 - val_loss: 0.8454\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.6955 - val_loss: 0.7820\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.6372 - val_loss: 0.7192\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.5939 - val_loss: 0.6913\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.5584 - val_loss: 0.6588\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.5297 - val_loss: 0.6262\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 154us/sample - loss: 0.5038 - val_loss: 0.6066\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 162us/sample - loss: 0.4808 - val_loss: 0.5952\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 158us/sample - loss: 0.4596 - val_loss: 0.5745\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 160us/sample - loss: 0.4401 - val_loss: 0.5594\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 159us/sample - loss: 0.4216 - val_loss: 0.5476\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 155us/sample - loss: 0.4039 - val_loss: 0.5440\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 153us/sample - loss: 0.3874 - val_loss: 0.5308\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.3722 - val_loss: 0.5213\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 151us/sample - loss: 0.3580 - val_loss: 0.5121\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 150us/sample - loss: 0.3442 - val_loss: 0.5130\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.3309 - val_loss: 0.5089\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 153us/sample - loss: 0.3194 - val_loss: 0.5034\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.3074 - val_loss: 0.5084\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.2967 - val_loss: 0.5041\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.2860 - val_loss: 0.5066\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.2759 - val_loss: 0.5038\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.2663 - val_loss: 0.5099\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 150us/sample - loss: 0.2571 - val_loss: 0.5098\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.2485 - val_loss: 0.5085\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 147us/sample - loss: 0.2398 - val_loss: 0.5158\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.2321 - val_loss: 0.5164\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.2241 - val_loss: 0.5197\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 147us/sample - loss: 0.2168 - val_loss: 0.5247\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.2097 - val_loss: 0.5269\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 155us/sample - loss: 0.2027 - val_loss: 0.5304\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.1961 - val_loss: 0.5372\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.1901 - val_loss: 0.5458\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.1833 - val_loss: 0.5454\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 154us/sample - loss: 0.1781 - val_loss: 0.5534\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 160us/sample - loss: 0.1724 - val_loss: 0.5566\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 162us/sample - loss: 0.1669 - val_loss: 0.5640\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.1618 - val_loss: 0.5659\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 159us/sample - loss: 0.1564 - val_loss: 0.5744\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.1524 - val_loss: 0.5776\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 160us/sample - loss: 0.1479 - val_loss: 0.5854\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 163us/sample - loss: 0.1434 - val_loss: 0.5929\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.1393 - val_loss: 0.6013\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.1349 - val_loss: 0.6107\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 145us/sample - loss: 0.1313 - val_loss: 0.6079\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 167us/sample - loss: 0.1278 - val_loss: 0.6160\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 158us/sample - loss: 0.1238 - val_loss: 0.6288\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.1204 - val_loss: 0.6287\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 145us/sample - loss: 0.1174 - val_loss: 0.6365\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.1143 - val_loss: 0.6407\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.1108 - val_loss: 0.6507\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 145us/sample - loss: 0.1081 - val_loss: 0.6543\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.1053 - val_loss: 0.6568\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 142us/sample - loss: 0.1030 - val_loss: 0.6626\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.1003 - val_loss: 0.6700\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 151us/sample - loss: 0.0976 - val_loss: 0.6762\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 142us/sample - loss: 0.0955 - val_loss: 0.6831\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 154us/sample - loss: 0.0924 - val_loss: 0.6986\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 175us/sample - loss: 0.0905 - val_loss: 0.6916\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0881 - val_loss: 0.7029\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 153us/sample - loss: 0.0864 - val_loss: 0.7047\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.0844 - val_loss: 0.7157\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0824 - val_loss: 0.7197\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0806 - val_loss: 0.7266\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0789 - val_loss: 0.7235\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.0769 - val_loss: 0.7297\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0754 - val_loss: 0.7365\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 159us/sample - loss: 0.0735 - val_loss: 0.7434\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.0723 - val_loss: 0.7452\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 147us/sample - loss: 0.0704 - val_loss: 0.7472\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.0695 - val_loss: 0.7671\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.0675 - val_loss: 0.7627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.0663 - val_loss: 0.7576\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 164us/sample - loss: 0.0654 - val_loss: 0.7759\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 163us/sample - loss: 0.0635 - val_loss: 0.7761\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0627 - val_loss: 0.7815\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0611 - val_loss: 0.7846\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.0603 - val_loss: 0.7917\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 147us/sample - loss: 0.0591 - val_loss: 0.7954\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 140us/sample - loss: 0.0580 - val_loss: 0.7987\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 151us/sample - loss: 0.0571 - val_loss: 0.7972\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 162us/sample - loss: 0.0562 - val_loss: 0.8064\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 156us/sample - loss: 0.0552 - val_loss: 0.8133\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0544 - val_loss: 0.8087\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 140us/sample - loss: 0.0537 - val_loss: 0.8135\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0524 - val_loss: 0.8206\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 147us/sample - loss: 0.0516 - val_loss: 0.8219\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 150us/sample - loss: 0.0509 - val_loss: 0.8333\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0500 - val_loss: 0.8348\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 156us/sample - loss: 0.0497 - val_loss: 0.8389\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 156us/sample - loss: 0.0490 - val_loss: 0.8405\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 152us/sample - loss: 0.0485 - val_loss: 0.8400\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 151us/sample - loss: 0.0475 - val_loss: 0.8486\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 151us/sample - loss: 0.0469 - val_loss: 0.8417\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 151us/sample - loss: 0.0467 - val_loss: 0.8595\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.0457 - val_loss: 0.8561\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 140us/sample - loss: 0.0449 - val_loss: 0.8604\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.0447 - val_loss: 0.8633\n"
     ]
    }
   ],
   "source": [
    "data_path=\"por.txt\"\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.    \n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Vá.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Vá.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Vá.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Oi.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Corre!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Corre!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Corre!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Corre!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Corre!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Corre!\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Que\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Que\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Uau!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Uau!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Uau!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Fogo!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Fogo!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Fogo!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Socorro!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Socorro!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Pula!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Pula!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Pule.\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Pule.\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Pule.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Parem!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Parem!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Parem!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Parem!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Parem!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Aguarde!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Aguarde!\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Esperem.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Esperem.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Siga em frente.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Siga em frente.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Siga em frente.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Siga em frente.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Alô.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Alô.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Alô.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Alô.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Eu corri.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Eu sei.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Eu sei.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Eu sei.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Eu sei.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Eu sei.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Tento.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Tento.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Eu quero ver!\n",
      "\n",
      "-\n",
      "Input sentence: I won.\n",
      "Decoded sentence: Eu venci.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Ah não!\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Relaxa!\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Relaxa!\n",
      "\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Tiro!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Sorria.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Sorria.\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Ataquem!\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Ataquem!\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Ataquem!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Saúde!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Parado!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Levanta-te!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Levanta-te!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Levanta-te!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Levanta-te!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Levanta-te!\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Siga em frente.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Entendi.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Entendi.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Entendi.\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Entendeu?\n",
      "\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence: Ele correu.\n",
      "\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence: Ele correu.\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Entra aí!\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Entra aí!\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Me abrace.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Eu caí.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Sei.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Sei.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Eu saí.\n",
      "\n",
      "-\n",
      "Input sentence: I lied.\n",
      "Decoded sentence: Eu menti.\n",
      "\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence: Eu paguei.\n",
      "\n",
      "-\n",
      "Input sentence: I quit.\n",
      "Decoded sentence: Eu me demito.\n",
      "\n",
      "-\n",
      "Input sentence: I work.\n",
      "Decoded sentence: Eu estou trabalhando.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Eu vou bem.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Eu vou bem.\n",
      "\n",
      "-\n",
      "Input sentence: I'm up.\n",
      "Decoded sentence: Estou acordado.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Escuta.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: De maneira alguma!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Change seq2seq to generate automated responses english to portuguese in word-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "import numpy as np\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"por.txt\"\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.    \n",
    "num_samples = 10000  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_WORD = \"__(START)__\"\n",
    "END_WORD = \"__(END)__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "#     remove_punc = lambda x: x.translate(str.maketrans('', '', string.punctuation))\n",
    "#     remove_digits = lambda x: x.translate(str.maketrans('', '', string.digits))\n",
    "    text = text.lower()\n",
    "#     text = remove_punc(text)\n",
    "#     text = remove_digits(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 2895\n",
      "Number of unique output tokens: 4993\n",
      "Max sequence length for inputs: 5\n",
      "Max sequence length for outputs: 10\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_words = set()\n",
    "target_words = set()\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    line = cleanup(line)\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    # We use START_WORD as the \"start sequence\" character\n",
    "    # for the targets, and END_WORD as \"end sequence\" character.\n",
    "    target_text = START_WORD + \" \" + target_text + \" \" + END_WORD\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for word in input_text.split(\" \"):\n",
    "        if word not in input_words:\n",
    "            input_words.add(word)\n",
    "    for word in target_text.split(\" \"):\n",
    "        if word not in target_words:\n",
    "            target_words.add(word)\n",
    "            \n",
    "input_words = sorted(list(input_words))\n",
    "target_words = sorted(list(target_words))\n",
    "num_encoder_tokens = len(input_words)\n",
    "num_decoder_tokens = len(target_words)\n",
    "max_encoder_seq_length = max([len(txt.split(\" \")) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt.split(\" \")) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_word_index = dict(\n",
    "    [(word, i) for i, word in enumerate(input_words)])\n",
    "target_word_index = dict(\n",
    "    [(word, i) for i, word in enumerate(target_words)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, word in enumerate(input_text.split(\" \")):\n",
    "        encoder_input_data[i, t] = input_word_index[word]\n",
    "    for t, word in enumerate(target_text.split(\" \")):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_word_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start word.\n",
    "            decoder_target_data[i, t - 1, target_word_index[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 256)    741120      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, None, 256)    1278208     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 256), (None, 525312      embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  525312      embedding_8[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 4993)   1283201     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,353,153\n",
      "Trainable params: 4,353,153\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 5s 608us/sample - loss: 1.9642 - acc: 0.1185 - val_loss: 2.1216 - val_acc: 0.1204\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 3s 359us/sample - loss: 1.6283 - acc: 0.1426 - val_loss: 1.9680 - val_acc: 0.1620\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 3s 349us/sample - loss: 1.4751 - acc: 0.1606 - val_loss: 1.8481 - val_acc: 0.1732\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 4s 389us/sample - loss: 1.3760 - acc: 0.1702 - val_loss: 1.7822 - val_acc: 0.1815\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 4s 442us/sample - loss: 1.2907 - acc: 0.1785 - val_loss: 1.7414 - val_acc: 0.1895\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 3s 364us/sample - loss: 1.2197 - acc: 0.1881 - val_loss: 1.7159 - val_acc: 0.1881\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 3s 356us/sample - loss: 1.1558 - acc: 0.1963 - val_loss: 1.6877 - val_acc: 0.1966\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 4s 396us/sample - loss: 1.1000 - acc: 0.2035 - val_loss: 1.6696 - val_acc: 0.2025\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 4s 406us/sample - loss: 1.0492 - acc: 0.2099 - val_loss: 1.6497 - val_acc: 0.2036\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 4s 474us/sample - loss: 1.0011 - acc: 0.2153 - val_loss: 1.6449 - val_acc: 0.2027\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 4s 454us/sample - loss: 0.9597 - acc: 0.2210 - val_loss: 1.6548 - val_acc: 0.2061\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 3s 389us/sample - loss: 0.9201 - acc: 0.2263 - val_loss: 1.6306 - val_acc: 0.2052\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 4s 431us/sample - loss: 0.8817 - acc: 0.2308 - val_loss: 1.6473 - val_acc: 0.2061\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 3s 383us/sample - loss: 0.8467 - acc: 0.2359 - val_loss: 1.6465 - val_acc: 0.2079\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 3s 388us/sample - loss: 0.8145 - acc: 0.2404 - val_loss: 1.6521 - val_acc: 0.2115\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 4s 407us/sample - loss: 0.7850 - acc: 0.2444 - val_loss: 1.6457 - val_acc: 0.2108\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 3s 380us/sample - loss: 0.7547 - acc: 0.2489 - val_loss: 1.6590 - val_acc: 0.2133\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 3s 374us/sample - loss: 0.7262 - acc: 0.2537 - val_loss: 1.6490 - val_acc: 0.2134\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 4s 391us/sample - loss: 0.6995 - acc: 0.2575 - val_loss: 1.6612 - val_acc: 0.2090\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 4s 402us/sample - loss: 0.6751 - acc: 0.2616 - val_loss: 1.6359 - val_acc: 0.2140\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 3s 350us/sample - loss: 0.6519 - acc: 0.2644 - val_loss: 1.6697 - val_acc: 0.2148\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 3s 377us/sample - loss: 0.6288 - acc: 0.2692 - val_loss: 1.6595 - val_acc: 0.2167\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 3s 375us/sample - loss: 0.6064 - acc: 0.2737 - val_loss: 1.6641 - val_acc: 0.2155\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 4s 459us/sample - loss: 0.5856 - acc: 0.2761 - val_loss: 1.6702 - val_acc: 0.2148\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 4s 448us/sample - loss: 0.5643 - acc: 0.2802 - val_loss: 1.6978 - val_acc: 0.2113\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 4s 419us/sample - loss: 0.5463 - acc: 0.2831 - val_loss: 1.7068 - val_acc: 0.2110\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 4s 406us/sample - loss: 0.5285 - acc: 0.2869 - val_loss: 1.7251 - val_acc: 0.2108\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 4s 401us/sample - loss: 0.5134 - acc: 0.2892 - val_loss: 1.7480 - val_acc: 0.2112\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 4s 429us/sample - loss: 0.4981 - acc: 0.2922 - val_loss: 1.7364 - val_acc: 0.2124\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 3s 344us/sample - loss: 0.4826 - acc: 0.2945 - val_loss: 1.7499 - val_acc: 0.2095\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 3s 348us/sample - loss: 0.4669 - acc: 0.2973 - val_loss: 1.7309 - val_acc: 0.2149\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 3s 370us/sample - loss: 0.4527 - acc: 0.3004 - val_loss: 1.7319 - val_acc: 0.2150\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 3s 353us/sample - loss: 0.4389 - acc: 0.3015 - val_loss: 1.7423 - val_acc: 0.2154\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 3s 371us/sample - loss: 0.4263 - acc: 0.3045 - val_loss: 1.7461 - val_acc: 0.2141\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 4s 414us/sample - loss: 0.4152 - acc: 0.3051 - val_loss: 1.7720 - val_acc: 0.2150\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 4s 454us/sample - loss: 0.4065 - acc: 0.3068 - val_loss: 1.7513 - val_acc: 0.2178\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 3s 383us/sample - loss: 0.3972 - acc: 0.3090 - val_loss: 1.7526 - val_acc: 0.2148\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 4s 498us/sample - loss: 0.3877 - acc: 0.3104 - val_loss: 1.7783 - val_acc: 0.2108\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 3s 368us/sample - loss: 0.3797 - acc: 0.3116 - val_loss: 1.7637 - val_acc: 0.2152\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 3s 373us/sample - loss: 0.3713 - acc: 0.3122 - val_loss: 1.7621 - val_acc: 0.2147\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 3s 352us/sample - loss: 0.3647 - acc: 0.3131 - val_loss: 1.7754 - val_acc: 0.2151\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 3s 349us/sample - loss: 0.3575 - acc: 0.3142 - val_loss: 1.7607 - val_acc: 0.2145\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 3s 355us/sample - loss: 0.3511 - acc: 0.3155 - val_loss: 1.7737 - val_acc: 0.2156\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 3s 384us/sample - loss: 0.3448 - acc: 0.3163 - val_loss: 1.7704 - val_acc: 0.2138\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 4s 413us/sample - loss: 0.3388 - acc: 0.3167 - val_loss: 1.7528 - val_acc: 0.2183\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 4s 418us/sample - loss: 0.3336 - acc: 0.3177 - val_loss: 1.7637 - val_acc: 0.2150\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 4s 397us/sample - loss: 0.3277 - acc: 0.3183 - val_loss: 1.7827 - val_acc: 0.2141\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 4s 452us/sample - loss: 0.3231 - acc: 0.3191 - val_loss: 1.7742 - val_acc: 0.2155\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 4s 416us/sample - loss: 0.3182 - acc: 0.3190 - val_loss: 1.7880 - val_acc: 0.2177\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 4s 466us/sample - loss: 0.3134 - acc: 0.3201 - val_loss: 1.8040 - val_acc: 0.2157\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 4s 399us/sample - loss: 0.3087 - acc: 0.3211 - val_loss: 1.7878 - val_acc: 0.2141\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 3s 334us/sample - loss: 0.3039 - acc: 0.3214 - val_loss: 1.7844 - val_acc: 0.2140\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 3s 348us/sample - loss: 0.2994 - acc: 0.3221 - val_loss: 1.7820 - val_acc: 0.2169\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 4s 408us/sample - loss: 0.2956 - acc: 0.3216 - val_loss: 1.8182 - val_acc: 0.2141\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 3s 374us/sample - loss: 0.2908 - acc: 0.3224 - val_loss: 1.8095 - val_acc: 0.2131\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 4s 397us/sample - loss: 0.2875 - acc: 0.3223 - val_loss: 1.8235 - val_acc: 0.2141\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 3s 371us/sample - loss: 0.2841 - acc: 0.3228 - val_loss: 1.8372 - val_acc: 0.2133\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 3s 360us/sample - loss: 0.2798 - acc: 0.3240 - val_loss: 1.8287 - val_acc: 0.2140\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 3s 344us/sample - loss: 0.2755 - acc: 0.3248 - val_loss: 1.8302 - val_acc: 0.2167\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 3s 351us/sample - loss: 0.2731 - acc: 0.3245 - val_loss: 1.8580 - val_acc: 0.2122\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 3s 363us/sample - loss: 0.2698 - acc: 0.3246 - val_loss: 1.8592 - val_acc: 0.2124\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 3s 352us/sample - loss: 0.2666 - acc: 0.3250 - val_loss: 1.8544 - val_acc: 0.2142\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 3s 360us/sample - loss: 0.2645 - acc: 0.3254 - val_loss: 1.8596 - val_acc: 0.2120\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 3s 350us/sample - loss: 0.2614 - acc: 0.3252 - val_loss: 1.8484 - val_acc: 0.2100\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 4s 478us/sample - loss: 0.2599 - acc: 0.3255 - val_loss: 1.8864 - val_acc: 0.2136\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 4s 408us/sample - loss: 0.2571 - acc: 0.3258 - val_loss: 1.8668 - val_acc: 0.2112\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 3s 363us/sample - loss: 0.2540 - acc: 0.3267 - val_loss: 1.8722 - val_acc: 0.2119\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 3s 366us/sample - loss: 0.2526 - acc: 0.3265 - val_loss: 1.8801 - val_acc: 0.2137\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 3s 353us/sample - loss: 0.2506 - acc: 0.3268 - val_loss: 1.8830 - val_acc: 0.2094\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 3s 374us/sample - loss: 0.2476 - acc: 0.3266 - val_loss: 1.8879 - val_acc: 0.2117\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 4s 389us/sample - loss: 0.2445 - acc: 0.3274 - val_loss: 1.8608 - val_acc: 0.2121\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 4s 426us/sample - loss: 0.2426 - acc: 0.3269 - val_loss: 1.8930 - val_acc: 0.2126\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 4s 403us/sample - loss: 0.2401 - acc: 0.3278 - val_loss: 1.8893 - val_acc: 0.2131\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 3s 382us/sample - loss: 0.2382 - acc: 0.3278 - val_loss: 1.8914 - val_acc: 0.2120\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 3s 373us/sample - loss: 0.2366 - acc: 0.3285 - val_loss: 1.8918 - val_acc: 0.2141\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 3s 343us/sample - loss: 0.2352 - acc: 0.3290 - val_loss: 1.9062 - val_acc: 0.2118\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 3s 343us/sample - loss: 0.2329 - acc: 0.3297 - val_loss: 1.9094 - val_acc: 0.2107\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - 3s 351us/sample - loss: 0.2310 - acc: 0.3296 - val_loss: 1.9167 - val_acc: 0.2118\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 3s 353us/sample - loss: 0.2298 - acc: 0.3301 - val_loss: 1.8997 - val_acc: 0.2100\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 4s 392us/sample - loss: 0.2279 - acc: 0.3298 - val_loss: 1.9078 - val_acc: 0.2110\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 4s 390us/sample - loss: 0.2269 - acc: 0.3307 - val_loss: 1.8995 - val_acc: 0.2115\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 3s 377us/sample - loss: 0.2258 - acc: 0.3306 - val_loss: 1.9115 - val_acc: 0.2126\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 3s 383us/sample - loss: 0.2250 - acc: 0.3310 - val_loss: 1.9140 - val_acc: 0.2120\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 3s 354us/sample - loss: 0.2235 - acc: 0.3313 - val_loss: 1.9143 - val_acc: 0.2150\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 4s 413us/sample - loss: 0.2235 - acc: 0.3306 - val_loss: 1.9208 - val_acc: 0.2115\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 4s 408us/sample - loss: 0.2219 - acc: 0.3309 - val_loss: 1.9171 - val_acc: 0.2147\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 3s 362us/sample - loss: 0.2215 - acc: 0.3310 - val_loss: 1.9223 - val_acc: 0.2136\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 3s 342us/sample - loss: 0.2212 - acc: 0.3316 - val_loss: 1.9374 - val_acc: 0.2118\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 3s 368us/sample - loss: 0.2204 - acc: 0.3317 - val_loss: 1.9116 - val_acc: 0.2142\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 4s 398us/sample - loss: 0.2195 - acc: 0.3316 - val_loss: 1.9255 - val_acc: 0.2103\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 4s 429us/sample - loss: 0.2188 - acc: 0.3315 - val_loss: 1.9205 - val_acc: 0.2127\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 4s 428us/sample - loss: 0.2178 - acc: 0.3323 - val_loss: 1.9244 - val_acc: 0.2123\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 4s 405us/sample - loss: 0.2169 - acc: 0.3322 - val_loss: 1.9337 - val_acc: 0.2113\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 3s 389us/sample - loss: 0.2169 - acc: 0.3319 - val_loss: 1.9466 - val_acc: 0.2108\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 4s 398us/sample - loss: 0.2156 - acc: 0.3324 - val_loss: 1.9414 - val_acc: 0.2121\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 4s 420us/sample - loss: 0.2151 - acc: 0.3327 - val_loss: 1.9439 - val_acc: 0.2124\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 4s 399us/sample - loss: 0.2149 - acc: 0.3323 - val_loss: 1.9332 - val_acc: 0.2124\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 4s 434us/sample - loss: 0.2142 - acc: 0.3326 - val_loss: 1.9472 - val_acc: 0.2115\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 4s 402us/sample - loss: 0.2136 - acc: 0.3330 - val_loss: 1.9473 - val_acc: 0.2106\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 4s 419us/sample - loss: 0.2134 - acc: 0.3329 - val_loss: 1.9487 - val_acc: 0.2095\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.    \n",
    "encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
    "_, state_h, state_c = LSTM(latent_dim,\n",
    "                           return_state=True)(x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(num_decoder_tokens, latent_dim)\n",
    "x = decoder_embedding(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "x, _, _ = decoder_lstm(x, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(x)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile & run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
    "# rather than sequences of integers like `decoder_input_data`!\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)\n",
    "\n",
    "model.save('s2s_word.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding_inputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_embedding_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence:\t\t what a phony!\n",
      "Decoded sentence:\t que hipócrita!\n",
      "-\n",
      "Input sentence:\t\t please fix it.\n",
      "Decoded sentence:\t por favor, arrume-o.\n",
      "-\n",
      "Input sentence:\t\t stop resisting!\n",
      "Decoded sentence:\t para de resistir!\n",
      "-\n",
      "Input sentence:\t\t i'll tell tom.\n",
      "Decoded sentence:\t vou contar para\n",
      "-\n",
      "Input sentence:\t\t we want to win.\n",
      "Decoded sentence:\t nós queremos\n",
      "-\n",
      "Input sentence:\t\t shall we start?\n",
      "Decoded sentence:\t nós devemos\n",
      "-\n",
      "Input sentence:\t\t i'm very tired.\n",
      "Decoded sentence:\t estou muito\n",
      "-\n",
      "Input sentence:\t\t have some more.\n",
      "Decoded sentence:\t pegue mais um\n",
      "-\n",
      "Input sentence:\t\t is it true?\n",
      "Decoded sentence:\t é verdade? __(END)__\n",
      "-\n",
      "Input sentence:\t\t come with us.\n",
      "Decoded sentence:\t venha conosco.\n",
      "-\n",
      "Input sentence:\t\t what a feast!\n",
      "Decoded sentence:\t que não nos\n",
      "-\n",
      "Input sentence:\t\t contact tom.\n",
      "Decoded sentence:\t o tom. __(END)__\n",
      "-\n",
      "Input sentence:\t\t he's in danger.\n",
      "Decoded sentence:\t ele está em\n",
      "-\n",
      "Input sentence:\t\t enjoy the show.\n",
      "Decoded sentence:\t eu o show. __(END)__\n",
      "-\n",
      "Input sentence:\t\t we're so happy.\n",
      "Decoded sentence:\t somos felizes.\n",
      "-\n",
      "Input sentence:\t\t be calm.\n",
      "Decoded sentence:\t fique calmo.\n",
      "-\n",
      "Input sentence:\t\t nobody listens.\n",
      "Decoded sentence:\t ninguém escuta.\n",
      "-\n",
      "Input sentence:\t\t that is my dog.\n",
      "Decoded sentence:\t aquele é o meu\n",
      "-\n",
      "Input sentence:\t\t it's very hot.\n",
      "Decoded sentence:\t está muito quente.\n",
      "-\n",
      "Input sentence:\t\t send it to me.\n",
      "Decoded sentence:\t envie para mim.\n",
      "-\n",
      "Input sentence:\t\t she's hot.\n",
      "Decoded sentence:\t ela está com\n",
      "-\n",
      "Input sentence:\t\t my tummy hurts.\n",
      "Decoded sentence:\t minha está doendo.\n",
      "-\n",
      "Input sentence:\t\t i am hungarian.\n",
      "Decoded sentence:\t eu sou húngaro.\n",
      "-\n",
      "Input sentence:\t\t she is awkward.\n",
      "Decoded sentence:\t ela é estranha.\n",
      "-\n",
      "Input sentence:\t\t is it smooth?\n",
      "Decoded sentence:\t é para nervoso.\n",
      "-\n",
      "Input sentence:\t\t i hear that.\n",
      "Decoded sentence:\t escuto aquilo.\n",
      "-\n",
      "Input sentence:\t\t is it reliable?\n",
      "Decoded sentence:\t é confiável?\n",
      "-\n",
      "Input sentence:\t\t we'll call you.\n",
      "Decoded sentence:\t nós vamos te\n",
      "-\n",
      "Input sentence:\t\t i like that.\n",
      "Decoded sentence:\t eu gosto disso.\n",
      "-\n",
      "Input sentence:\t\t you're weak.\n",
      "Decoded sentence:\t tu estás fraco.\n",
      "-\n",
      "Input sentence:\t\t i'll tell tom.\n",
      "Decoded sentence:\t vou contar para\n",
      "-\n",
      "Input sentence:\t\t i accept gifts.\n",
      "Decoded sentence:\t eu me tom. __(END)__\n",
      "-\n",
      "Input sentence:\t\t try this.\n",
      "Decoded sentence:\t experimenta\n",
      "-\n",
      "Input sentence:\t\t it's too dark.\n",
      "Decoded sentence:\t está muito escuro.\n",
      "-\n",
      "Input sentence:\t\t it's a shame.\n",
      "Decoded sentence:\t é uma vergonha.\n",
      "-\n",
      "Input sentence:\t\t please sing.\n",
      "Decoded sentence:\t por favor, cante.\n",
      "-\n",
      "Input sentence:\t\t he was alone.\n",
      "Decoded sentence:\t ele estava só.\n",
      "-\n",
      "Input sentence:\t\t it was wet.\n",
      "Decoded sentence:\t estava molhado.\n",
      "-\n",
      "Input sentence:\t\t we'll dance.\n",
      "Decoded sentence:\t nós vamos dançar.\n",
      "-\n",
      "Input sentence:\t\t lock the door.\n",
      "Decoded sentence:\t tranque a porta!\n",
      "-\n",
      "Input sentence:\t\t study hard.\n",
      "Decoded sentence:\t estude muito.\n",
      "-\n",
      "Input sentence:\t\t no problem.\n",
      "Decoded sentence:\t não há problema.\n",
      "-\n",
      "Input sentence:\t\t go inside.\n",
      "Decoded sentence:\t vai para dentro.\n",
      "-\n",
      "Input sentence:\t\t is it for me?\n",
      "Decoded sentence:\t isso é para\n",
      "-\n",
      "Input sentence:\t\t are you nuts?\n",
      "Decoded sentence:\t estás louco?\n",
      "-\n",
      "Input sentence:\t\t we'll do that.\n",
      "Decoded sentence:\t faremos isso.\n",
      "-\n",
      "Input sentence:\t\t does that work?\n",
      "Decoded sentence:\t aquilo funciona?\n",
      "-\n",
      "Input sentence:\t\t tom is dying.\n",
      "Decoded sentence:\t tom está morrendo.\n",
      "-\n",
      "Input sentence:\t\t trust me.\n",
      "Decoded sentence:\t confie em mim.\n",
      "-\n",
      "Input sentence:\t\t i made dinner.\n",
      "Decoded sentence:\t fiz o jantar.\n",
      "-\n",
      "Input sentence:\t\t get everything.\n",
      "Decoded sentence:\t pegue tudo.\n",
      "-\n",
      "Input sentence:\t\t i'm a tourist.\n",
      "Decoded sentence:\t sou um turista.\n",
      "-\n",
      "Input sentence:\t\t i prayed.\n",
      "Decoded sentence:\t eu me fazer\n",
      "-\n",
      "Input sentence:\t\t he's smart.\n",
      "Decoded sentence:\t ele é inteligente.\n",
      "-\n",
      "Input sentence:\t\t we'll show tom.\n",
      "Decoded sentence:\t nós vamos perguntar\n",
      "-\n",
      "Input sentence:\t\t that's my book.\n",
      "Decoded sentence:\t esse é o meu\n",
      "-\n",
      "Input sentence:\t\t we're students.\n",
      "Decoded sentence:\t somos doida.\n",
      "-\n",
      "Input sentence:\t\t they lied.\n",
      "Decoded sentence:\t eles mentiram.\n",
      "-\n",
      "Input sentence:\t\t i'm sad.\n",
      "Decoded sentence:\t eu estou triste.\n",
      "-\n",
      "Input sentence:\t\t you'll do it.\n",
      "Decoded sentence:\t você vai fazer\n",
      "-\n",
      "Input sentence:\t\t tom saw them.\n",
      "Decoded sentence:\t tom viu elas.\n",
      "-\n",
      "Input sentence:\t\t stop laughing.\n",
      "Decoded sentence:\t parem de rir!\n",
      "-\n",
      "Input sentence:\t\t well done!\n",
      "Decoded sentence:\t bem feito! __(END)__\n",
      "-\n",
      "Input sentence:\t\t tom is awake.\n",
      "Decoded sentence:\t o tom está acordado.\n",
      "-\n",
      "Input sentence:\t\t those are mine.\n",
      "Decoded sentence:\t é legal. __(END)__\n",
      "-\n",
      "Input sentence:\t\t call me later.\n",
      "Decoded sentence:\t me liga depois.\n",
      "-\n",
      "Input sentence:\t\t be prepared.\n",
      "Decoded sentence:\t esteja preparado.\n",
      "-\n",
      "Input sentence:\t\t tom's mistaken.\n",
      "Decoded sentence:\t tom é cego.\n",
      "-\n",
      "Input sentence:\t\t i sell flowers.\n",
      "Decoded sentence:\t vendo flores.\n",
      "-\n",
      "Input sentence:\t\t i love boston.\n",
      "Decoded sentence:\t adoro boston.\n",
      "-\n",
      "Input sentence:\t\t i'm a father.\n",
      "Decoded sentence:\t eu sou um pai.\n",
      "-\n",
      "Input sentence:\t\t whose is it?\n",
      "Decoded sentence:\t de quem é? __(END)__\n",
      "-\n",
      "Input sentence:\t\t tom has a ford.\n",
      "Decoded sentence:\t tom tem uma\n",
      "-\n",
      "Input sentence:\t\t i'm not you.\n",
      "Decoded sentence:\t não sou você.\n",
      "-\n",
      "Input sentence:\t\t hey, relax.\n",
      "Decoded sentence:\t ei, relaxe.\n",
      "-\n",
      "Input sentence:\t\t don't tell me.\n",
      "Decoded sentence:\t não me fale.\n",
      "-\n",
      "Input sentence:\t\t tom warned us.\n",
      "Decoded sentence:\t tom nos avisou.\n",
      "-\n",
      "Input sentence:\t\t i miss my kids.\n",
      "Decoded sentence:\t estou com saudade\n",
      "-\n",
      "Input sentence:\t\t who's she?\n",
      "Decoded sentence:\t quem é ela?\n",
      "-\n",
      "Input sentence:\t\t this is my bag.\n",
      "Decoded sentence:\t isto é o meu\n",
      "-\n",
      "Input sentence:\t\t you may stay.\n",
      "Decoded sentence:\t tu podes ficar.\n",
      "-\n",
      "Input sentence:\t\t they're mine.\n",
      "Decoded sentence:\t eles são meus.\n",
      "-\n",
      "Input sentence:\t\t i'm next.\n",
      "Decoded sentence:\t sou o próximo.\n",
      "-\n",
      "Input sentence:\t\t i said that.\n",
      "Decoded sentence:\t eu disse isso.\n",
      "-\n",
      "Input sentence:\t\t is that weird?\n",
      "Decoded sentence:\t isso é estranho?\n",
      "-\n",
      "Input sentence:\t\t i feel sick.\n",
      "Decoded sentence:\t estou mal. __(END)__\n",
      "-\n",
      "Input sentence:\t\t i like that.\n",
      "Decoded sentence:\t eu gosto disso.\n",
      "-\n",
      "Input sentence:\t\t freeze!\n",
      "Decoded sentence:\t parado! __(END)__\n",
      "-\n",
      "Input sentence:\t\t he loves them.\n",
      "Decoded sentence:\t ele as ama.\n",
      "-\n",
      "Input sentence:\t\t i've got money.\n",
      "Decoded sentence:\t eu tenho dinheiro.\n",
      "-\n",
      "Input sentence:\t\t please stop.\n",
      "Decoded sentence:\t por favor, pare.\n",
      "-\n",
      "Input sentence:\t\t he almost died.\n",
      "Decoded sentence:\t ele quase morreu.\n",
      "-\n",
      "Input sentence:\t\t can't you read?\n",
      "Decoded sentence:\t você não sabe\n",
      "-\n",
      "Input sentence:\t\t is it a trap?\n",
      "Decoded sentence:\t é uma uma mova.\n",
      "-\n",
      "Input sentence:\t\t i can't win.\n",
      "Decoded sentence:\t eu não consigo\n",
      "-\n",
      "Input sentence:\t\t do you get me?\n",
      "Decoded sentence:\t você me compreende?\n",
      "-\n",
      "Input sentence:\t\t we're twins.\n",
      "Decoded sentence:\t nós somos gêmeos.\n",
      "-\n",
      "Input sentence:\t\t they have come.\n",
      "Decoded sentence:\t eles são legais.\n",
      "-\n",
      "Input sentence:\t\t i'm happy.\n",
      "Decoded sentence:\t eu estou feliz.\n",
      "-\n",
      "Input sentence:\t\t they're alone.\n",
      "Decoded sentence:\t eles estão sozinhos.\n"
     ]
    }
   ],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "target_index_word = dict(\n",
    "    (i, word) for word, i in target_word_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_word_index[START_WORD]\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    has_seen_first_word = False\n",
    "    while not stop_condition:\n",
    "        output_words, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a word\n",
    "        sampled_word_index = np.argmax(output_words[0, -1, :])\n",
    "        sampled_word = target_index_word[sampled_word_index]\n",
    "        decoded_sentence += \" \" + sampled_word if has_seen_first_word \\\n",
    "            else sampled_word\n",
    "        has_seen_first_word = True\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        stop_condition = (sampled_word == END_WORD or\n",
    "           len(decoded_sentence) > max_decoder_seq_length)\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_word_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for _ in range(100):\n",
    "    seq_index = random.randint(0, len(input_texts) - 2)\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:\\t\\t', input_texts[seq_index])\n",
    "    print('Decoded sentence:\\t', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
